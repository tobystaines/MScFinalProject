INFO - UNet_Speech_Separation - Running command 'do_experiment'
INFO - UNet_Speech_Separation - Started run with ID "113"
Experiment ID: 113
Preparing dataset
Dataset ready
2018-10-11 19:30:46.640426: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-10-11 19:30:46.810938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-10-11 19:30:46.811619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:23:00.0
totalMemory: 10.92GiB freeMemory: 10.76GiB
2018-10-11 19:30:46.811646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:23:00.0, compute capability: 6.1)
Session started
Iterators created
Creating model
Loading checkpoint
INFO:tensorflow:Restoring parameters from /home/enterprise.internal.city.ac.uk/acvn728/checkpoints/99/99-21000
INFO - tensorflow - Restoring parameters from /home/enterprise.internal.city.ac.uk/acvn728/checkpoints/99/99-21000
Starting training
2018-10-11 19:31:02.730834: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 803 of 1000
2018-10-11 19:31:04.506897: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-11 19:31:06.192174:	Training iteration: 1, Loss: 0.006352502852678299
Checkpoint
2018-10-11 19:31:07.778676:	Training iteration: 2, Loss: 0.006914437748491764
Checkpoint
2018-10-11 19:31:08.936970:	Training iteration: 3, Loss: 0.008088892325758934
Checkpoint
2018-10-11 19:31:10.103207:	Training iteration: 4, Loss: 0.007335836533457041
Checkpoint
2018-10-11 19:31:11.344754:	Training iteration: 5, Loss: 0.006553026847541332
Checkpoint
2018-10-11 19:31:12.488574:	Training iteration: 6, Loss: 0.005912563763558865
Checkpoint
2018-10-11 19:31:13.630613:	Training iteration: 7, Loss: 0.004848616197705269
Checkpoint
2018-10-11 19:31:14.789948:	Training iteration: 8, Loss: 0.0050994763150811195
Checkpoint
2018-10-11 19:31:15.943837:	Training iteration: 9, Loss: 0.0075724185444414616
Checkpoint
2018-10-11 19:31:17.126864:	Training iteration: 10, Loss: 0.006691069342195988
Checkpoint
2018-10-11 19:31:18.300812:	Training iteration: 11, Loss: 0.006763666868209839
Checkpoint
2018-10-11 19:31:19.476617:	Training iteration: 12, Loss: 0.005774690769612789
Checkpoint
2018-10-11 19:31:20.659094:	Training iteration: 13, Loss: 0.005234484560787678
Checkpoint
2018-10-11 19:31:21.833794:	Training iteration: 14, Loss: 0.007001771125942469
Checkpoint
2018-10-11 19:31:23.125789:	Training iteration: 15, Loss: 0.0052457647398114204
Checkpoint
2018-10-11 19:31:24.297843:	Training iteration: 16, Loss: 0.005679861642420292
Checkpoint
2018-10-11 19:31:25.473617:	Training iteration: 17, Loss: 0.0048970808275043964
Checkpoint
2018-10-11 19:31:26.640640:	Training iteration: 18, Loss: 0.007023251615464687
Checkpoint
2018-10-11 19:31:27.816616:	Training iteration: 19, Loss: 0.005053152330219746
Checkpoint
2018-10-11 19:31:28.974333:	Training iteration: 20, Loss: 0.0064476123079657555
Checkpoint
2018-10-11 19:31:30.109076:	Training iteration: 21, Loss: 0.005292099434882402
Checkpoint
2018-10-11 19:31:31.272361:	Training iteration: 22, Loss: 0.004881978966295719
Checkpoint
2018-10-11 19:31:32.448705:	Training iteration: 23, Loss: 0.005842634476721287
Checkpoint
2018-10-11 19:31:33.646687:	Training iteration: 24, Loss: 0.006001895759254694
Checkpoint
2018-10-11 19:31:34.797866:	Training iteration: 25, Loss: 0.0060871196910738945
Checkpoint
2018-10-11 19:31:35.985622:	Training iteration: 26, Loss: 0.005234297830611467
Checkpoint
2018-10-11 19:31:37.150485:	Training iteration: 27, Loss: 0.005754406098276377
Checkpoint
2018-10-11 19:31:38.469422:	Training iteration: 28, Loss: 0.005265594460070133
Checkpoint
2018-10-11 19:31:39.638311:	Training iteration: 29, Loss: 0.004326677415519953
Checkpoint
2018-10-11 19:31:40.813175:	Training iteration: 30, Loss: 0.005935247056186199
Checkpoint
2018-10-11 19:31:41.990380:	Training iteration: 31, Loss: 0.004931825213134289
Checkpoint
2018-10-11 19:31:43.157449:	Training iteration: 32, Loss: 0.004319104366004467
Checkpoint
2018-10-11 19:31:44.334697:	Training iteration: 33, Loss: 0.006262424401938915
Checkpoint
2018-10-11 19:31:45.512084:	Training iteration: 34, Loss: 0.005499215330928564
Checkpoint
2018-10-11 19:31:46.697363:	Training iteration: 35, Loss: 0.006429658271372318
Checkpoint
2018-10-11 19:31:47.868731:	Training iteration: 36, Loss: 0.0048834094777703285
Checkpoint
2018-10-11 19:31:49.043361:	Training iteration: 37, Loss: 0.006532661616802216
Checkpoint
2018-10-11 19:31:50.205781:	Training iteration: 38, Loss: 0.005780189763754606
Checkpoint
2018-10-11 19:31:51.389639:	Training iteration: 39, Loss: 0.005398280918598175
Checkpoint
2018-10-11 19:31:52.548264:	Training iteration: 40, Loss: 0.0051318565383553505
Checkpoint
2018-10-11 19:31:53.722844:	Training iteration: 41, Loss: 0.005414927843958139
Checkpoint
2018-10-11 19:31:54.901266:	Training iteration: 42, Loss: 0.005259775556623936
Checkpoint
2018-10-11 19:31:56.091179:	Training iteration: 43, Loss: 0.005542135797441006
Checkpoint
2018-10-11 19:31:57.251824:	Training iteration: 44, Loss: 0.004796651192009449
Checkpoint
2018-10-11 19:31:58.430068:	Training iteration: 45, Loss: 0.004963028710335493
Checkpoint
2018-10-11 19:31:59.608055:	Training iteration: 46, Loss: 0.005188176408410072
Checkpoint
2018-10-11 19:32:00.819832:	Training iteration: 47, Loss: 0.004513545893132687
Checkpoint
2018-10-11 19:32:02.003749:	Training iteration: 48, Loss: 0.005639767274260521
Checkpoint
2018-10-11 19:32:03.167343:	Training iteration: 49, Loss: 0.004439288750290871
Checkpoint
2018-10-11 19:32:04.373268:	Training iteration: 50, Loss: 0.005614343099296093
Checkpoint
2018-10-11 19:32:05.714758:	Training iteration: 51, Loss: 0.005442134104669094
Checkpoint
2018-10-11 19:32:06.875732:	Training iteration: 52, Loss: 0.005597495939582586
Checkpoint
2018-10-11 19:32:08.054942:	Training iteration: 53, Loss: 0.00771989906206727
Checkpoint
2018-10-11 19:32:09.235255:	Training iteration: 54, Loss: 0.0052333553321659565
Checkpoint
2018-10-11 19:32:10.401259:	Training iteration: 55, Loss: 0.00443131010979414
Checkpoint
2018-10-11 19:32:11.570611:	Training iteration: 56, Loss: 0.005915256682783365
Checkpoint
2018-10-11 19:32:12.787881:	Training iteration: 57, Loss: 0.00480650644749403
Checkpoint
2018-10-11 19:32:13.968293:	Training iteration: 58, Loss: 0.005579016171395779
Checkpoint
2018-10-11 19:32:15.147612:	Training iteration: 59, Loss: 0.004777865018695593
Checkpoint
2018-10-11 19:32:16.326497:	Training iteration: 60, Loss: 0.004325038753449917
Checkpoint
2018-10-11 19:32:17.553613:	Training iteration: 61, Loss: 0.005773879121989012
Checkpoint
2018-10-11 19:32:18.731515:	Training iteration: 62, Loss: 0.0064576477743685246
Checkpoint
2018-10-11 19:32:20.005496:	Training iteration: 63, Loss: 0.005170946009457111
Checkpoint
2018-10-11 19:32:21.223340:	Training iteration: 64, Loss: 0.00546445744112134
Checkpoint
2018-10-11 19:32:22.396530:	Training iteration: 65, Loss: 0.006865561008453369
Checkpoint
2018-10-11 19:32:23.593015:	Training iteration: 66, Loss: 0.0054501756094396114
Checkpoint
2018-10-11 19:32:24.766212:	Training iteration: 67, Loss: 0.00512442784383893
Checkpoint
2018-10-11 19:32:25.941205:	Training iteration: 68, Loss: 0.005725845694541931
Checkpoint
2018-10-11 19:32:27.118859:	Training iteration: 69, Loss: 0.00611527543514967
Checkpoint
2018-10-11 19:32:28.326159:	Training iteration: 70, Loss: 0.004720741417258978
Checkpoint
2018-10-11 19:32:29.505262:	Training iteration: 71, Loss: 0.005160720087587833
Checkpoint
2018-10-11 19:32:30.672320:	Training iteration: 72, Loss: 0.004692298360168934
Checkpoint
2018-10-11 19:32:31.850246:	Training iteration: 73, Loss: 0.005928019527345896
Checkpoint
2018-10-11 19:32:33.014088:	Training iteration: 74, Loss: 0.0052569047547876835
Checkpoint
2018-10-11 19:32:34.182874:	Training iteration: 75, Loss: 0.005078884307295084
Checkpoint
2018-10-11 19:32:35.401621:	Training iteration: 76, Loss: 0.004062779247760773
Checkpoint
2018-10-11 19:32:36.574282:	Training iteration: 77, Loss: 0.00462972279638052
Checkpoint
2018-10-11 19:32:37.745380:	Training iteration: 78, Loss: 0.006398875266313553
Checkpoint
2018-10-11 19:32:38.958962:	Training iteration: 79, Loss: 0.00462452694773674
Checkpoint
2018-10-11 19:32:40.125855:	Training iteration: 80, Loss: 0.004585801158100367
Checkpoint
2018-10-11 19:32:41.292573:	Training iteration: 81, Loss: 0.0038220002315938473
Checkpoint
2018-10-11 19:32:42.448401:	Training iteration: 82, Loss: 0.0044932859018445015
Checkpoint
2018-10-11 19:32:43.682058:	Training iteration: 83, Loss: 0.005251771304756403
Checkpoint
2018-10-11 19:32:44.925345:	Training iteration: 84, Loss: 0.006581473164260387
Checkpoint
2018-10-11 19:32:46.469560:	Training iteration: 85, Loss: 0.005529991816729307
Checkpoint
2018-10-11 19:32:47.844564:	Training iteration: 86, Loss: 0.0053971633315086365
Checkpoint
2018-10-11 19:32:49.163759:	Training iteration: 87, Loss: 0.00558239221572876
Checkpoint
2018-10-11 19:32:50.367119:	Training iteration: 88, Loss: 0.005555593874305487
Checkpoint
2018-10-11 19:32:51.536589:	Training iteration: 89, Loss: 0.004677788354456425
Checkpoint
2018-10-11 19:32:52.953442:	Training iteration: 90, Loss: 0.005069075617939234
Checkpoint
2018-10-11 19:32:54.157157:	Training iteration: 91, Loss: 0.005879271775484085
Checkpoint
2018-10-11 19:32:55.353299:	Training iteration: 92, Loss: 0.007236038334667683
Checkpoint
2018-10-11 19:32:56.544961:	Training iteration: 93, Loss: 0.005151039455085993
Checkpoint
2018-10-11 19:32:57.689174:	Training iteration: 94, Loss: 0.005950466264039278
Checkpoint
2018-10-11 19:32:59.069981:	Training iteration: 95, Loss: 0.004820195492357016
Checkpoint
2018-10-11 19:33:00.281732:	Training iteration: 96, Loss: 0.0068944646045565605
Checkpoint
2018-10-11 19:33:01.441231:	Training iteration: 97, Loss: 0.005385849624872208
Checkpoint
2018-10-11 19:33:02.573844:	Training iteration: 98, Loss: 0.004580250941216946
Checkpoint
2018-10-11 19:33:04.059413:	Training iteration: 99, Loss: 0.005490628536790609
Checkpoint
2018-10-11 19:33:05.322233:	Training iteration: 100, Loss: 0.006300455890595913
Checkpoint
2018-10-11 19:33:06.493831:	Training iteration: 101, Loss: 0.005019586533308029
Checkpoint
2018-10-11 19:33:07.736378:	Training iteration: 102, Loss: 0.005542502738535404
Checkpoint
2018-10-11 19:33:08.906591:	Training iteration: 103, Loss: 0.0061460332944989204
Checkpoint
2018-10-11 19:33:10.120634:	Training iteration: 104, Loss: 0.00623623002320528
Checkpoint
2018-10-11 19:33:11.659421:	Training iteration: 105, Loss: 0.0055594854056835175
Checkpoint
2018-10-11 19:33:12.890961:	Training iteration: 106, Loss: 0.005983750335872173
Checkpoint
2018-10-11 19:33:14.103271:	Training iteration: 107, Loss: 0.004709158092737198
Checkpoint
2018-10-11 19:33:15.414237:	Training iteration: 108, Loss: 0.005730867385864258
Checkpoint
2018-10-11 19:33:16.579052:	Training iteration: 109, Loss: 0.0051271067932248116
Checkpoint
2018-10-11 19:33:17.727401:	Training iteration: 110, Loss: 0.004555095918476582
Checkpoint
2018-10-11 19:33:18.899130:	Training iteration: 111, Loss: 0.005239053163677454
Checkpoint
2018-10-11 19:33:20.051213:	Training iteration: 112, Loss: 0.005580571945756674
Checkpoint
2018-10-11 19:33:21.181656:	Training iteration: 113, Loss: 0.004061684012413025
Checkpoint
2018-10-11 19:33:22.421564:	Training iteration: 114, Loss: 0.0061282990500330925
Checkpoint
2018-10-11 19:33:23.586463:	Training iteration: 115, Loss: 0.006021874025464058
Checkpoint
2018-10-11 19:33:24.750404:	Training iteration: 116, Loss: 0.005769185721874237
Checkpoint
2018-10-11 19:33:25.900483:	Training iteration: 117, Loss: 0.006898104213178158
Checkpoint
2018-10-11 19:33:27.061654:	Training iteration: 118, Loss: 0.0044054812751710415
Checkpoint
2018-10-11 19:33:28.468419:	Training iteration: 119, Loss: 0.005245601292699575
Checkpoint
2018-10-11 19:33:29.751389:	Training iteration: 120, Loss: 0.005392470862716436
Checkpoint
2018-10-11 19:33:30.985706:	Training iteration: 121, Loss: 0.005817322060465813
Checkpoint
2018-10-11 19:33:32.471288:	Training iteration: 122, Loss: 0.005552609451115131
Checkpoint
2018-10-11 19:37:01.032925:	Training iteration: 123, Loss: 0.003940226044505835
Checkpoint
