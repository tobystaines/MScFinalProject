INFO - UNet_Speech_Separation - Running command 'do_experiment'
INFO - UNet_Speech_Separation - Started run with ID "111"
Experiment ID: 111
Preparing dataset
Dataset ready
2018-10-11 13:46:28.422850: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-10-11 13:46:28.644720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-10-11 13:46:28.645215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:24:00.0
totalMemory: 10.92GiB freeMemory: 10.76GiB
2018-10-11 13:46:28.645233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:24:00.0, compute capability: 6.1)
Session started
run-start: run #1: 1 fetch (IteratorToStringHandle:0); 0 feeds

TTTTTT FFFF DDD  BBBB   GGG 
  TT   F    D  D B   B G    
  TT   FFF  D  D BBBB  G  GG
  TT   F    D  D B   B G   G
  TT   F    DDD  BBBB   GGG 

======================================
Session.run() call #1:

Fetch(es):
  IteratorToStringHandle:0

Feed dict:
  (Empty)
======================================

Select one of the following commands to proceed ---->
  run:
    Execute the run() call with debug tensor-watching
  run -n:
    Execute the run() call without debug tensor-watching
  run -t <T>:
    Execute run() calls (T - 1) times without debugging, then execute run() once more with debugging and drop back to the CLI
  run -f <filter_name>:
    Keep executing run() calls until a dumped tensor passes a given, registered filter (conditional breakpoint mode)
    Registered filter(s):
        * has_inf_or_nan
  invoke_stepper:
    Use the node-stepper interface, which allows you to interactively step through nodes involved in the graph run() call and inspect/modify their values

For more details, see help..


tfdbg> /home/enterprise.internal.city.ac.uk/acvn728/.local/lib/python3.5/site-packages/tensorflow/python/debug/lib/debug_data.py:225: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  elif (np.issubdtype(tensor.dtype, np.float) or
/home/enterprise.internal.city.ac.uk/acvn728/.local/lib/python3.5/site-packages/tensorflow/python/debug/lib/debug_data.py:226: FutureWarning: Conversion of the second argument of issubdtype from `complex` to `np.complexfloating` is deprecated. In future, it will be treated as `np.complex128 == np.dtype(complex).type`.
  np.issubdtype(tensor.dtype, np.complex) or
Iterators created
Creating model
Loading checkpoint
INFO:tensorflow:Restoring parameters from /home/enterprise.internal.city.ac.uk/acvn728/checkpoints/99/99-21000
INFO - tensorflow - Restoring parameters from /home/enterprise.internal.city.ac.uk/acvn728/checkpoints/99/99-21000
Starting training
2018-10-11 13:47:00.347527: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.354832: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.354842: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.356544: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.357189: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.358369: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.358410: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.359613: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.359663: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.359869: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.360060: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.360213: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.360236: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.361211: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.361473: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.361714: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.362007: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.362184: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.364796: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.366616: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.367849: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.367956: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.368039: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.368113: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.425970: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.427301: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.428538: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.429275: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.430065: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.430161: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.430176: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.430286: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.430372: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.430927: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.431717: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.432225: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.432735: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.432823: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.432900: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.432973: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.433050: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.433127: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.433201: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:00.433277: E tensorflow/core/kernels/dataset.cc:58] The Encode() method is not implemented for DatasetVariantWrapper objects.
2018-10-11 13:47:01.761631: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add/Enter_grad/b_acc_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761683: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761690: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761696: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761702: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/b_count_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761707: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/b_count_9" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761713: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/b_count_5" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761719: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761724: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761729: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_3_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761734: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_3_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761738: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_3_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761743: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_3_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761748: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Sum_1_grad/DynamicStitch/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761753: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Sum_1_grad/DynamicStitch/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761760: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_3_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761765: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_3_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761770: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_3_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761775: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_3_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761782: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_3_grad/mul/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761786: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_3_grad/mul/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761791: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Tile_grad/stack/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761795: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Tile_grad/stack/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761800: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/ExpandDims_grad/Reshape/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761804: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/ExpandDims_grad/Reshape/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761809: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_2_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761814: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_2_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761819: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_2_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761824: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_2_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761828: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_2_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761833: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_2_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761837: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_2_grad/mul/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761842: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_2_grad/mul/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761847: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_2_grad/mul_1/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761851: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_2_grad/mul_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761856: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761860: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761866: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761870: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761875: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_grad/RealDiv/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761880: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_grad/RealDiv/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761885: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_grad/Neg/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761889: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_grad/Neg/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761894: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_1_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761901: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_1_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761906: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_1_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761910: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_1_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761915: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_1_grad/RealDiv/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761919: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_1_grad/RealDiv/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761924: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_1_grad/Neg/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761928: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_1_grad/Neg/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761933: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_1_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761937: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_1_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761941: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_1_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761946: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_1_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761951: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_1_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761956: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_1_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761961: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/norm/Sum_grad/DynamicStitch/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761965: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/norm/Sum_grad/DynamicStitch/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761969: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/norm/mul_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761974: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/norm/mul_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761978: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/norm/mul_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761983: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/norm/mul_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761987: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761992: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.761997: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Sum_grad/DynamicStitch/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762002: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Sum_grad/DynamicStitch/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762006: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762011: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762016: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762020: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762025: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_grad/mul_1/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762029: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_grad/mul_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762034: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Reshape_1_grad/Reshape/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762039: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Reshape_1_grad/Reshape/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762044: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Softmax_grad/mul/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762051: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Softmax_grad/mul/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762056: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Reshape_grad/Reshape/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762060: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Reshape_grad/Reshape/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762065: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/TensorArrayWrite/TensorArrayWriteV3/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762069: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Enter_2" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762074: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762079: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/GreaterEqual/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762084: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/GreaterEqual_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762089: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/GreaterEqual_2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762093: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add/Enter_grad/b_acc_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762098: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762103: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762107: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_3_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762112: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_3_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762116: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_3_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762121: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_3_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762127: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Sum_1_grad/DynamicStitch/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762131: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Sum_1_grad/DynamicStitch/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762136: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762140: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762145: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762150: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762154: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/mul/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762159: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/mul/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762163: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Tile_grad/stack/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762168: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Tile_grad/stack/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762173: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/ExpandDims_grad/Reshape/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762177: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/ExpandDims_grad/Reshape/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762182: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762186: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762191: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762195: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762200: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762204: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762209: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/mul/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762214: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/mul/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762218: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/mul_1/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762223: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/mul_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762227: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762232: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762237: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762242: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762246: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/RealDiv/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762251: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/RealDiv/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762256: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/Neg/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762260: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/Neg/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762265: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762269: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762274: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762278: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762283: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/RealDiv/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762288: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/RealDiv/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762292: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/Neg/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762297: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/Neg/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762301: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762305: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762310: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762314: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762319: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762324: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762328: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/Sum_grad/DynamicStitch/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762333: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/Sum_grad/DynamicStitch/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762338: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762343: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762347: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762352: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762356: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762360: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762365: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Sum_grad/DynamicStitch/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762369: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Sum_grad/DynamicStitch/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762375: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762379: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762384: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762388: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762392: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/mul_1/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762397: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/mul_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762402: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Reshape_1_grad/Reshape/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762406: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Reshape_1_grad/Reshape/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762411: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/mul/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762416: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/mul/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762420: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Reshape_grad/Reshape/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762425: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Reshape_grad/Reshape/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762431: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add/Enter_grad/b_acc_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762441: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762447: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762451: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762456: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762461: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762466: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762471: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762476: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_1_grad/DynamicStitch/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762481: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_1_grad/DynamicStitch/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762486: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762490: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762495: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762499: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762504: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/mul/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762509: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/mul/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762513: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Tile_grad/stack/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762517: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Tile_grad/stack/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762522: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/ExpandDims_grad/Reshape/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762526: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/ExpandDims_grad/Reshape/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762531: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_2_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762536: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_2_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762540: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762545: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762550: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762555: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762559: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762564: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762568: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul_1/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762573: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762577: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762582: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762586: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762591: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762596: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/RealDiv/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762601: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/RealDiv/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762605: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Neg/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762610: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Neg/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762614: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762619: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762624: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.762628: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.783911: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/RealDiv/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.783925: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/RealDiv/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.783931: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Neg/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.783938: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Neg/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.783944: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.783950: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.783956: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.783961: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.783967: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.783974: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.783980: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/Sum_grad/DynamicStitch/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.783986: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/Sum_grad/DynamicStitch/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.783992: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.783998: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784003: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784009: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784014: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784020: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784037: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_grad/DynamicStitch/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784044: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_grad/DynamicStitch/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784049: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/BroadcastGradientArgs/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784055: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/BroadcastGradientArgs/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784061: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/BroadcastGradientArgs/StackPopV2_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784067: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/BroadcastGradientArgs/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784072: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/mul_1/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784078: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/mul_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784083: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Reshape_1_grad/Reshape/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784093: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Reshape_1_grad/Reshape/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784098: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/mul/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784104: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/mul/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784110: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Reshape_grad/Reshape/StackPopV2/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784115: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Reshape_grad/Reshape/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784121: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/TensorArrayWrite/TensorArrayWriteV3/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784127: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Enter_2" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784132: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.784138: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/TensorArrayWrite/TensorArrayWriteV3/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803414: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Enter_2" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803428: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803435: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Exit_2_grad/b_exit" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803442: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803448: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803453: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803460: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Exit_1_grad/b_exit" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803465: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803471: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803477: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/mul/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803484: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul/Enter_grad/b_acc" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803490: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/mul_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803496: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3/Enter_grad/b_acc" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803502: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Exit_2_grad/b_exit" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803507: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803516: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/mul/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803521: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul/Enter_grad/b_acc" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803527: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803532: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/mul_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803538: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3/Enter_grad/b_acc" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803544: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803550: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Exit_1_grad/b_exit" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803557: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Exit_2_grad/b_exit" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803562: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Enter_1" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803568: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Exit_1_grad/b_exit" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803574: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_3/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803579: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803586: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_grad/mul/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803591: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul/Enter_grad/b_acc" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803597: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_3_grad/mul_1/Enter" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:01.803604: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node "Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_3/Enter_grad/b_acc" on device "/job:localhost/replica:0/task:0/device:GPU:0" from 10 to 1. (This does not affect subsequent non-debug runs.)
2018-10-11 13:47:12.175302: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 983 of 1000
2018-10-11 13:47:12.248867: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
/home/enterprise.internal.city.ac.uk/acvn728/.local/lib/python3.5/site-packages/tensorflow/python/debug/lib/debug_data.py:225: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  elif (np.issubdtype(tensor.dtype, np.float) or
/home/enterprise.internal.city.ac.uk/acvn728/.local/lib/python3.5/site-packages/tensorflow/python/debug/lib/debug_data.py:226: FutureWarning: Conversion of the second argument of issubdtype from `complex` to `np.complexfloating` is deprecated. In future, it will be treated as `np.complex128 == np.dtype(complex).type`.
  np.issubdtype(tensor.dtype, np.complex) or
2018-10-11 13:50:24.694374:	Training iteration: 1, Loss: 0.0068901823833584785
2018-10-11 13:53:32.284731:	Training iteration: 2, Loss: 0.00619416031986475
2018-10-11 13:56:42.770583:	Training iteration: 3, Loss: 0.005042244680225849
2018-10-11 13:59:51.604021:	Training iteration: 4, Loss: 0.00673674326390028
2018-10-11 14:02:57.026708:	Training iteration: 5, Loss: 0.005616375710815191
2018-10-11 14:06:10.865957:	Training iteration: 6, Loss: 0.0057152034714818
2018-10-11 14:09:19.455747:	Training iteration: 7, Loss: 0.006305675022304058
2018-10-11 14:12:27.413365:	Training iteration: 8, Loss: 0.004779686685651541
2018-10-11 14:15:36.392623:	Training iteration: 9, Loss: 0.006538388319313526
2018-10-11 14:18:46.100660:	Training iteration: 10, Loss: 0.005121248308569193
2018-10-11 14:21:54.856611:	Training iteration: 11, Loss: 0.005760574247688055
2018-10-11 14:25:01.781117:	Training iteration: 12, Loss: 0.004425305873155594
2018-10-11 14:28:09.022780:	Training iteration: 13, Loss: 0.00601725559681654
2018-10-11 14:31:15.910137:	Training iteration: 14, Loss: 0.006029871758073568
2018-10-11 14:34:22.549681:	Training iteration: 15, Loss: 0.004426266066730022
2018-10-11 14:37:30.001917:	Training iteration: 16, Loss: 0.0074720741249620914
2018-10-11 14:40:33.364637:	Training iteration: 17, Loss: 0.005727135576307774
2018-10-11 14:43:38.055995:	Training iteration: 18, Loss: 0.004782537464052439
2018-10-11 14:46:43.898096:	Training iteration: 19, Loss: 0.005182293243706226
2018-10-11 14:49:48.173128:	Training iteration: 20, Loss: 0.004928217269480228
2018-10-11 14:52:54.850496:	Training iteration: 21, Loss: 0.0050192843191325665
2018-10-11 14:55:59.602093:	Training iteration: 22, Loss: 0.003871391760185361
2018-10-11 14:59:06.729720:	Training iteration: 23, Loss: 0.00849846936762333
2018-10-11 15:02:10.318734:	Training iteration: 24, Loss: 0.0045626224018633366
2018-10-11 15:05:15.738376:	Training iteration: 25, Loss: 0.005658985581248999
2018-10-11 15:08:21.359018:	Training iteration: 26, Loss: 0.004598569590598345
2018-10-11 15:11:25.314115:	Training iteration: 27, Loss: 0.004908466245979071
2018-10-11 15:14:30.927489:	Training iteration: 28, Loss: 0.006583834998309612
2018-10-11 15:17:36.001706:	Training iteration: 29, Loss: 0.00558375334367156
2018-10-11 15:20:39.506433:	Training iteration: 30, Loss: 0.007324498146772385
2018-10-11 15:23:43.244506:	Training iteration: 31, Loss: 0.006304423324763775
2018-10-11 15:26:47.267411:	Training iteration: 32, Loss: 0.006144061218947172
2018-10-11 15:29:52.651734:	Training iteration: 33, Loss: 0.003870603395625949
2018-10-11 15:32:57.897142:	Training iteration: 34, Loss: 0.006481497548520565
2018-10-11 15:36:04.063116:	Training iteration: 35, Loss: 0.00621627364307642
2018-10-11 15:39:08.563560:	Training iteration: 36, Loss: 0.005211895797401667
2018-10-11 15:42:13.835187:	Training iteration: 37, Loss: 0.005540435668081045
2018-10-11 15:45:21.276608:	Training iteration: 38, Loss: 0.005093345884233713
2018-10-11 15:48:26.776329:	Training iteration: 39, Loss: 0.006040970794856548
2018-10-11 15:51:33.351056:	Training iteration: 40, Loss: 0.004127658903598785
2018-10-11 15:54:39.910883:	Training iteration: 41, Loss: 0.0062552643939852715
2018-10-11 15:57:44.118148:	Training iteration: 42, Loss: 0.004931914620101452
2018-10-11 16:00:48.213793:	Training iteration: 43, Loss: 0.004221191629767418
2018-10-11 16:03:52.834495:	Training iteration: 44, Loss: 0.006038781255483627
2018-10-11 16:06:59.141538:	Training iteration: 45, Loss: 0.005043724086135626
2018-10-11 16:10:05.372728:	Training iteration: 46, Loss: 0.004549307283014059
2018-10-11 16:13:11.893774:	Training iteration: 47, Loss: 0.004840114153921604
2018-10-11 16:16:19.032790:	Training iteration: 48, Loss: 0.005088059697300196
2018-10-11 16:19:23.583453:	Training iteration: 49, Loss: 0.005120526533573866
2018-10-11 16:22:28.197596:	Training iteration: 50, Loss: 0.00591152161359787
2018-10-11 16:25:33.204437:	Training iteration: 51, Loss: 0.006321843713521957
2018-10-11 16:28:36.967939:	Training iteration: 52, Loss: 0.005099628120660782
2018-10-11 16:31:41.010216:	Training iteration: 53, Loss: 0.005272349808365107
2018-10-11 16:34:44.685446:	Training iteration: 54, Loss: 0.0058451006188988686
2018-10-11 16:37:50.424889:	Training iteration: 55, Loss: 0.004432555753737688
2018-10-11 16:40:56.236982:	Training iteration: 56, Loss: 0.00535814743489027
2018-10-11 16:44:00.661755:	Training iteration: 57, Loss: 0.00512584438547492
2018-10-11 16:47:06.403938:	Training iteration: 58, Loss: 0.005074260290712118
2018-10-11 16:50:12.136524:	Training iteration: 59, Loss: 0.004693871829658747
2018-10-11 16:53:17.972816:	Training iteration: 60, Loss: 0.004969400353729725
2018-10-11 16:56:24.171935:	Training iteration: 61, Loss: 0.004694562871009111
2018-10-11 16:59:29.961946:	Training iteration: 62, Loss: 0.005197306629270315
2018-10-11 17:02:36.493990:	Training iteration: 63, Loss: 0.006266586482524872
2018-10-11 17:05:42.352630:	Training iteration: 64, Loss: 0.004489641636610031
2018-10-11 17:08:47.517830:	Training iteration: 65, Loss: 0.005387325771152973
2018-10-11 17:11:52.272988:	Training iteration: 66, Loss: 0.0037266425788402557
2018-10-11 17:14:55.450246:	Training iteration: 67, Loss: 0.004948968533426523
2018-10-11 17:18:00.194810:	Training iteration: 68, Loss: 0.00625113258138299
2018-10-11 17:21:04.681113:	Training iteration: 69, Loss: 0.0077361660078167915
2018-10-11 17:24:10.927758:	Training iteration: 70, Loss: 0.005665951408445835
2018-10-11 17:27:16.974252:	Training iteration: 71, Loss: 0.004594710655510426
2018-10-11 17:30:22.290306:	Training iteration: 72, Loss: 0.004528134595602751
2018-10-11 17:33:28.439991:	Training iteration: 73, Loss: 0.004749901592731476
2018-10-11 17:36:36.705895:	Training iteration: 74, Loss: 0.006334599107503891
2018-10-11 17:39:41.897306:	Training iteration: 75, Loss: 0.008441342040896416
2018-10-11 17:42:46.339042:	Training iteration: 76, Loss: 0.006314513273537159
2018-10-11 17:45:51.583254:	Training iteration: 77, Loss: 0.0050300369039177895
2018-10-11 17:48:55.686924:	Training iteration: 78, Loss: 0.005029217805713415
2018-10-11 17:51:59.824451:	Training iteration: 79, Loss: 0.003975606057792902
2018-10-11 17:55:04.111615:	Training iteration: 80, Loss: 0.00401044636964798
2018-10-11 17:58:08.130146:	Training iteration: 81, Loss: 0.004366129636764526
2018-10-11 18:01:12.797394:	Training iteration: 82, Loss: 0.006638639606535435
2018-10-11 18:04:18.778048:	Training iteration: 83, Loss: 0.005986946634948254
2018-10-11 18:07:23.588332:	Training iteration: 84, Loss: 0.005546480882912874
2018-10-11 18:10:28.201786:	Training iteration: 85, Loss: 0.004642000887542963
2018-10-11 18:13:32.747726:	Training iteration: 86, Loss: 0.004745923914015293
2018-10-11 18:16:38.694999:	Training iteration: 87, Loss: 0.006263901945203543
2018-10-11 18:19:42.392334:	Training iteration: 88, Loss: 0.005177342798560858
2018-10-11 18:22:48.071708:	Training iteration: 89, Loss: 0.003569339867681265
2018-10-11 18:25:54.350890:	Training iteration: 90, Loss: 0.005814036820083857
2018-10-11 18:28:59.610097:	Training iteration: 91, Loss: 0.0041830530390143394
2018-10-11 18:32:05.144643:	Training iteration: 92, Loss: 0.006678922567516565
2018-10-11 18:35:11.006354:	Training iteration: 93, Loss: 0.006978221237659454
2018-10-11 18:38:15.061035:	Training iteration: 94, Loss: 0.003968427889049053
2018-10-11 18:41:19.451603:	Training iteration: 95, Loss: 0.006806506309658289
2018-10-11 18:44:23.751319:	Training iteration: 96, Loss: 0.005792370066046715
2018-10-11 18:47:30.148016:	Training iteration: 97, Loss: 0.004391807597130537
2018-10-11 18:50:35.744461:	Training iteration: 98, Loss: 0.004934676922857761
2018-10-11 18:53:40.188116:	Training iteration: 99, Loss: 0.006277434527873993
2018-10-11 18:56:44.609778:	Training iteration: 100, Loss: 0.003659436944872141
2018-10-11 18:59:49.964380:	Training iteration: 101, Loss: 0.005266728810966015
2018-10-11 19:02:56.063321:	Training iteration: 102, Loss: 0.00549256382510066
2018-10-11 19:06:02.217568:	Training iteration: 103, Loss: 0.005183066241443157
2018-10-11 19:09:06.731541:	Training iteration: 104, Loss: 0.004885015543550253
2018-10-11 19:12:10.735435:	Training iteration: 105, Loss: 0.004984638653695583
2018-10-11 19:15:15.791669:	Training iteration: 106, Loss: 0.006195415277034044
2018-10-11 19:18:21.175026:	Training iteration: 107, Loss: 0.005774574354290962
2018-10-11 19:21:25.043276:	Training iteration: 108, Loss: 0.003941582050174475
2018-10-11 19:24:15.543722:	Training iteration: 109, Loss: 0.0057311030104756355
2018-10-11 19:26:26.744461:	Training iteration: 110, Loss: 0.006848818622529507
2018-10-11 19:28:26.189996:	Training iteration: 111, Loss: 0.004952157381922007
2018-10-11 19:30:34.574006:	Training iteration: 112, Loss: 0.006150989793241024
2018-10-11 19:32:41.067027:	Training iteration: 113, Loss: 0.006570148281753063
2018-10-11 19:34:43.400541:	Training iteration: 114, Loss: 0.006007669027894735
2018-10-11 19:50:42.749797:	Training iteration: 115, Loss: 0.005352369509637356
2018-10-11 19:52:39.637997:	Training iteration: 116, Loss: 0.005575890652835369
2018-10-11 19:54:37.299072:	Training iteration: 117, Loss: 0.007332394365221262
2018-10-11 19:56:35.951655:	Training iteration: 118, Loss: 0.0037961278576403856
2018-10-11 19:58:32.136808:	Training iteration: 119, Loss: 0.005158009938895702
2018-10-11 20:00:28.958415:	Training iteration: 120, Loss: 0.005291464738547802
2018-10-11 20:02:27.117217:	Training iteration: 121, Loss: 0.005149556789547205
2018-10-11 20:04:25.140486:	Training iteration: 122, Loss: 0.0048409393057227135
2018-10-11 20:06:20.760069:	Training iteration: 123, Loss: 0.004477605223655701
2018-10-11 20:08:16.287311:	Training iteration: 124, Loss: 0.005304090213030577
2018-10-11 20:10:14.128667:	Training iteration: 125, Loss: 0.006290399935096502
2018-10-11 20:12:10.248674:	Training iteration: 126, Loss: 0.004416133277118206
2018-10-11 20:14:05.207453:	Training iteration: 127, Loss: 0.003509757574647665
2018-10-11 20:16:03.520429:	Training iteration: 128, Loss: 0.0040340363048017025
2018-10-11 20:17:59.437211:	Training iteration: 129, Loss: 0.0056409225799143314
2018-10-11 20:20:00.994683:	Training iteration: 130, Loss: 0.005106110591441393
2018-10-11 20:21:56.907823:	Training iteration: 131, Loss: 0.005812422838062048
2018-10-11 20:23:57.019414:	Training iteration: 132, Loss: 0.005140166729688644
2018-10-11 20:26:08.588874:	Training iteration: 133, Loss: 0.004729502834379673
2018-10-11 20:28:19.799671:	Training iteration: 134, Loss: 0.0048964014276862144
2018-10-11 20:30:31.561394:	Training iteration: 135, Loss: 0.007469291798770428
2018-10-11 20:32:45.220955:	Training iteration: 136, Loss: 0.004295381251722574
2018-10-11 20:34:55.155940:	Training iteration: 137, Loss: 0.006417234428226948
2018-10-11 20:37:06.954799:	Training iteration: 138, Loss: 0.00556398369371891
2018-10-11 20:39:22.415928:	Training iteration: 139, Loss: 0.004768492188304663
2018-10-11 20:41:33.333536:	Training iteration: 140, Loss: 0.006658508442342281
2018-10-11 20:43:44.693098:	Training iteration: 141, Loss: 0.006863058544695377
2018-10-11 20:45:55.999661:	Training iteration: 142, Loss: 0.004827623721212149
2018-10-11 20:48:09.962559:	Training iteration: 143, Loss: 0.004361582454293966
2018-10-11 20:50:22.379876:	Training iteration: 144, Loss: 0.003306538565084338
2018-10-11 20:52:35.184360:	Training iteration: 145, Loss: 0.005199767649173737
2018-10-11 20:54:48.728524:	Training iteration: 146, Loss: 0.004081633407622576
2018-10-11 20:56:48.844607:	Training iteration: 147, Loss: 0.004949958063662052
2018-10-11 20:58:40.534740:	Training iteration: 148, Loss: 0.004852538462728262
2018-10-11 21:00:31.046996:	Training iteration: 149, Loss: 0.006011439021676779
2018-10-11 21:02:20.131252:	Training iteration: 150, Loss: 0.005000808276236057
2018-10-11 21:04:11.415729:	Training iteration: 151, Loss: 0.004140055272728205
2018-10-11 21:06:00.084681:	Training iteration: 152, Loss: 0.006287971045821905
2018-10-11 21:07:53.524960:	Training iteration: 153, Loss: 0.006576165556907654
2018-10-11 21:09:47.674142:	Training iteration: 154, Loss: 0.004082728177309036
2018-10-11 21:11:41.622239:	Training iteration: 155, Loss: 0.0038035870529711246
2018-10-11 21:13:34.719799:	Training iteration: 156, Loss: 0.004991776775568724
2018-10-11 21:15:28.586852:	Training iteration: 157, Loss: 0.005755152553319931
2018-10-11 21:17:23.258165:	Training iteration: 158, Loss: 0.006110771093517542
2018-10-11 21:19:15.808062:	Training iteration: 159, Loss: 0.00659180898219347
2018-10-11 21:21:08.775086:	Training iteration: 160, Loss: 0.006658108439296484
2018-10-11 21:23:03.163837:	Training iteration: 161, Loss: 0.005452284123748541
2018-10-11 21:24:54.814313:	Training iteration: 162, Loss: 0.004925163928419352
2018-10-11 21:26:46.819276:	Training iteration: 163, Loss: 0.006475751753896475
2018-10-11 21:28:39.320929:	Training iteration: 164, Loss: 0.004191511310636997
2018-10-11 21:30:33.226345:	Training iteration: 165, Loss: 0.004837490618228912
2018-10-11 21:32:26.055809:	Training iteration: 166, Loss: 0.004087991081178188
2018-10-11 21:34:20.847813:	Training iteration: 167, Loss: 0.0038396306335926056
2018-10-11 21:36:13.499061:	Training iteration: 168, Loss: 0.006295019295066595
2018-10-11 21:38:05.935658:	Training iteration: 169, Loss: 0.005044109188020229
2018-10-11 21:40:01.644400:	Training iteration: 170, Loss: 0.004779417999088764
2018-10-11 21:41:55.330764:	Training iteration: 171, Loss: 0.0066026924178004265
2018-10-11 21:43:49.447935:	Training iteration: 172, Loss: 0.005576056428253651
2018-10-11 21:45:39.847280:	Training iteration: 173, Loss: 0.005096862092614174
2018-10-11 21:47:33.180811:	Training iteration: 174, Loss: 0.005749849136918783
2018-10-11 21:49:25.208936:	Training iteration: 175, Loss: 0.006762849632650614
2018-10-11 21:51:19.514167:	Training iteration: 176, Loss: 0.006461843848228455
2018-10-11 21:53:09.689425:	Training iteration: 177, Loss: 0.00554489204660058
2018-10-11 21:54:59.873445:	Training iteration: 178, Loss: 0.00639496510848403
2018-10-11 21:56:50.655853:	Training iteration: 179, Loss: 0.004417708609253168
2018-10-11 21:58:41.439336:	Training iteration: 180, Loss: 0.0053272549994289875
2018-10-11 22:00:33.183922:	Training iteration: 181, Loss: 0.004134883172810078
2018-10-11 22:02:26.485550:	Training iteration: 182, Loss: 0.005490329582244158
2018-10-11 22:04:18.338822:	Training iteration: 183, Loss: 0.005572418216615915
2018-10-11 22:06:06.436690:	Training iteration: 184, Loss: 0.005376200191676617
2018-10-11 22:08:01.655867:	Training iteration: 185, Loss: 0.004294381011277437
2018-10-11 22:09:55.532354:	Training iteration: 186, Loss: 0.005490916781127453
2018-10-11 22:11:48.837628:	Training iteration: 187, Loss: 0.004829929210245609
2018-10-11 22:13:44.039790:	Training iteration: 188, Loss: 0.005290723405778408
2018-10-11 22:15:39.778322:	Training iteration: 189, Loss: 0.007071046624332666
2018-10-11 22:17:36.734717:	Training iteration: 190, Loss: 0.006258056499063969
2018-10-11 22:19:51.148174:	Training iteration: 191, Loss: 0.005053145810961723
2018-10-11 22:22:59.491686:	Training iteration: 192, Loss: 0.004687168635427952
2018-10-11 22:26:05.608757:	Training iteration: 193, Loss: 0.005987853743135929
2018-10-11 22:29:12.288478:	Training iteration: 194, Loss: 0.005622311029583216
2018-10-11 22:32:19.304910:	Training iteration: 195, Loss: 0.004136658273637295
2018-10-11 22:35:25.140032:	Training iteration: 196, Loss: 0.0033291466534137726
2018-10-11 22:38:30.532333:	Training iteration: 197, Loss: 0.005776846315711737
2018-10-11 22:41:37.438479:	Training iteration: 198, Loss: 0.006947131361812353
2018-10-11 22:44:44.018787:	Training iteration: 199, Loss: 0.007420643232762814
2018-10-11 22:47:48.999495:	Training iteration: 200, Loss: 0.005492239724844694
2018-10-11 22:50:56.045698:	Training iteration: 201, Loss: 0.0068307435140013695
2018-10-11 22:54:02.328490:	Training iteration: 202, Loss: 0.0044307163916528225
2018-10-11 22:57:07.813313:	Training iteration: 203, Loss: 0.005405799485743046
2018-10-11 23:00:15.399335:	Training iteration: 204, Loss: 0.004866007715463638
2018-10-11 23:03:20.822409:	Training iteration: 205, Loss: 0.004702433943748474
2018-10-11 23:06:26.515390:	Training iteration: 206, Loss: 0.005802631378173828
2018-10-11 23:09:32.614651:	Training iteration: 207, Loss: 0.005278393626213074
2018-10-11 23:12:38.625750:	Training iteration: 208, Loss: 0.005293057765811682
2018-10-11 23:15:46.188447:	Training iteration: 209, Loss: 0.005278870463371277
2018-10-11 23:18:51.737836:	Training iteration: 210, Loss: 0.005840112920850515
2018-10-11 23:21:56.007114:	Training iteration: 211, Loss: 0.005883463192731142
2018-10-11 23:25:02.532485:	Training iteration: 212, Loss: 0.004927994683384895
2018-10-11 23:28:09.018553:	Training iteration: 213, Loss: 0.006394130643457174
2018-10-11 23:31:13.209009:	Training iteration: 214, Loss: 0.004868494812399149
2018-10-11 23:34:19.137590:	Training iteration: 215, Loss: 0.004781135357916355
2018-10-11 23:37:25.978478:	Training iteration: 216, Loss: 0.005322122015058994
2018-10-11 23:40:30.911609:	Training iteration: 217, Loss: 0.005883346311748028
2018-10-11 23:43:37.089392:	Training iteration: 218, Loss: 0.00474060233682394
2018-10-11 23:46:44.752868:	Training iteration: 219, Loss: 0.004538069013506174
2018-10-11 23:49:50.392274:	Training iteration: 220, Loss: 0.005363316275179386
2018-10-11 23:52:55.909521:	Training iteration: 221, Loss: 0.004974390380084515
2018-10-11 23:56:01.681332:	Training iteration: 222, Loss: 0.004690092988312244
2018-10-11 23:59:07.402791:	Training iteration: 223, Loss: 0.005451079457998276
2018-10-12 00:02:12.937207:	Training iteration: 224, Loss: 0.005132295191287994
2018-10-12 00:05:19.045714:	Training iteration: 225, Loss: 0.008080631494522095
2018-10-12 00:08:24.713803:	Training iteration: 226, Loss: 0.005293881054967642
2018-10-12 00:11:30.828549:	Training iteration: 227, Loss: 0.004801548086106777
2018-10-12 00:14:36.721178:	Training iteration: 228, Loss: 0.005757587496191263
2018-10-12 00:17:42.552718:	Training iteration: 229, Loss: 0.005313407629728317
2018-10-12 00:20:48.314259:	Training iteration: 230, Loss: 0.006682589650154114
2018-10-12 00:23:53.780585:	Training iteration: 231, Loss: 0.004717007279396057
2018-10-12 00:27:00.522921:	Training iteration: 232, Loss: 0.007013845257461071
2018-10-12 00:30:04.590952:	Training iteration: 233, Loss: 0.006055784411728382
2018-10-12 00:33:11.126308:	Training iteration: 234, Loss: 0.004818257875740528
2018-10-12 00:36:17.100622:	Training iteration: 235, Loss: 0.004286732990294695
2018-10-12 00:39:23.727266:	Training iteration: 236, Loss: 0.0051239123567938805
2018-10-12 00:42:30.423605:	Training iteration: 237, Loss: 0.006654625292867422
2018-10-12 00:45:36.757905:	Training iteration: 238, Loss: 0.0049094222486019135
2018-10-12 00:48:41.928658:	Training iteration: 239, Loss: 0.005280476063489914
2018-10-12 00:51:48.235585:	Training iteration: 240, Loss: 0.005910275969654322
2018-10-12 00:54:53.742247:	Training iteration: 241, Loss: 0.004778057336807251
2018-10-12 00:57:58.840113:	Training iteration: 242, Loss: 0.005329278763383627
2018-10-12 01:01:05.032994:	Training iteration: 243, Loss: 0.005564653314650059
2018-10-12 01:04:11.048854:	Training iteration: 244, Loss: 0.004278031177818775
2018-10-12 01:07:18.681379:	Training iteration: 245, Loss: 0.004082197789102793
2018-10-12 01:10:24.726428:	Training iteration: 246, Loss: 0.005227998830378056
2018-10-12 01:13:31.133458:	Training iteration: 247, Loss: 0.007547174580395222
2018-10-12 01:16:38.666181:	Training iteration: 248, Loss: 0.004441994708031416
2018-10-12 01:19:44.561468:	Training iteration: 249, Loss: 0.005430956371128559
2018-10-12 01:22:50.829096:	Training iteration: 250, Loss: 0.004729700740426779
2018-10-12 01:25:57.028460:	Training iteration: 251, Loss: 0.005364240612834692
2018-10-12 01:29:02.491560:	Training iteration: 252, Loss: 0.003813092363998294
2018-10-12 01:32:08.380616:	Training iteration: 253, Loss: 0.0056653739884495735
2018-10-12 01:35:14.107854:	Training iteration: 254, Loss: 0.005314393900334835
2018-10-12 01:38:20.411343:	Training iteration: 255, Loss: 0.006021329201757908
2018-10-12 01:41:26.781370:	Training iteration: 256, Loss: 0.006573242135345936
2018-10-12 01:44:31.619543:	Training iteration: 257, Loss: 0.00400394294410944
2018-10-12 01:47:36.062176:	Training iteration: 258, Loss: 0.0053366972133517265
2018-10-12 01:50:41.177954:	Training iteration: 259, Loss: 0.005978933069854975
2018-10-12 01:53:47.129909:	Training iteration: 260, Loss: 0.0043545374646782875
2018-10-12 01:56:52.619458:	Training iteration: 261, Loss: 0.00445376243442297
2018-10-12 01:59:58.608330:	Training iteration: 262, Loss: 0.005021463613957167
2018-10-12 02:03:04.813548:	Training iteration: 263, Loss: 0.0049552167765796185
2018-10-12 02:06:10.991122:	Training iteration: 264, Loss: 0.004651413299143314
2018-10-12 02:09:15.713258:	Training iteration: 265, Loss: 0.0064138262532651424
2018-10-12 02:12:22.421629:	Training iteration: 266, Loss: 0.0038135084323585033
2018-10-12 02:15:27.571693:	Training iteration: 267, Loss: 0.006494896020740271
2018-10-12 02:18:34.812828:	Training iteration: 268, Loss: 0.004579006228595972
2018-10-12 02:21:41.023801:	Training iteration: 269, Loss: 0.0036720745265483856
2018-10-12 02:24:46.814899:	Training iteration: 270, Loss: 0.006778390612453222
2018-10-12 02:27:53.620390:	Training iteration: 271, Loss: 0.004396354779601097
2018-10-12 02:31:00.796873:	Training iteration: 272, Loss: 0.0048646642826497555
2018-10-12 02:34:04.993323:	Training iteration: 273, Loss: 0.005064745899289846
2018-10-12 02:37:10.452247:	Training iteration: 274, Loss: 0.005877105053514242
2018-10-12 02:40:16.789180:	Training iteration: 275, Loss: 0.005374508909881115
2018-10-12 02:43:21.082987:	Training iteration: 276, Loss: 0.005634050816297531
2018-10-12 02:46:24.924379:	Training iteration: 277, Loss: 0.007961745373904705
2018-10-12 02:49:32.560808:	Training iteration: 278, Loss: 0.00583267118781805
2018-10-12 02:52:40.113030:	Training iteration: 279, Loss: 0.0038448520936071873
2018-10-12 02:55:44.153471:	Training iteration: 280, Loss: 0.0039245327934622765
2018-10-12 02:58:48.284793:	Training iteration: 281, Loss: 0.004975050687789917
2018-10-12 03:01:55.122523:	Training iteration: 282, Loss: 0.00423783902078867
2018-10-12 03:05:01.437975:	Training iteration: 283, Loss: 0.004290343727916479
2018-10-12 03:08:08.805080:	Training iteration: 284, Loss: 0.004960169550031424
2018-10-12 03:11:15.519188:	Training iteration: 285, Loss: 0.005880303680896759
2018-10-12 03:14:22.918432:	Training iteration: 286, Loss: 0.005040341522544622
2018-10-12 03:17:31.009304:	Training iteration: 287, Loss: 0.004820581991225481
2018-10-12 03:20:37.975631:	Training iteration: 288, Loss: 0.003741257591173053
2018-10-12 03:23:44.439283:	Training iteration: 289, Loss: 0.005051933228969574
2018-10-12 03:26:50.246555:	Training iteration: 290, Loss: 0.0047925799153745174
2018-10-12 03:29:55.671190:	Training iteration: 291, Loss: 0.004500103648751974
2018-10-12 03:33:02.697513:	Training iteration: 292, Loss: 0.005964139010757208
2018-10-12 03:36:08.494740:	Training iteration: 293, Loss: 0.006749308668076992
2018-10-12 03:39:14.854546:	Training iteration: 294, Loss: 0.005541280843317509
2018-10-12 03:42:21.783162:	Training iteration: 295, Loss: 0.004206907469779253
2018-10-12 03:45:32.526509:	Training iteration: 296, Loss: 0.004881409928202629
2018-10-12 03:48:42.017409:	Training iteration: 297, Loss: 0.005319977644830942
2018-10-12 03:51:48.440759:	Training iteration: 298, Loss: 0.005623658653348684
2018-10-12 03:54:55.326942:	Training iteration: 299, Loss: 0.007089571096003056
2018-10-12 03:58:01.186144:	Training iteration: 300, Loss: 0.00503214355558157
2018-10-12 04:01:06.559928:	Training iteration: 301, Loss: 0.005537660792469978
2018-10-12 04:04:11.859778:	Training iteration: 302, Loss: 0.00525434035807848
2018-10-12 04:07:18.854946:	Training iteration: 303, Loss: 0.006507108453661203
2018-10-12 04:10:23.847017:	Training iteration: 304, Loss: 0.0071853152476251125
2018-10-12 04:13:30.508668:	Training iteration: 305, Loss: 0.004070279188454151
2018-10-12 04:16:37.541558:	Training iteration: 306, Loss: 0.005542059428989887
2018-10-12 04:19:43.612234:	Training iteration: 307, Loss: 0.006158323492854834
2018-10-12 04:22:48.199202:	Training iteration: 308, Loss: 0.00470203161239624
2018-10-12 04:25:54.777858:	Training iteration: 309, Loss: 0.004405593499541283
2018-10-12 04:29:00.282600:	Training iteration: 310, Loss: 0.006166869308799505
2018-10-12 04:32:07.012711:	Training iteration: 311, Loss: 0.00828203558921814
2018-10-12 04:35:13.793860:	Training iteration: 312, Loss: 0.005841401405632496
2018-10-12 04:38:20.539045:	Training iteration: 313, Loss: 0.004822194576263428
2018-10-12 04:41:27.549423:	Training iteration: 314, Loss: 0.005919069983065128
2018-10-12 04:44:32.215994:	Training iteration: 315, Loss: 0.0051038553938269615
2018-10-12 04:47:37.493309:	Training iteration: 316, Loss: 0.005750707350671291
2018-10-12 04:50:43.975591:	Training iteration: 317, Loss: 0.005450237542390823
2018-10-12 04:53:49.845279:	Training iteration: 318, Loss: 0.00756898382678628
2018-10-12 04:56:55.626728:	Training iteration: 319, Loss: 0.005251503549516201
2018-10-12 05:00:02.109165:	Training iteration: 320, Loss: 0.0038704336620867252
2018-10-12 05:03:08.351284:	Training iteration: 321, Loss: 0.005760307423770428
2018-10-12 05:06:16.611474:	Training iteration: 322, Loss: 0.006688127759844065
2018-10-12 05:09:24.778621:	Training iteration: 323, Loss: 0.00437321700155735
2018-10-12 05:12:29.830530:	Training iteration: 324, Loss: 0.0056776078417897224
2018-10-12 05:15:35.380993:	Training iteration: 325, Loss: 0.005674007348716259
2018-10-12 05:18:42.849487:	Training iteration: 326, Loss: 0.00637729000300169
2018-10-12 05:21:48.411741:	Training iteration: 327, Loss: 0.0053213126957416534
2018-10-12 05:24:54.177056:	Training iteration: 328, Loss: 0.004568336997181177
2018-10-12 05:28:00.117904:	Training iteration: 329, Loss: 0.0037744143046438694
2018-10-12 05:31:05.306504:	Training iteration: 330, Loss: 0.004226001910865307
2018-10-12 05:34:11.743519:	Training iteration: 331, Loss: 0.00571715971454978
2018-10-12 05:37:17.349549:	Training iteration: 332, Loss: 0.00493157934397459
2018-10-12 05:40:21.777277:	Training iteration: 333, Loss: 0.0034080077894032
2018-10-12 05:43:28.030109:	Training iteration: 334, Loss: 0.0043563456274569035
2018-10-12 05:46:35.020725:	Training iteration: 335, Loss: 0.007254471071064472
2018-10-12 05:49:40.610513:	Training iteration: 336, Loss: 0.003990584518760443
2018-10-12 05:52:46.944037:	Training iteration: 337, Loss: 0.005068683065474033
2018-10-12 05:55:53.400037:	Training iteration: 338, Loss: 0.005381087306886911
2018-10-12 05:58:59.178990:	Training iteration: 339, Loss: 0.006163143087178469
2018-10-12 06:02:05.318932:	Training iteration: 340, Loss: 0.005402948707342148
2018-10-12 06:05:12.563813:	Training iteration: 341, Loss: 0.006036477629095316
2018-10-12 06:08:17.170788:	Training iteration: 342, Loss: 0.005245153792202473
2018-10-12 06:11:23.516993:	Training iteration: 343, Loss: 0.004697701428085566
2018-10-12 06:14:28.074223:	Training iteration: 344, Loss: 0.00644370773807168
2018-10-12 06:17:34.323566:	Training iteration: 345, Loss: 0.005765547510236502
2018-10-12 06:20:39.159192:	Training iteration: 346, Loss: 0.00497813057154417
2018-10-12 06:23:45.929982:	Training iteration: 347, Loss: 0.0039378078654408455
2018-10-12 06:26:52.676525:	Training iteration: 348, Loss: 0.003985769115388393
2018-10-12 06:29:59.555465:	Training iteration: 349, Loss: 0.00627604266628623
2018-10-12 06:33:05.637733:	Training iteration: 350, Loss: 0.005356288980692625
2018-10-12 06:36:11.659318:	Training iteration: 351, Loss: 0.005685160402208567
2018-10-12 06:39:15.572517:	Training iteration: 352, Loss: 0.005749971605837345
2018-10-12 06:42:21.208454:	Training iteration: 353, Loss: 0.004921498242765665
2018-10-12 06:45:24.787782:	Training iteration: 354, Loss: 0.004901209846138954
2018-10-12 06:48:31.729697:	Training iteration: 355, Loss: 0.00742252916097641
2018-10-12 06:51:37.335827:	Training iteration: 356, Loss: 0.004724137485027313
2018-10-12 06:54:43.809190:	Training iteration: 357, Loss: 0.005836385767906904
2018-10-12 06:57:50.668210:	Training iteration: 358, Loss: 0.005536447279155254
2018-10-12 07:00:56.786067:	Training iteration: 359, Loss: 0.00416732020676136
2018-10-12 07:04:02.233431:	Training iteration: 360, Loss: 0.0048296828754246235
2018-10-12 07:07:07.606353:	Training iteration: 361, Loss: 0.006277567241340876
2018-10-12 07:10:14.318408:	Training iteration: 362, Loss: 0.0039015754591673613
2018-10-12 07:13:21.340070:	Training iteration: 363, Loss: 0.005935367196798325
2018-10-12 07:16:27.621166:	Training iteration: 364, Loss: 0.005161046516150236
2018-10-12 07:19:35.720672:	Training iteration: 365, Loss: 0.0059171030297875404
2018-10-12 07:22:41.726096:	Training iteration: 366, Loss: 0.005649636499583721
2018-10-12 07:25:47.672772:	Training iteration: 367, Loss: 0.0048777321353554726
2018-10-12 07:28:53.673246:	Training iteration: 368, Loss: 0.005644222255796194
2018-10-12 07:31:59.143627:	Training iteration: 369, Loss: 0.0058355205692350864
2018-10-12 07:35:04.873892:	Training iteration: 370, Loss: 0.006189288571476936
2018-10-12 07:38:12.327787:	Training iteration: 371, Loss: 0.00434412294998765
2018-10-12 07:41:18.383091:	Training iteration: 372, Loss: 0.0045580132864415646
2018-10-12 07:44:24.944495:	Training iteration: 373, Loss: 0.004712019115686417
2018-10-12 07:47:18.125321:	Training iteration: 374, Loss: 0.0062922099605202675
2018-10-12 07:49:16.669742:	Training iteration: 375, Loss: 0.004875059239566326
2018-10-12 07:51:24.087599:	Training iteration: 376, Loss: 0.0056976815685629845
2018-10-12 07:53:26.880011:	Training iteration: 377, Loss: 0.006290110759437084
2018-10-12 07:55:20.537304:	Training iteration: 378, Loss: 0.0064019011333584785
2018-10-12 07:57:14.788957:	Training iteration: 379, Loss: 0.004434450063854456
2018-10-12 07:59:06.856068:	Training iteration: 380, Loss: 0.004009672440588474
2018-10-12 08:01:13.415455:	Training iteration: 381, Loss: 0.004717829171568155
2018-10-12 08:03:21.210951:	Training iteration: 382, Loss: 0.005302647594362497
2018-10-12 08:05:20.076747:	Training iteration: 383, Loss: 0.004545679781585932
2018-10-12 08:07:38.026010:	Training iteration: 384, Loss: 0.005358387716114521
2018-10-12 08:09:43.254787:	Training iteration: 385, Loss: 0.005522128660231829
2018-10-12 08:12:02.536670:	Training iteration: 386, Loss: 0.00519727636128664
2018-10-12 08:14:12.660162:	Training iteration: 387, Loss: 0.005031986627727747
2018-10-12 08:16:22.924679:	Training iteration: 388, Loss: 0.006783624179661274
2018-10-12 08:18:26.078931:	Training iteration: 389, Loss: 0.004110582638531923
2018-10-12 08:20:18.160720:	Training iteration: 390, Loss: 0.005355842411518097
2018-10-12 08:22:10.845938:	Training iteration: 391, Loss: 0.005407957825809717
2018-10-12 08:24:02.975600:	Training iteration: 392, Loss: 0.004605480469763279
2018-10-12 08:25:59.128454:	Training iteration: 393, Loss: 0.003950753249228001
2018-10-12 08:27:54.312808:	Training iteration: 394, Loss: 0.005729592405259609
2018-10-12 08:29:51.132109:	Training iteration: 395, Loss: 0.00421952735632658
2018-10-12 08:31:47.953942:	Training iteration: 396, Loss: 0.004620364401489496
2018-10-12 08:33:38.337174:	Training iteration: 397, Loss: 0.0060050697065889835
2018-10-12 08:35:34.368137:	Training iteration: 398, Loss: 0.004431474953889847
2018-10-12 08:37:32.336408:	Training iteration: 399, Loss: 0.005747665651142597
2018-10-12 08:39:27.485443:	Training iteration: 400, Loss: 0.00703839585185051
2018-10-12 08:41:20.673423:	Training iteration: 401, Loss: 0.005095346365123987
2018-10-12 08:43:13.745788:	Training iteration: 402, Loss: 0.0054716854356229305
2018-10-12 08:45:08.275808:	Training iteration: 403, Loss: 0.0070336489006876945
2018-10-12 08:47:01.259615:	Training iteration: 404, Loss: 0.0053215911611914635
2018-10-12 08:48:55.269613:	Training iteration: 405, Loss: 0.004783113952726126
2018-10-12 08:50:48.719441:	Training iteration: 406, Loss: 0.005001082085072994
2018-10-12 08:52:44.474075:	Training iteration: 407, Loss: 0.0040303729474544525
2018-10-12 08:54:38.422587:	Training iteration: 408, Loss: 0.005126872565597296
2018-10-12 08:56:33.531965:	Training iteration: 409, Loss: 0.004352130461484194
2018-10-12 08:58:28.846771:	Training iteration: 410, Loss: 0.005579457618296146
2018-10-12 09:00:24.350020:	Training iteration: 411, Loss: 0.005089910235255957
2018-10-12 09:02:18.946921:	Training iteration: 412, Loss: 0.005131274927407503
2018-10-12 09:04:12.425551:	Training iteration: 413, Loss: 0.006763314362615347
2018-10-12 09:06:09.210874:	Training iteration: 414, Loss: 0.0051603764295578
2018-10-12 09:08:03.688666:	Training iteration: 415, Loss: 0.006710580550134182
2018-10-12 09:10:01.291782:	Training iteration: 416, Loss: 0.0060396501794457436
2018-10-12 09:11:54.735539:	Training iteration: 417, Loss: 0.006911477539688349
2018-10-12 09:13:47.641198:	Training iteration: 418, Loss: 0.004004708956927061
2018-10-12 09:15:40.853930:	Training iteration: 419, Loss: 0.006373055279254913
2018-10-12 09:17:36.290564:	Training iteration: 420, Loss: 0.006532865576446056
2018-10-12 09:19:31.224106:	Training iteration: 421, Loss: 0.00421987846493721
2018-10-12 09:21:28.009035:	Training iteration: 422, Loss: 0.00537529494613409
2018-10-12 09:23:20.694427:	Training iteration: 423, Loss: 0.006867291871458292
2018-10-12 09:25:12.613185:	Training iteration: 424, Loss: 0.005590370390564203
2018-10-12 09:27:05.363040:	Training iteration: 425, Loss: 0.006343187298625708
2018-10-12 09:28:58.247016:	Training iteration: 426, Loss: 0.005558324977755547
2018-10-12 09:30:52.484836:	Training iteration: 427, Loss: 0.003993246704339981
2018-10-12 09:32:45.271865:	Training iteration: 428, Loss: 0.006347564049065113
2018-10-12 09:34:40.802190:	Training iteration: 429, Loss: 0.006036386825144291
2018-10-12 09:36:30.216319:	Training iteration: 430, Loss: 0.005561244674026966
2018-10-12 09:38:23.880533:	Training iteration: 431, Loss: 0.005209402646869421
2018-10-12 09:40:17.742651:	Training iteration: 432, Loss: 0.006441518664360046
2018-10-12 09:42:09.394966:	Training iteration: 433, Loss: 0.0046833837404847145
2018-10-12 09:44:00.656969:	Training iteration: 434, Loss: 0.008512785658240318
2018-10-12 09:45:51.760267:	Training iteration: 435, Loss: 0.003814718220382929
2018-10-12 09:47:46.834811:	Training iteration: 436, Loss: 0.00614545401185751
2018-10-12 09:49:39.885123:	Training iteration: 437, Loss: 0.005479365587234497
2018-10-12 09:51:34.786604:	Training iteration: 438, Loss: 0.0045179822482168674
2018-10-12 09:53:29.279293:	Training iteration: 439, Loss: 0.004861061926931143
2018-10-12 09:55:20.319142:	Training iteration: 440, Loss: 0.005121748894453049
2018-10-12 09:57:11.903637:	Training iteration: 441, Loss: 0.00443197600543499
2018-10-12 09:59:01.813830:	Training iteration: 442, Loss: 0.005424668081104755
2018-10-12 10:00:56.726916:	Training iteration: 443, Loss: 0.005197647958993912
2018-10-12 10:02:52.048078:	Training iteration: 444, Loss: 0.0055468035861849785
2018-10-12 10:04:44.834036:	Training iteration: 445, Loss: 0.005636599846184254
2018-10-12 10:06:38.590643:	Training iteration: 446, Loss: 0.003566883970052004
2018-10-12 10:08:32.212274:	Training iteration: 447, Loss: 0.005695529747754335
2018-10-12 10:10:25.016430:	Training iteration: 448, Loss: 0.005195496138185263
2018-10-12 10:12:17.486000:	Training iteration: 449, Loss: 0.0054626925848424435
2018-10-12 10:14:09.794969:	Training iteration: 450, Loss: 0.005084355361759663
2018-10-12 10:15:59.494315:	Training iteration: 451, Loss: 0.003704909235239029
2018-10-12 10:17:51.062765:	Training iteration: 452, Loss: 0.006310637108981609
2018-10-12 10:19:44.802328:	Training iteration: 453, Loss: 0.00514715351164341
2018-10-12 10:21:39.323344:	Training iteration: 454, Loss: 0.005477746482938528
2018-10-12 10:23:34.164610:	Training iteration: 455, Loss: 0.005476503632962704
2018-10-12 10:25:27.442740:	Training iteration: 456, Loss: 0.004490314982831478
2018-10-12 10:27:21.482813:	Training iteration: 457, Loss: 0.0050616757944226265
2018-10-12 10:29:16.519205:	Training iteration: 458, Loss: 0.006200103554874659
2018-10-12 10:31:13.759088:	Training iteration: 459, Loss: 0.006026090122759342
2018-10-12 10:33:06.640565:	Training iteration: 460, Loss: 0.006082052830606699
2018-10-12 10:34:59.245424:	Training iteration: 461, Loss: 0.0049882386811077595
2018-10-12 10:36:55.054089:	Training iteration: 462, Loss: 0.003685543779283762
2018-10-12 10:38:50.370672:	Training iteration: 463, Loss: 0.006224398035556078
2018-10-12 10:40:40.837558:	Training iteration: 464, Loss: 0.0065894098952412605
2018-10-12 10:42:34.397319:	Training iteration: 465, Loss: 0.005437622778117657
2018-10-12 10:44:27.404140:	Training iteration: 466, Loss: 0.005963987670838833
2018-10-12 10:46:22.323309:	Training iteration: 467, Loss: 0.005526332184672356
2018-10-12 10:48:15.162007:	Training iteration: 468, Loss: 0.00467695901170373
2018-10-12 10:50:08.813977:	Training iteration: 469, Loss: 0.005189717281609774
2018-10-12 10:52:04.753928:	Training iteration: 470, Loss: 0.005614736117422581
2018-10-12 10:53:55.606969:	Training iteration: 471, Loss: 0.005061558447778225
2018-10-12 10:55:49.915475:	Training iteration: 472, Loss: 0.006131342612206936
2018-10-12 10:57:45.558978:	Training iteration: 473, Loss: 0.0061093284748494625
2018-10-12 10:59:38.833426:	Training iteration: 474, Loss: 0.005270838737487793
2018-10-12 11:01:33.492694:	Training iteration: 475, Loss: 0.008096018806099892
2018-10-12 11:03:29.118874:	Training iteration: 476, Loss: 0.004236450884491205
2018-10-12 11:05:22.156512:	Training iteration: 477, Loss: 0.0064146919175982475
2018-10-12 11:07:13.646900:	Training iteration: 478, Loss: 0.005312600173056126
2018-10-12 11:09:08.337665:	Training iteration: 479, Loss: 0.006114372983574867
2018-10-12 11:11:04.467348:	Training iteration: 480, Loss: 0.004646885208785534
2018-10-12 11:13:00.247056:	Training iteration: 481, Loss: 0.005070805549621582
2018-10-12 11:14:55.605453:	Training iteration: 482, Loss: 0.006659629754722118
2018-10-12 11:16:51.110717:	Training iteration: 483, Loss: 0.0050442833453416824
2018-10-12 11:18:43.873992:	Training iteration: 484, Loss: 0.0037996366154402494
2018-10-12 11:20:37.725135:	Training iteration: 485, Loss: 0.005719994194805622
2018-10-12 11:22:30.457164:	Training iteration: 486, Loss: 0.005169450305402279
2018-10-12 11:24:24.056815:	Training iteration: 487, Loss: 0.003633089829236269
2018-10-12 11:26:18.264615:	Training iteration: 488, Loss: 0.0046569956466555595
2018-10-12 11:28:09.232401:	Training iteration: 489, Loss: 0.0046199229545891285
2018-10-12 11:30:01.722672:	Training iteration: 490, Loss: 0.004856984131038189
2018-10-12 11:31:53.255472:	Training iteration: 491, Loss: 0.006060791667550802
2018-10-12 11:33:49.743719:	Training iteration: 492, Loss: 0.00569044379517436
2018-10-12 11:35:42.103435:	Training iteration: 493, Loss: 0.005225716158747673
2018-10-12 11:37:36.393493:	Training iteration: 494, Loss: 0.004337736871093512
2018-10-12 11:39:28.992288:	Training iteration: 495, Loss: 0.004911762662231922
2018-10-12 11:41:22.260668:	Training iteration: 496, Loss: 0.00448650261387229
2018-10-12 11:43:13.917246:	Training iteration: 497, Loss: 0.004741061478853226
2018-10-12 11:45:05.996199:	Training iteration: 498, Loss: 0.005093246698379517
2018-10-12 11:46:59.056483:	Training iteration: 499, Loss: 0.004296641796827316
2018-10-12 11:48:52.653523:	Training iteration: 500, Loss: 0.005060711409896612
2018-10-12 11:50:49.221874:	Training iteration: 501, Loss: 0.004812824074178934
2018-10-12 11:52:42.197852:	Training iteration: 502, Loss: 0.0056296540424227715
2018-10-12 11:54:34.483428:	Training iteration: 503, Loss: 0.00505454558879137
2018-10-12 11:56:28.845603:	Training iteration: 504, Loss: 0.005468493327498436
2018-10-12 11:58:20.518293:	Training iteration: 505, Loss: 0.004910290241241455
2018-10-12 12:00:13.895685:	Training iteration: 506, Loss: 0.005628409795463085
2018-10-12 12:02:09.840834:	Training iteration: 507, Loss: 0.0044957115314900875
2018-10-12 12:04:02.451286:	Training iteration: 508, Loss: 0.004508855752646923
2018-10-12 12:05:53.054940:	Training iteration: 509, Loss: 0.004927999805659056
2018-10-12 12:07:50.933165:	Training iteration: 510, Loss: 0.004271503537893295
2018-10-12 12:09:58.769065:	Training iteration: 511, Loss: 0.005190038587898016
2018-10-12 12:12:02.112946:	Training iteration: 512, Loss: 0.005528225563466549
2018-10-12 12:14:09.660990:	Training iteration: 513, Loss: 0.0065953596495091915
2018-10-12 12:16:12.792210:	Training iteration: 514, Loss: 0.004163231700658798
2018-10-12 12:18:25.047190:	Training iteration: 515, Loss: 0.004794443491846323
2018-10-12 12:20:23.928967:	Training iteration: 516, Loss: 0.003839115146547556
2018-10-12 12:22:33.602136:	Training iteration: 517, Loss: 0.004509593825787306
2018-10-12 12:24:36.926472:	Training iteration: 518, Loss: 0.005186059512197971
2018-10-12 12:26:43.288235:	Training iteration: 519, Loss: 0.004373266361653805
2018-10-12 12:28:36.128732:	Training iteration: 520, Loss: 0.004976063501089811
2018-10-12 12:30:29.134947:	Training iteration: 521, Loss: 0.005895235575735569
2018-10-12 12:32:22.190928:	Training iteration: 522, Loss: 0.005393517669290304
2018-10-12 12:34:14.909127:	Training iteration: 523, Loss: 0.005067658610641956
2018-10-12 12:36:07.599356:	Training iteration: 524, Loss: 0.006185171660035849
2018-10-12 12:38:00.285793:	Training iteration: 525, Loss: 0.004200472962111235
2018-10-12 12:39:52.526868:	Training iteration: 526, Loss: 0.004243763163685799
2018-10-12 12:41:46.935746:	Training iteration: 527, Loss: 0.004803107585757971
2018-10-12 12:43:39.534749:	Training iteration: 528, Loss: 0.006646221969276667
2018-10-12 12:45:31.820325:	Training iteration: 529, Loss: 0.006050129421055317
2018-10-12 12:47:28.230001:	Training iteration: 530, Loss: 0.0061386385932564735
2018-10-12 12:49:19.946476:	Training iteration: 531, Loss: 0.004495027009397745
2018-10-12 12:51:17.715665:	Training iteration: 532, Loss: 0.007419587578624487
2018-10-12 12:53:27.554630:	Training iteration: 533, Loss: 0.005298673175275326
2018-10-12 12:55:19.969461:	Training iteration: 534, Loss: 0.0037749516777694225
2018-10-12 12:57:10.566647:	Training iteration: 535, Loss: 0.005211713723838329
2018-10-12 12:59:00.836139:	Training iteration: 536, Loss: 0.00593309011310339
2018-10-12 13:00:53.090533:	Training iteration: 537, Loss: 0.004487562924623489
2018-10-12 13:02:46.555183:	Training iteration: 538, Loss: 0.004469483159482479
2018-10-12 13:04:36.638856:	Training iteration: 539, Loss: 0.004508933983743191
2018-10-12 13:06:30.862127:	Training iteration: 540, Loss: 0.004332182463258505
2018-10-12 13:08:42.187710:	Training iteration: 541, Loss: 0.005798444151878357
2018-10-12 13:10:37.122879:	Training iteration: 542, Loss: 0.005008072592318058
2018-10-12 13:12:29.992843:	Training iteration: 543, Loss: 0.0037382058799266815
2018-10-12 13:14:24.727101:	Training iteration: 544, Loss: 0.004823088645935059
2018-10-12 13:16:15.978312:	Training iteration: 545, Loss: 0.004776993300765753
2018-10-12 13:18:09.244951:	Training iteration: 546, Loss: 0.006280233152210712
2018-10-12 13:19:59.288520:	Training iteration: 547, Loss: 0.004692728631198406
2018-10-12 13:21:48.597120:	Training iteration: 548, Loss: 0.004224257078021765
2018-10-12 13:23:37.002540:	Training iteration: 549, Loss: 0.0047980849631130695
2018-10-12 13:25:28.060413:	Training iteration: 550, Loss: 0.006064187735319138
2018-10-12 13:27:20.397217:	Training iteration: 551, Loss: 0.003901320742443204
2018-10-12 13:29:11.489152:	Training iteration: 552, Loss: 0.005447354633361101
2018-10-12 13:31:02.854385:	Training iteration: 553, Loss: 0.004939603619277477
2018-10-12 13:32:53.369484:	Training iteration: 554, Loss: 0.0072734421119093895
2018-10-12 13:34:46.070471:	Training iteration: 555, Loss: 0.004821617156267166
2018-10-12 13:36:36.974718:	Training iteration: 556, Loss: 0.004437172319740057
2018-10-12 13:38:30.917533:	Training iteration: 557, Loss: 0.006048489827662706
2018-10-12 13:40:24.350998:	Training iteration: 558, Loss: 0.0048204101622104645
2018-10-12 13:42:16.075417:	Training iteration: 559, Loss: 0.007191069424152374
2018-10-12 13:44:11.126658:	Training iteration: 560, Loss: 0.005518696270883083
2018-10-12 13:46:01.517828:	Training iteration: 561, Loss: 0.005920159164816141
2018-10-12 13:47:54.513054:	Training iteration: 562, Loss: 0.004518137779086828
2018-10-12 13:49:45.504406:	Training iteration: 563, Loss: 0.006252777762711048
2018-10-12 13:51:36.699489:	Training iteration: 564, Loss: 0.0050064511597156525
2018-10-12 13:53:27.551460:	Training iteration: 565, Loss: 0.005554954055696726
2018-10-12 13:55:19.282816:	Training iteration: 566, Loss: 0.003773829434067011
2018-10-12 13:57:11.342565:	Training iteration: 567, Loss: 0.004901162348687649
2018-10-12 13:59:02.091107:	Training iteration: 568, Loss: 0.007992313243448734
2018-10-12 14:00:55.336237:	Training iteration: 569, Loss: 0.004396167583763599
2018-10-12 14:02:49.045618:	Training iteration: 570, Loss: 0.0054241204634308815
2018-10-12 14:04:42.949506:	Training iteration: 571, Loss: 0.004338574595749378
2018-10-12 14:06:35.077828:	Training iteration: 572, Loss: 0.005395848304033279
2018-10-12 14:08:25.179461:	Training iteration: 573, Loss: 0.005259398370981216
2018-10-12 14:10:18.130619:	Training iteration: 574, Loss: 0.004526781849563122
2018-10-12 14:12:08.965318:	Training iteration: 575, Loss: 0.006780298892408609
2018-10-12 14:14:00.702292:	Training iteration: 576, Loss: 0.006762894801795483
2018-10-12 14:15:52.915750:	Training iteration: 577, Loss: 0.005381418392062187
2018-10-12 14:17:48.465783:	Training iteration: 578, Loss: 0.006192849949002266
2018-10-12 14:19:42.169702:	Training iteration: 579, Loss: 0.00540036428719759
2018-10-12 14:21:32.340744:	Training iteration: 580, Loss: 0.0045463694259524345
2018-10-12 14:23:24.028793:	Training iteration: 581, Loss: 0.006135913543403149
2018-10-12 14:25:17.588850:	Training iteration: 582, Loss: 0.00527441781014204
2018-10-12 14:27:09.959233:	Training iteration: 583, Loss: 0.004207028541713953
2018-10-12 14:29:02.822239:	Training iteration: 584, Loss: 0.006027408875524998
2018-10-12 14:30:56.771418:	Training iteration: 585, Loss: 0.005947829224169254
2018-10-12 14:32:53.141872:	Training iteration: 586, Loss: 0.006111915688961744
2018-10-12 14:34:49.052073:	Training iteration: 587, Loss: 0.006788520608097315
2018-10-12 14:36:42.112969:	Training iteration: 588, Loss: 0.005404267460107803
2018-10-12 14:38:36.067717:	Training iteration: 589, Loss: 0.004216024186462164
2018-10-12 14:40:29.069599:	Training iteration: 590, Loss: 0.004677562974393368
2018-10-12 14:42:24.752889:	Training iteration: 591, Loss: 0.005498949438333511
2018-10-12 14:44:22.831300:	Training iteration: 592, Loss: 0.005850036628544331
2018-10-12 14:46:14.603119:	Training iteration: 593, Loss: 0.007334908936172724
2018-10-12 14:48:11.083519:	Training iteration: 594, Loss: 0.0052598584443330765
2018-10-12 14:50:09.623587:	Training iteration: 595, Loss: 0.005406699143350124
2018-10-12 14:52:05.562367:	Training iteration: 596, Loss: 0.0052248043939471245
2018-10-12 14:53:57.982041:	Training iteration: 597, Loss: 0.005281717516481876
2018-10-12 14:55:52.815114:	Training iteration: 598, Loss: 0.006275949068367481
2018-10-12 14:57:45.867487:	Training iteration: 599, Loss: 0.0056621902622282505
2018-10-12 14:59:36.995374:	Training iteration: 600, Loss: 0.005285446997731924
2018-10-12 15:01:29.318305:	Training iteration: 601, Loss: 0.005575158633291721
2018-10-12 15:04:23.576568:	Training iteration: 602, Loss: 0.0067854574881494045
2018-10-12 15:06:20.398397:	Training iteration: 603, Loss: 0.004902873188257217
2018-10-12 15:08:14.886731:	Training iteration: 604, Loss: 0.005404488183557987
2018-10-12 15:10:08.898537:	Training iteration: 605, Loss: 0.005319986492395401
2018-10-12 15:12:03.545243:	Training iteration: 606, Loss: 0.004577269311994314
2018-10-12 15:13:57.661497:	Training iteration: 607, Loss: 0.00557321822270751
2018-10-12 15:15:50.965728:	Training iteration: 608, Loss: 0.005855678580701351
2018-10-12 15:17:44.853678:	Training iteration: 609, Loss: 0.005518899764865637
2018-10-12 15:19:36.024014:	Training iteration: 610, Loss: 0.005350724793970585
2018-10-12 15:21:28.968673:	Training iteration: 611, Loss: 0.005110355094075203
2018-10-12 15:23:23.982478:	Training iteration: 612, Loss: 0.005627670791000128
2018-10-12 15:25:16.365503:	Training iteration: 613, Loss: 0.005566497799009085
2018-10-12 15:27:10.115214:	Training iteration: 614, Loss: 0.004394809249788523
2018-10-12 15:29:06.819516:	Training iteration: 615, Loss: 0.0049035316333174706
2018-10-12 15:30:58.352320:	Training iteration: 616, Loss: 0.0059749288484454155
2018-10-12 15:32:54.286606:	Training iteration: 617, Loss: 0.00512757059186697
2018-10-12 15:34:48.235079:	Training iteration: 618, Loss: 0.007144927978515625
2018-10-12 15:36:39.645982:	Training iteration: 619, Loss: 0.0034773163497447968
2018-10-12 15:38:30.797074:	Training iteration: 620, Loss: 0.006532509811222553
2018-10-12 15:40:26.930986:	Training iteration: 621, Loss: 0.005684507545083761
2018-10-12 15:42:19.734510:	Training iteration: 622, Loss: 0.006212501786649227
2018-10-12 15:44:13.963380:	Training iteration: 623, Loss: 0.004987809807062149
2018-10-12 15:46:08.160765:	Training iteration: 624, Loss: 0.004496417939662933
2018-10-12 15:48:02.595502:	Training iteration: 625, Loss: 0.0056115807965397835
2018-10-12 15:49:55.580799:	Training iteration: 626, Loss: 0.0052550858817994595
2018-10-12 15:51:47.518022:	Training iteration: 627, Loss: 0.0041276924312114716
2018-10-12 15:53:40.230987:	Training iteration: 628, Loss: 0.005181573331356049
2018-10-12 15:55:32.428866:	Training iteration: 629, Loss: 0.006891162134706974
2018-10-12 15:57:23.840340:	Training iteration: 630, Loss: 0.004165777005255222
2018-10-12 15:59:17.957368:	Training iteration: 631, Loss: 0.006320972926914692
2018-10-12 16:01:13.746313:	Training iteration: 632, Loss: 0.005377688445150852
2018-10-12 16:03:04.843509:	Training iteration: 633, Loss: 0.006132194306701422
2018-10-12 16:04:57.036996:	Training iteration: 634, Loss: 0.0036773309111595154
2018-10-12 16:06:49.672977:	Training iteration: 635, Loss: 0.005723119713366032
2018-10-12 16:08:41.716955:	Training iteration: 636, Loss: 0.006475507281720638
2018-10-12 16:10:32.266595:	Training iteration: 637, Loss: 0.004843758884817362
2018-10-12 16:12:25.955591:	Training iteration: 638, Loss: 0.0063588619232177734
2018-10-12 16:14:19.298343:	Training iteration: 639, Loss: 0.0052290139719843864
2018-10-12 16:16:07.127610:	Training iteration: 640, Loss: 0.003956822212785482
2018-10-12 16:17:58.942054:	Training iteration: 641, Loss: 0.005745247937738895
2018-10-12 16:19:51.644907:	Training iteration: 642, Loss: 0.005685023032128811
2018-10-12 16:21:44.873051:	Training iteration: 643, Loss: 0.004157977178692818
2018-10-12 16:23:38.595921:	Training iteration: 644, Loss: 0.006357637234032154
2018-10-12 16:25:30.169775:	Training iteration: 645, Loss: 0.0062630451284348965
2018-10-12 16:27:20.593806:	Training iteration: 646, Loss: 0.003900698618963361
2018-10-12 16:29:10.096537:	Training iteration: 647, Loss: 0.006284573581069708
2018-10-12 16:31:01.790012:	Training iteration: 648, Loss: 0.004845851566642523
2018-10-12 16:32:53.200461:	Training iteration: 649, Loss: 0.004221484996378422
2018-10-12 16:34:44.105737:	Training iteration: 650, Loss: 0.006053106393665075
2018-10-12 16:36:38.129176:	Training iteration: 651, Loss: 0.004608838353306055
2018-10-12 16:38:27.786008:	Training iteration: 652, Loss: 0.005346179008483887
2018-10-12 16:40:20.763486:	Training iteration: 653, Loss: 0.0055279964581131935
2018-10-12 16:42:12.302318:	Training iteration: 654, Loss: 0.004196326248347759
2018-10-12 16:44:02.371928:	Training iteration: 655, Loss: 0.005565478932112455
2018-10-12 16:45:55.120514:	Training iteration: 656, Loss: 0.004484276287257671
2018-10-12 16:47:47.660045:	Training iteration: 657, Loss: 0.005916026420891285
2018-10-12 16:49:36.571784:	Training iteration: 658, Loss: 0.0051396493799984455
2018-10-12 16:51:28.309525:	Training iteration: 659, Loss: 0.00626275222748518
2018-10-12 16:53:21.623605:	Training iteration: 660, Loss: 0.006598742213100195
2018-10-12 16:55:16.074712:	Training iteration: 661, Loss: 0.004211571998894215
2018-10-12 16:57:06.752755:	Training iteration: 662, Loss: 0.004583077505230904
2018-10-12 16:58:59.470444:	Training iteration: 663, Loss: 0.005303202662616968
2018-10-12 17:00:52.279973:	Training iteration: 664, Loss: 0.005748698953539133
2018-10-12 17:02:43.534736:	Training iteration: 665, Loss: 0.0038057088386267424
2018-10-12 17:04:36.918915:	Training iteration: 666, Loss: 0.005343258380889893
2018-10-12 17:06:28.077927:	Training iteration: 667, Loss: 0.0038406618405133486
2018-10-12 17:08:17.858212:	Training iteration: 668, Loss: 0.004764343611896038
2018-10-12 17:10:07.385487:	Training iteration: 669, Loss: 0.006340336054563522
2018-10-12 17:11:58.139706:	Training iteration: 670, Loss: 0.005901389755308628
2018-10-12 17:13:52.689529:	Training iteration: 671, Loss: 0.005229742266237736
2018-10-12 17:15:45.407669:	Training iteration: 672, Loss: 0.005320693366229534
2018-10-12 17:17:38.517601:	Training iteration: 673, Loss: 0.007303881458938122
2018-10-12 17:19:27.509552:	Training iteration: 674, Loss: 0.006731378845870495
2018-10-12 17:21:21.513820:	Training iteration: 675, Loss: 0.005590755492448807
2018-10-12 17:23:11.726003:	Training iteration: 676, Loss: 0.005645550787448883
2018-10-12 17:25:02.863106:	Training iteration: 677, Loss: 0.004260971210896969
2018-10-12 17:26:52.980181:	Training iteration: 678, Loss: 0.005557452328503132
2018-10-12 17:28:47.378449:	Training iteration: 679, Loss: 0.0034666932187974453
2018-10-12 17:30:36.414076:	Training iteration: 680, Loss: 0.005433013662695885
2018-10-12 17:32:27.320602:	Training iteration: 681, Loss: 0.004969938658177853
2018-10-12 17:34:20.628447:	Training iteration: 682, Loss: 0.004220285452902317
2018-10-12 17:36:13.673910:	Training iteration: 683, Loss: 0.0059522902593016624
2018-10-12 17:38:06.461959:	Training iteration: 684, Loss: 0.005336867179721594
2018-10-12 17:39:58.411338:	Training iteration: 685, Loss: 0.00533004617318511
2018-10-12 17:41:52.101485:	Training iteration: 686, Loss: 0.005552212707698345
2018-10-12 17:43:44.465343:	Training iteration: 687, Loss: 0.005985474679619074
2018-10-12 17:45:37.665833:	Training iteration: 688, Loss: 0.006402994506061077
2018-10-12 17:47:28.806568:	Training iteration: 689, Loss: 0.005532330367714167
2018-10-12 17:49:22.833753:	Training iteration: 690, Loss: 0.004715257324278355
2018-10-12 17:51:13.560866:	Training iteration: 691, Loss: 0.0058492631651461124
2018-10-12 17:53:05.908873:	Training iteration: 692, Loss: 0.0049398792907595634
2018-10-12 17:54:56.661412:	Training iteration: 693, Loss: 0.0062791407108306885
2018-10-12 17:56:51.281928:	Training iteration: 694, Loss: 0.006988788489252329
2018-10-12 17:58:42.101655:	Training iteration: 695, Loss: 0.005214468576014042
2018-10-12 18:00:36.136477:	Training iteration: 696, Loss: 0.006317174527794123
2018-10-12 18:02:27.048307:	Training iteration: 697, Loss: 0.00507280882447958
2018-10-12 18:04:20.558142:	Training iteration: 698, Loss: 0.004197374917566776
2018-10-12 18:06:12.237750:	Training iteration: 699, Loss: 0.0041284761391580105
2018-10-12 18:08:05.741100:	Training iteration: 700, Loss: 0.007110097911208868
2018-10-12 18:09:59.200863:	Training iteration: 701, Loss: 0.005537237040698528
2018-10-12 18:11:51.405650:	Training iteration: 702, Loss: 0.004714200273156166
2018-10-12 18:13:42.790884:	Training iteration: 703, Loss: 0.0045144446194171906
2018-10-12 18:15:36.715997:	Training iteration: 704, Loss: 0.005459201987832785
2018-10-12 18:17:27.022215:	Training iteration: 705, Loss: 0.0053922878578305244
2018-10-12 18:19:18.182952:	Training iteration: 706, Loss: 0.004920127801597118
2018-10-12 18:21:11.754158:	Training iteration: 707, Loss: 0.005707153119146824
2018-10-12 18:23:02.978302:	Training iteration: 708, Loss: 0.00597126130014658
2018-10-12 18:24:59.201409:	Training iteration: 709, Loss: 0.005078776273876429
2018-10-12 18:26:51.478814:	Training iteration: 710, Loss: 0.0037050233222544193
2018-10-12 18:28:47.163903:	Training iteration: 711, Loss: 0.004200358875095844
2018-10-12 18:30:39.203873:	Training iteration: 712, Loss: 0.00509648909792304
2018-10-12 18:32:30.194284:	Training iteration: 713, Loss: 0.005957214627414942
2018-10-12 18:34:22.680011:	Training iteration: 714, Loss: 0.006650014780461788
2018-10-12 18:36:13.243504:	Training iteration: 715, Loss: 0.005332177504897118
2018-10-12 18:38:04.704527:	Training iteration: 716, Loss: 0.005064566154032946
2018-10-12 18:39:56.262303:	Training iteration: 717, Loss: 0.006243040785193443
2018-10-12 18:41:46.986054:	Training iteration: 718, Loss: 0.00482139503583312
2018-10-12 18:43:38.839376:	Training iteration: 719, Loss: 0.006300897803157568
2018-10-12 18:45:30.131825:	Training iteration: 720, Loss: 0.0061524854972958565
2018-10-12 18:47:22.806107:	Training iteration: 721, Loss: 0.0076726810075342655
2018-10-12 18:49:13.677432:	Training iteration: 722, Loss: 0.00535376975312829
2018-10-12 18:51:03.896827:	Training iteration: 723, Loss: 0.005016692448407412
2018-10-12 18:52:54.940546:	Training iteration: 724, Loss: 0.0042286282405257225
2018-10-12 18:54:47.826053:	Training iteration: 725, Loss: 0.005289821419864893
2018-10-12 18:56:39.575869:	Training iteration: 726, Loss: 0.005493350327014923
2018-10-12 18:58:32.484063:	Training iteration: 727, Loss: 0.005420682020485401
2018-10-12 19:00:26.318496:	Training iteration: 728, Loss: 0.006022330839186907
2018-10-12 19:02:19.773632:	Training iteration: 729, Loss: 0.005758455954492092
2018-10-12 19:04:14.862709:	Training iteration: 730, Loss: 0.00691615417599678
2018-10-12 19:06:05.916869:	Training iteration: 731, Loss: 0.004963178187608719
2018-10-12 19:07:58.734090:	Training iteration: 732, Loss: 0.005640811286866665
2018-10-12 19:09:52.708427:	Training iteration: 733, Loss: 0.006471921689808369
2018-10-12 19:11:46.136118:	Training iteration: 734, Loss: 0.004532073624432087
2018-10-12 19:13:37.962341:	Training iteration: 735, Loss: 0.004001860972493887
2018-10-12 19:15:33.270180:	Training iteration: 736, Loss: 0.0065975310280919075
2018-10-12 19:17:26.421090:	Training iteration: 737, Loss: 0.006166823208332062
2018-10-12 19:19:16.964968:	Training iteration: 738, Loss: 0.004441126249730587
2018-10-12 19:21:07.517017:	Training iteration: 739, Loss: 0.005443315953016281
2018-10-12 19:22:58.169138:	Training iteration: 740, Loss: 0.006100144237279892
2018-10-12 19:24:50.132258:	Training iteration: 741, Loss: 0.005126464646309614
2018-10-12 19:26:42.472642:	Training iteration: 742, Loss: 0.0061300937086343765
2018-10-12 19:28:35.566920:	Training iteration: 743, Loss: 0.005311824381351471
2018-10-12 19:30:27.669621:	Training iteration: 744, Loss: 0.005454419646412134
2018-10-12 19:32:21.171083:	Training iteration: 745, Loss: 0.005854389164596796
2018-10-12 19:34:15.225936:	Training iteration: 746, Loss: 0.005163448862731457
2018-10-12 19:36:08.278030:	Training iteration: 747, Loss: 0.0047644441947340965
2018-10-12 19:37:58.084128:	Training iteration: 748, Loss: 0.00693685095757246
2018-10-12 19:39:45.917053:	Training iteration: 749, Loss: 0.005801056046038866
2018-10-12 19:41:35.626466:	Training iteration: 750, Loss: 0.005456559360027313
2018-10-12 19:43:27.768028:	Training iteration: 751, Loss: 0.006684629712253809
2018-10-12 19:45:19.621659:	Training iteration: 752, Loss: 0.004991992376744747
2018-10-12 19:47:13.645307:	Training iteration: 753, Loss: 0.006020755972713232
2018-10-12 19:49:07.449377:	Training iteration: 754, Loss: 0.005101791117340326
2018-10-12 19:51:00.980718:	Training iteration: 755, Loss: 0.0048361956141889095
2018-10-12 19:52:56.947385:	Training iteration: 756, Loss: 0.004665045998990536
2018-10-12 19:54:51.814453:	Training iteration: 757, Loss: 0.008165089413523674
2018-10-12 19:56:45.716175:	Training iteration: 758, Loss: 0.006258928682655096
2018-10-12 19:58:43.524169:	Training iteration: 759, Loss: 0.005779811181128025
2018-10-12 20:00:38.000203:	Training iteration: 760, Loss: 0.004493458662182093
2018-10-12 20:02:33.366592:	Training iteration: 761, Loss: 0.005171295255422592
2018-10-12 20:04:26.762218:	Training iteration: 762, Loss: 0.004957315977662802
2018-10-12 20:06:23.050886:	Training iteration: 763, Loss: 0.00692033302038908
2018-10-12 20:08:17.538801:	Training iteration: 764, Loss: 0.004228650592267513
2018-10-12 20:10:13.733726:	Training iteration: 765, Loss: 0.00600892398506403
2018-10-12 20:12:08.759552:	Training iteration: 766, Loss: 0.004719041753560305
2018-10-12 20:14:00.981408:	Training iteration: 767, Loss: 0.005512205883860588
2018-10-12 20:15:55.499300:	Training iteration: 768, Loss: 0.006596146617084742
2018-10-12 20:17:49.443993:	Training iteration: 769, Loss: 0.005991116166114807
2018-10-12 20:19:44.301306:	Training iteration: 770, Loss: 0.005937273148447275
2018-10-12 20:21:38.104971:	Training iteration: 771, Loss: 0.004781556781381369
2018-10-12 20:23:29.365026:	Training iteration: 772, Loss: 0.005159865133464336
2018-10-12 20:25:23.344266:	Training iteration: 773, Loss: 0.00470749894157052
2018-10-12 20:27:16.516463:	Training iteration: 774, Loss: 0.0077431113459169865
2018-10-12 20:29:09.425644:	Training iteration: 775, Loss: 0.005019497126340866
2018-10-12 20:31:04.706806:	Training iteration: 776, Loss: 0.005018148571252823
2018-10-12 20:32:57.652979:	Training iteration: 777, Loss: 0.007189403288066387
2018-10-12 20:34:52.910348:	Training iteration: 778, Loss: 0.004037476144731045
2018-10-12 20:36:44.646262:	Training iteration: 779, Loss: 0.005263634026050568
2018-10-12 20:38:38.775482:	Training iteration: 780, Loss: 0.005403370130807161
2018-10-12 20:40:33.758021:	Training iteration: 781, Loss: 0.004252343438565731
2018-10-12 20:42:26.467693:	Training iteration: 782, Loss: 0.004262941889464855
2018-10-12 20:44:19.610352:	Training iteration: 783, Loss: 0.003868006868287921
2018-10-12 20:46:14.603867:	Training iteration: 784, Loss: 0.005582413636147976
2018-10-12 20:48:08.907597:	Training iteration: 785, Loss: 0.0053525520488619804
2018-10-12 20:50:00.591299:	Training iteration: 786, Loss: 0.00443063210695982
2018-10-12 20:51:52.040782:	Training iteration: 787, Loss: 0.0060145119205117226
2018-10-12 20:53:46.099185:	Training iteration: 788, Loss: 0.008636163547635078
2018-10-12 20:55:37.264121:	Training iteration: 789, Loss: 0.005190753377974033
2018-10-12 20:57:28.977936:	Training iteration: 790, Loss: 0.004771289881318808
2018-10-12 20:59:22.818103:	Training iteration: 791, Loss: 0.005332773085683584
2018-10-12 21:01:17.731148:	Training iteration: 792, Loss: 0.005490799900144339
2018-10-12 21:03:10.755979:	Training iteration: 793, Loss: 0.005392568651586771
2018-10-12 21:05:04.014916:	Training iteration: 794, Loss: 0.00546274334192276
2018-10-12 21:06:57.275245:	Training iteration: 795, Loss: 0.00536921713501215
2018-10-12 21:08:50.592954:	Training iteration: 796, Loss: 0.004410866182297468
2018-10-12 21:10:41.325556:	Training iteration: 797, Loss: 0.005199509672820568
2018-10-12 21:12:33.446812:	Training iteration: 798, Loss: 0.004828275181353092
2018-10-12 21:14:27.457932:	Training iteration: 799, Loss: 0.005329421255737543
2018-10-12 21:16:20.922794:	Training iteration: 800, Loss: 0.005481021944433451
2018-10-12 21:18:15.969887:	Training iteration: 801, Loss: 0.005526345688849688
2018-10-12 21:20:11.552639:	Training iteration: 802, Loss: 0.005680421832948923
2018-10-12 21:22:06.327680:	Training iteration: 803, Loss: 0.004272732883691788
2018-10-12 21:23:58.041413:	Training iteration: 804, Loss: 0.005309497006237507
2018-10-12 21:25:51.716807:	Training iteration: 805, Loss: 0.005283440463244915
2018-10-12 21:27:45.530081:	Training iteration: 806, Loss: 0.0037970454432070255
2018-10-12 21:29:35.498462:	Training iteration: 807, Loss: 0.007345461752265692
2018-10-12 21:31:30.531336:	Training iteration: 808, Loss: 0.005344008561223745
2018-10-12 21:33:27.992592:	Training iteration: 809, Loss: 0.005141196772456169
2018-10-12 21:35:23.563451:	Training iteration: 810, Loss: 0.004752992652356625
2018-10-12 21:37:18.985744:	Training iteration: 811, Loss: 0.008398794569075108
2018-10-12 21:39:15.244523:	Training iteration: 812, Loss: 0.00614056596532464
2018-10-12 21:41:05.909314:	Training iteration: 813, Loss: 0.0036377408541738987
2018-10-12 21:42:59.462427:	Training iteration: 814, Loss: 0.003975675441324711
2018-10-12 21:44:51.105525:	Training iteration: 815, Loss: 0.006211703643202782
2018-10-12 21:46:41.361927:	Training iteration: 816, Loss: 0.0052923234179615974
2018-10-12 21:48:33.631762:	Training iteration: 817, Loss: 0.004619330633431673
2018-10-12 21:50:28.105866:	Training iteration: 818, Loss: 0.0054674772545695305
2018-10-12 21:52:19.493277:	Training iteration: 819, Loss: 0.004087130539119244
2018-10-12 21:54:13.458676:	Training iteration: 820, Loss: 0.004432109650224447
2018-10-12 21:56:06.124069:	Training iteration: 821, Loss: 0.004725512117147446
2018-10-12 21:58:01.217501:	Training iteration: 822, Loss: 0.006945767905563116
2018-10-12 21:59:53.962363:	Training iteration: 823, Loss: 0.0049165175296366215
2018-10-12 22:01:51.624494:	Training iteration: 824, Loss: 0.004011405166238546
2018-10-12 22:03:47.630916:	Training iteration: 825, Loss: 0.004759328905493021
2018-10-12 22:05:40.226300:	Training iteration: 826, Loss: 0.005426655989140272
2018-10-12 22:07:32.341084:	Training iteration: 827, Loss: 0.004088818561285734
2018-10-12 22:09:27.202785:	Training iteration: 828, Loss: 0.006251420825719833
2018-10-12 22:11:19.022148:	Training iteration: 829, Loss: 0.006612077355384827
2018-10-12 22:13:09.804634:	Training iteration: 830, Loss: 0.003681245492771268
2018-10-12 22:15:02.939021:	Training iteration: 831, Loss: 0.00397421745583415
2018-10-12 22:16:58.648977:	Training iteration: 832, Loss: 0.004789276979863644
2018-10-12 22:18:50.840983:	Training iteration: 833, Loss: 0.004510906990617514
2018-10-12 22:20:43.957780:	Training iteration: 834, Loss: 0.005306660197675228
2018-10-12 22:22:35.980992:	Training iteration: 835, Loss: 0.0038709796499460936
2018-10-12 22:24:27.411306:	Training iteration: 836, Loss: 0.0058678570203483105
2018-10-12 22:26:19.396113:	Training iteration: 837, Loss: 0.0049954913556575775
2018-10-12 22:28:09.561252:	Training iteration: 838, Loss: 0.0050182705745100975
2018-10-12 22:30:00.920292:	Training iteration: 839, Loss: 0.005301075521856546
2018-10-12 22:31:53.041137:	Training iteration: 840, Loss: 0.004914510063827038
2018-10-12 22:33:45.896260:	Training iteration: 841, Loss: 0.006190462037920952
2018-10-12 22:35:38.775549:	Training iteration: 842, Loss: 0.005156044848263264
2018-10-12 22:37:31.781285:	Training iteration: 843, Loss: 0.005220884922891855
2018-10-12 22:39:25.386790:	Training iteration: 844, Loss: 0.0062874434515833855
2018-10-12 22:41:19.381394:	Training iteration: 845, Loss: 0.007788541726768017
2018-10-12 22:43:12.565329:	Training iteration: 846, Loss: 0.005835016258060932
2018-10-12 22:45:05.969618:	Training iteration: 847, Loss: 0.0056271604262292385
2018-10-12 22:47:00.799892:	Training iteration: 848, Loss: 0.004752719309180975
2018-10-12 22:48:54.968514:	Training iteration: 849, Loss: 0.004080883227288723
2018-10-12 22:50:47.670937:	Training iteration: 850, Loss: 0.006989789195358753
2018-10-12 22:52:37.418852:	Training iteration: 851, Loss: 0.005864409729838371
2018-10-12 22:54:31.741249:	Training iteration: 852, Loss: 0.004312015138566494
2018-10-12 22:56:23.243868:	Training iteration: 853, Loss: 0.004600089974701405
2018-10-12 22:58:16.664330:	Training iteration: 854, Loss: 0.004797336645424366
2018-10-12 23:00:06.547773:	Training iteration: 855, Loss: 0.006292673759162426
2018-10-12 23:01:59.238542:	Training iteration: 856, Loss: 0.0050183250568807125
2018-10-12 23:03:49.220396:	Training iteration: 857, Loss: 0.004863402806222439
2018-10-12 23:05:40.995842:	Training iteration: 858, Loss: 0.004994870629161596
2018-10-12 23:07:33.357837:	Training iteration: 859, Loss: 0.004570216406136751
2018-10-12 23:09:23.911930:	Training iteration: 860, Loss: 0.005390343721956015
2018-10-12 23:11:18.764422:	Training iteration: 861, Loss: 0.004554589278995991
2018-10-12 23:13:11.401553:	Training iteration: 862, Loss: 0.0053227865137159824
2018-10-12 23:15:02.431334:	Training iteration: 863, Loss: 0.005437055602669716
2018-10-12 23:16:54.183435:	Training iteration: 864, Loss: 0.00541249243542552
2018-10-12 23:18:46.514239:	Training iteration: 865, Loss: 0.006213759537786245
2018-10-12 23:20:39.921942:	Training iteration: 866, Loss: 0.00501635018736124
2018-10-12 23:22:32.182954:	Training iteration: 867, Loss: 0.004563766997307539
2018-10-12 23:24:23.066115:	Training iteration: 868, Loss: 0.006064277142286301
2018-10-12 23:26:16.418140:	Training iteration: 869, Loss: 0.005648261867463589
2018-10-12 23:28:10.033960:	Training iteration: 870, Loss: 0.004426561761647463
2018-10-12 23:30:05.211353:	Training iteration: 871, Loss: 0.0039294506423175335
2018-10-12 23:31:59.645721:	Training iteration: 872, Loss: 0.00464904448017478
2018-10-12 23:33:51.000873:	Training iteration: 873, Loss: 0.005273232702165842
2018-10-12 23:35:41.692713:	Training iteration: 874, Loss: 0.005161515437066555
2018-10-12 23:37:34.988429:	Training iteration: 875, Loss: 0.004917780868709087
2018-10-12 23:39:27.617810:	Training iteration: 876, Loss: 0.005683826748281717
2018-10-12 23:41:23.364279:	Training iteration: 877, Loss: 0.004296222236007452
2018-10-12 23:43:15.354317:	Training iteration: 878, Loss: 0.005707823671400547
2018-10-12 23:45:11.106332:	Training iteration: 879, Loss: 0.004403275903314352
2018-10-12 23:47:05.027315:	Training iteration: 880, Loss: 0.005199243780225515
2018-10-12 23:48:56.319842:	Training iteration: 881, Loss: 0.00563681498169899
2018-10-12 23:50:49.938190:	Training iteration: 882, Loss: 0.005281447898596525
2018-10-12 23:52:43.141079:	Training iteration: 883, Loss: 0.002784427721053362
2018-10-12 23:54:37.006528:	Training iteration: 884, Loss: 0.004950885660946369
2018-10-12 23:56:30.109804:	Training iteration: 885, Loss: 0.005981282331049442
2018-10-12 23:58:25.294143:	Training iteration: 886, Loss: 0.004692365415394306
2018-10-13 00:00:15.922005:	Training iteration: 887, Loss: 0.005320612341165543
2018-10-13 00:02:08.444218:	Training iteration: 888, Loss: 0.006017668638378382
2018-10-13 00:03:59.343659:	Training iteration: 889, Loss: 0.006279011256992817
2018-10-13 00:05:52.165444:	Training iteration: 890, Loss: 0.004413927905261517
2018-10-13 00:07:42.675074:	Training iteration: 891, Loss: 0.00630523357540369
2018-10-13 00:09:38.687605:	Training iteration: 892, Loss: 0.005816857796162367
2018-10-13 00:11:33.035104:	Training iteration: 893, Loss: 0.004690783564001322
2018-10-13 00:13:26.291233:	Training iteration: 894, Loss: 0.005650972481817007
2018-10-13 00:15:17.949390:	Training iteration: 895, Loss: 0.005034760106354952
2018-10-13 00:17:09.251047:	Training iteration: 896, Loss: 0.00544740492478013
2018-10-13 00:19:04.741784:	Training iteration: 897, Loss: 0.004511569626629353
2018-10-13 00:20:57.621143:	Training iteration: 898, Loss: 0.004926398862153292
2018-10-13 00:22:49.307466:	Training iteration: 899, Loss: 0.00428881635889411
2018-10-13 00:24:42.975733:	Training iteration: 900, Loss: 0.00560027128085494
2018-10-13 00:26:35.286653:	Training iteration: 901, Loss: 0.005090143997222185
2018-10-13 00:28:28.387639:	Training iteration: 902, Loss: 0.005184921436011791
2018-10-13 00:30:21.122661:	Training iteration: 903, Loss: 0.005374337546527386
2018-10-13 00:32:16.767342:	Training iteration: 904, Loss: 0.00438196724280715
2018-10-13 00:34:10.207232:	Training iteration: 905, Loss: 0.004630996845662594
2018-10-13 00:36:00.324077:	Training iteration: 906, Loss: 0.005110641475766897
2018-10-13 00:37:51.590502:	Training iteration: 907, Loss: 0.0066077872179448605
2018-10-13 00:39:44.591722:	Training iteration: 908, Loss: 0.004067949950695038
2018-10-13 00:41:38.867666:	Training iteration: 909, Loss: 0.005252552684396505
2018-10-13 00:43:32.335936:	Training iteration: 910, Loss: 0.0043077366426587105
2018-10-13 00:45:24.650569:	Training iteration: 911, Loss: 0.004738260060548782
2018-10-13 00:47:17.955531:	Training iteration: 912, Loss: 0.004310765769332647
2018-10-13 00:49:11.859908:	Training iteration: 913, Loss: 0.005611337721347809
2018-10-13 00:51:04.492220:	Training iteration: 914, Loss: 0.004174990113824606
2018-10-13 00:52:57.290086:	Training iteration: 915, Loss: 0.004082038067281246
2018-10-13 00:54:49.388937:	Training iteration: 916, Loss: 0.0036180070601403713
2018-10-13 00:56:41.571377:	Training iteration: 917, Loss: 0.003575251903384924
2018-10-13 00:58:33.822936:	Training iteration: 918, Loss: 0.0062980265356600285
2018-10-13 01:00:27.142335:	Training iteration: 919, Loss: 0.005375111009925604
2018-10-13 01:02:21.590584:	Training iteration: 920, Loss: 0.004969650413841009
2018-10-13 01:04:16.007840:	Training iteration: 921, Loss: 0.0043656425550580025
2018-10-13 01:06:07.695663:	Training iteration: 922, Loss: 0.005638921167701483
2018-10-13 01:07:59.302943:	Training iteration: 923, Loss: 0.0059221647679805756
2018-10-13 01:09:50.950909:	Training iteration: 924, Loss: 0.00385482469573617
2018-10-13 01:11:42.863944:	Training iteration: 925, Loss: 0.006347681395709515
2018-10-13 01:13:34.905109:	Training iteration: 926, Loss: 0.003864190075546503
2018-10-13 01:15:29.603387:	Training iteration: 927, Loss: 0.00688219303265214
2018-10-13 01:17:23.928713:	Training iteration: 928, Loss: 0.004154877737164497
2018-10-13 01:19:19.235289:	Training iteration: 929, Loss: 0.005223357118666172
2018-10-13 01:21:10.196450:	Training iteration: 930, Loss: 0.0047826701775193214
2018-10-13 01:23:04.107751:	Training iteration: 931, Loss: 0.004811911843717098
2018-10-13 01:25:00.899503:	Training iteration: 932, Loss: 0.005347554571926594
2018-10-13 01:26:55.380314:	Training iteration: 933, Loss: 0.007536913268268108
2018-10-13 01:28:46.344540:	Training iteration: 934, Loss: 0.0047572338953614235
2018-10-13 01:30:37.541474:	Training iteration: 935, Loss: 0.005961121525615454
2018-10-13 01:32:29.957588:	Training iteration: 936, Loss: 0.005054903216660023
2018-10-13 01:34:23.498955:	Training iteration: 937, Loss: 0.004754586145281792
2018-10-13 01:36:19.910428:	Training iteration: 938, Loss: 0.005214817356318235
2018-10-13 01:38:15.778105:	Training iteration: 939, Loss: 0.004970239941030741
2018-10-13 01:40:08.641373:	Training iteration: 940, Loss: 0.0050565386191010475
2018-10-13 01:42:02.372561:	Training iteration: 941, Loss: 0.004960204008966684
2018-10-13 01:43:53.015545:	Training iteration: 942, Loss: 0.007312925066798925
2018-10-13 01:45:45.240303:	Training iteration: 943, Loss: 0.004617634229362011
2018-10-13 01:47:37.184161:	Training iteration: 944, Loss: 0.004267482552677393
2018-10-13 01:49:30.020903:	Training iteration: 945, Loss: 0.003970116842538118
2018-10-13 01:51:24.566023:	Training iteration: 946, Loss: 0.005250162445008755
2018-10-13 01:53:21.181545:	Training iteration: 947, Loss: 0.0042329998686909676
2018-10-13 01:55:13.687673:	Training iteration: 948, Loss: 0.006533188279718161
2018-10-13 01:57:04.994926:	Training iteration: 949, Loss: 0.005834080278873444
2018-10-13 01:58:58.844498:	Training iteration: 950, Loss: 0.00559832900762558
2018-10-13 02:00:51.090029:	Training iteration: 951, Loss: 0.0055210222490131855
2018-10-13 02:02:45.945041:	Training iteration: 952, Loss: 0.00616616802290082
2018-10-13 02:04:39.669261:	Training iteration: 953, Loss: 0.005926978774368763
2018-10-13 02:06:32.072049:	Training iteration: 954, Loss: 0.003993279300630093
2018-10-13 02:08:26.902476:	Training iteration: 955, Loss: 0.0066178785637021065
2018-10-13 02:10:21.225852:	Training iteration: 956, Loss: 0.007830576039850712
2018-10-13 02:12:12.726886:	Training iteration: 957, Loss: 0.004783082753419876
2018-10-13 02:14:05.673991:	Training iteration: 958, Loss: 0.00533120846375823
2018-10-13 02:15:58.513781:	Training iteration: 959, Loss: 0.005426461808383465
2018-10-13 02:17:49.852545:	Training iteration: 960, Loss: 0.005898520350456238
2018-10-13 02:19:43.725598:	Training iteration: 961, Loss: 0.004847709555178881
2018-10-13 02:21:34.925505:	Training iteration: 962, Loss: 0.005038013216108084
2018-10-13 02:23:30.548483:	Training iteration: 963, Loss: 0.0035395727027207613
2018-10-13 02:25:24.614430:	Training iteration: 964, Loss: 0.005366592667996883
2018-10-13 02:27:20.460712:	Training iteration: 965, Loss: 0.0046829781495034695
2018-10-13 02:29:12.047477:	Training iteration: 966, Loss: 0.005468248389661312
2018-10-13 02:31:07.125383:	Training iteration: 967, Loss: 0.004258814267814159
2018-10-13 02:33:03.317601:	Training iteration: 968, Loss: 0.004393852315843105
2018-10-13 02:34:54.977265:	Training iteration: 969, Loss: 0.006636456586420536
2018-10-13 02:36:48.302743:	Training iteration: 970, Loss: 0.004796321969479322
2018-10-13 02:38:43.002322:	Training iteration: 971, Loss: 0.0063422308303415775
2018-10-13 02:40:36.012748:	Training iteration: 972, Loss: 0.005199749954044819
2018-10-13 02:42:32.164348:	Training iteration: 973, Loss: 0.005586673505604267
2018-10-13 02:44:24.680060:	Training iteration: 974, Loss: 0.008104461245238781
2018-10-13 02:46:19.330092:	Training iteration: 975, Loss: 0.004930512513965368
2018-10-13 02:48:15.812711:	Training iteration: 976, Loss: 0.004846592899411917
2018-10-13 02:50:07.931927:	Training iteration: 977, Loss: 0.004498676396906376
2018-10-13 02:52:01.600651:	Training iteration: 978, Loss: 0.0056498912163078785
2018-10-13 02:53:53.991536:	Training iteration: 979, Loss: 0.006425858940929174
2018-10-13 02:55:47.525380:	Training iteration: 980, Loss: 0.004409173037856817
2018-10-13 02:57:42.592728:	Training iteration: 981, Loss: 0.004036847501993179
2018-10-13 02:59:35.574315:	Training iteration: 982, Loss: 0.005159106105566025
2018-10-13 03:01:28.476044:	Training iteration: 983, Loss: 0.004145494196563959
2018-10-13 03:03:21.359614:	Training iteration: 984, Loss: 0.005339602008461952
2018-10-13 03:05:13.936867:	Training iteration: 985, Loss: 0.004537350498139858
2018-10-13 03:07:07.625873:	Training iteration: 986, Loss: 0.0058153229765594006
2018-10-13 03:09:01.750576:	Training iteration: 987, Loss: 0.0063963383436203
2018-10-13 03:10:56.518539:	Training iteration: 988, Loss: 0.005007956642657518
2018-10-13 03:12:48.397465:	Training iteration: 989, Loss: 0.006509999744594097
2018-10-13 03:14:40.380989:	Training iteration: 990, Loss: 0.004742004442960024
2018-10-13 03:16:33.505194:	Training iteration: 991, Loss: 0.004724054131656885
2018-10-13 03:18:28.851025:	Training iteration: 992, Loss: 0.005869881249964237
2018-10-13 03:20:22.043360:	Training iteration: 993, Loss: 0.005112280137836933
2018-10-13 03:22:14.379116:	Training iteration: 994, Loss: 0.004850462544709444
2018-10-13 03:24:08.701477:	Training iteration: 995, Loss: 0.005838868673890829
2018-10-13 03:26:02.546405:	Training iteration: 996, Loss: 0.004963869694620371
2018-10-13 03:27:55.211691:	Training iteration: 997, Loss: 0.005808535031974316
2018-10-13 03:29:47.143778:	Training iteration: 998, Loss: 0.004586519207805395
2018-10-13 03:31:37.385548:	Training iteration: 999, Loss: 0.005031359847635031
2018-10-13 03:33:33.215210:	Training iteration: 1000, Loss: 0.006545735988765955
Checkpoint
2018-10-13 03:35:34.359210:	Training iteration: 1001, Loss: 0.003493234980851412
2018-10-13 03:37:28.365767:	Training iteration: 1002, Loss: 0.00520166102796793
2018-10-13 03:39:26.776665:	Training iteration: 1003, Loss: 0.006385273300111294
2018-10-13 03:41:23.916271:	Training iteration: 1004, Loss: 0.004140667617321014
2018-10-13 03:43:22.053652:	Training iteration: 1005, Loss: 0.0052959006279706955
2018-10-13 03:45:18.111040:	Training iteration: 1006, Loss: 0.0043230121955275536
2018-10-13 03:47:13.362079:	Training iteration: 1007, Loss: 0.006207723636180162
2018-10-13 03:49:07.471209:	Training iteration: 1008, Loss: 0.005651257466524839
2018-10-13 03:51:01.822708:	Training iteration: 1009, Loss: 0.0040160613134503365
2018-10-13 03:52:57.346547:	Training iteration: 1010, Loss: 0.0052424268797039986
2018-10-13 03:54:50.242688:	Training iteration: 1011, Loss: 0.004438423551619053
2018-10-13 03:56:43.784319:	Training iteration: 1012, Loss: 0.00576366949826479
2018-10-13 03:58:35.608297:	Training iteration: 1013, Loss: 0.005705595947802067
2018-10-13 04:00:29.738581:	Training iteration: 1014, Loss: 0.005385817959904671
2018-10-13 04:02:24.117127:	Training iteration: 1015, Loss: 0.007762125227600336
2018-10-13 04:04:16.578175:	Training iteration: 1016, Loss: 0.005246189422905445
2018-10-13 04:06:07.085068:	Training iteration: 1017, Loss: 0.005132623948156834
2018-10-13 04:08:02.629194:	Training iteration: 1018, Loss: 0.006000911816954613
2018-10-13 04:09:56.489775:	Training iteration: 1019, Loss: 0.005352213978767395
2018-10-13 04:11:48.239959:	Training iteration: 1020, Loss: 0.0034831236116588116
2018-10-13 04:13:41.733208:	Training iteration: 1021, Loss: 0.005647884216159582
2018-10-13 04:15:33.684341:	Training iteration: 1022, Loss: 0.005457199644297361
2018-10-13 04:17:27.957696:	Training iteration: 1023, Loss: 0.0048321811482310295
2018-10-13 04:19:22.755989:	Training iteration: 1024, Loss: 0.005708985961973667
2018-10-13 04:21:16.922136:	Training iteration: 1025, Loss: 0.006783054675906897
2018-10-13 04:23:10.422467:	Training iteration: 1026, Loss: 0.0077484361827373505
2018-10-13 04:25:01.582955:	Training iteration: 1027, Loss: 0.006153859663754702
2018-10-13 04:26:53.368407:	Training iteration: 1028, Loss: 0.0045094178058207035
2018-10-13 04:28:49.275231:	Training iteration: 1029, Loss: 0.003976142033934593
2018-10-13 04:30:41.329574:	Training iteration: 1030, Loss: 0.005255514290183783
2018-10-13 04:32:35.031583:	Training iteration: 1031, Loss: 0.005941000767052174
2018-10-13 04:34:28.948463:	Training iteration: 1032, Loss: 0.0046393112279474735
2018-10-13 04:36:22.337412:	Training iteration: 1033, Loss: 0.0057401834055781364
2018-10-13 04:38:16.496210:	Training iteration: 1034, Loss: 0.004051449708640575
2018-10-13 04:40:12.824615:	Training iteration: 1035, Loss: 0.0038208093028515577
2018-10-13 04:42:04.603230:	Training iteration: 1036, Loss: 0.004129558801651001
2018-10-13 04:43:57.691348:	Training iteration: 1037, Loss: 0.005277196876704693
2018-10-13 04:45:51.221779:	Training iteration: 1038, Loss: 0.0053087277337908745
2018-10-13 04:47:45.086995:	Training iteration: 1039, Loss: 0.004960043355822563
2018-10-13 04:49:42.321475:	Training iteration: 1040, Loss: 0.004934770055115223
2018-10-13 04:51:36.643992:	Training iteration: 1041, Loss: 0.005483065731823444
2018-10-13 04:53:29.778117:	Training iteration: 1042, Loss: 0.0056271180510520935
2018-10-13 04:55:24.936199:	Training iteration: 1043, Loss: 0.004247893579304218
2018-10-13 04:57:21.707445:	Training iteration: 1044, Loss: 0.005669762380421162
2018-10-13 04:59:14.982700:	Training iteration: 1045, Loss: 0.004641521722078323
2018-10-13 05:01:07.372533:	Training iteration: 1046, Loss: 0.005127440206706524
2018-10-13 05:03:03.764065:	Training iteration: 1047, Loss: 0.005515557713806629
2018-10-13 05:04:56.126959:	Training iteration: 1048, Loss: 0.004859349690377712
2018-10-13 05:06:49.781774:	Training iteration: 1049, Loss: 0.004769427701830864
2018-10-13 05:08:43.941459:	Training iteration: 1050, Loss: 0.005971378646790981
2018-10-13 05:10:38.440362:	Training iteration: 1051, Loss: 0.005679454654455185
2018-10-13 05:12:31.656490:	Training iteration: 1052, Loss: 0.005813212133944035
2018-10-13 05:14:25.467189:	Training iteration: 1053, Loss: 0.005170968361198902
2018-10-13 05:16:20.747847:	Training iteration: 1054, Loss: 0.006330139935016632
2018-10-13 05:18:13.019961:	Training iteration: 1055, Loss: 0.005006952676922083
2018-10-13 05:20:08.068580:	Training iteration: 1056, Loss: 0.0056191557087004185
2018-10-13 05:22:03.614354:	Training iteration: 1057, Loss: 0.006266162730753422
2018-10-13 05:23:55.833564:	Training iteration: 1058, Loss: 0.004983111750334501
2018-10-13 05:25:49.998095:	Training iteration: 1059, Loss: 0.004606856964528561
2018-10-13 05:27:44.240641:	Training iteration: 1060, Loss: 0.006592762656509876
2018-10-13 05:29:35.941627:	Training iteration: 1061, Loss: 0.0059935906901955605
2018-10-13 05:31:29.718886:	Training iteration: 1062, Loss: 0.007984951138496399
2018-10-13 05:33:21.080345:	Training iteration: 1063, Loss: 0.004820133559405804
2018-10-13 05:35:11.815948:	Training iteration: 1064, Loss: 0.0045572565868496895
2018-10-13 05:37:05.894519:	Training iteration: 1065, Loss: 0.006204930134117603
2018-10-13 05:38:57.787602:	Training iteration: 1066, Loss: 0.004491104744374752
2018-10-13 05:40:51.954498:	Training iteration: 1067, Loss: 0.005251378286629915
2018-10-13 05:42:45.286513:	Training iteration: 1068, Loss: 0.005917639471590519
2018-10-13 05:44:38.138204:	Training iteration: 1069, Loss: 0.005084224510937929
2018-10-13 05:46:31.698945:	Training iteration: 1070, Loss: 0.0047376034781336784
2018-10-13 05:48:23.873485:	Training iteration: 1071, Loss: 0.005464592017233372
2018-10-13 05:50:15.582359:	Training iteration: 1072, Loss: 0.004570122808218002
2018-10-13 05:52:07.675626:	Training iteration: 1073, Loss: 0.0035472672898322344
2018-10-13 05:54:01.920501:	Training iteration: 1074, Loss: 0.003799429163336754
2018-10-13 05:55:55.553333:	Training iteration: 1075, Loss: 0.003925253637135029
2018-10-13 05:57:51.552077:	Training iteration: 1076, Loss: 0.005041866563260555
2018-10-13 05:59:46.564086:	Training iteration: 1077, Loss: 0.005857179872691631
2018-10-13 06:01:40.179682:	Training iteration: 1078, Loss: 0.004481894429773092
2018-10-13 06:03:32.311156:	Training iteration: 1079, Loss: 0.005872177891433239
2018-10-13 06:05:25.526398:	Training iteration: 1080, Loss: 0.0071082450449466705
2018-10-13 06:07:24.530042:	Training iteration: 1081, Loss: 0.005588981788605452
2018-10-13 06:09:18.188081:	Training iteration: 1082, Loss: 0.009126437827944756
2018-10-13 06:11:11.861183:	Training iteration: 1083, Loss: 0.006925208028405905
2018-10-13 06:13:08.489395:	Training iteration: 1084, Loss: 0.004975271876901388
2018-10-13 06:15:02.284236:	Training iteration: 1085, Loss: 0.005618202965706587
2018-10-13 06:16:54.034754:	Training iteration: 1086, Loss: 0.005230548791587353
2018-10-13 06:18:47.344480:	Training iteration: 1087, Loss: 0.0062415446154773235
2018-10-13 06:20:37.923545:	Training iteration: 1088, Loss: 0.0052507128566503525
2018-10-13 06:22:31.605373:	Training iteration: 1089, Loss: 0.004792744759470224
2018-10-13 06:24:25.088946:	Training iteration: 1090, Loss: 0.006035566329956055
2018-10-13 06:26:17.430363:	Training iteration: 1091, Loss: 0.005852450616657734
2018-10-13 06:28:10.067638:	Training iteration: 1092, Loss: 0.007040216121822596
2018-10-13 06:30:01.946314:	Training iteration: 1093, Loss: 0.005628232844173908
2018-10-13 06:31:54.759149:	Training iteration: 1094, Loss: 0.005233175121247768
2018-10-13 06:33:51.352979:	Training iteration: 1095, Loss: 0.004488921258598566
2018-10-13 06:35:47.506642:	Training iteration: 1096, Loss: 0.005775295197963715
2018-10-13 06:37:42.687230:	Training iteration: 1097, Loss: 0.005844307132065296
2018-10-13 06:39:35.540600:	Training iteration: 1098, Loss: 0.004873836413025856
2018-10-13 06:41:31.633856:	Training iteration: 1099, Loss: 0.004898251034319401
2018-10-13 06:43:25.084651:	Training iteration: 1100, Loss: 0.005672309082001448
2018-10-13 06:45:18.315916:	Training iteration: 1101, Loss: 0.007121783681213856
2018-10-13 06:47:09.264677:	Training iteration: 1102, Loss: 0.004725092556327581
2018-10-13 06:49:03.969058:	Training iteration: 1103, Loss: 0.0041311075910925865
2018-10-13 06:50:56.463303:	Training iteration: 1104, Loss: 0.004811682738363743
2018-10-13 06:52:52.459808:	Training iteration: 1105, Loss: 0.0038091042079031467
2018-10-13 06:54:46.770041:	Training iteration: 1106, Loss: 0.005791069008409977
2018-10-13 06:56:39.963824:	Training iteration: 1107, Loss: 0.005163033492863178
2018-10-13 06:58:35.247230:	Training iteration: 1108, Loss: 0.006363713648170233
2018-10-13 07:00:28.843985:	Training iteration: 1109, Loss: 0.004388061352074146
2018-10-13 07:02:21.866480:	Training iteration: 1110, Loss: 0.004955917596817017
2018-10-13 07:04:14.592990:	Training iteration: 1111, Loss: 0.005597768817096949
2018-10-13 07:06:07.295680:	Training iteration: 1112, Loss: 0.0048473672941327095
2018-10-13 07:08:00.302671:	Training iteration: 1113, Loss: 0.004508557263761759
2018-10-13 07:09:55.895648:	Training iteration: 1114, Loss: 0.00601526815444231
2018-10-13 07:11:47.392946:	Training iteration: 1115, Loss: 0.005680836737155914
2018-10-13 07:13:40.804732:	Training iteration: 1116, Loss: 0.0040512364357709885
2018-10-13 07:15:36.810163:	Training iteration: 1117, Loss: 0.006505866535007954
2018-10-13 07:17:29.535770:	Training iteration: 1118, Loss: 0.005761238746345043
2018-10-13 07:19:22.153636:	Training iteration: 1119, Loss: 0.006371374242007732
2018-10-13 07:21:13.616362:	Training iteration: 1120, Loss: 0.0046776821836829185
2018-10-13 07:23:08.015243:	Training iteration: 1121, Loss: 0.007451047655194998
2018-10-13 07:24:59.775936:	Training iteration: 1122, Loss: 0.006051348987966776
2018-10-13 07:26:53.547510:	Training iteration: 1123, Loss: 0.0068030403926968575
2018-10-13 07:28:44.092858:	Training iteration: 1124, Loss: 0.005592655390501022
2018-10-13 07:30:37.019023:	Training iteration: 1125, Loss: 0.005532334558665752
2018-10-13 07:32:29.691822:	Training iteration: 1126, Loss: 0.0058577535673975945
2018-10-13 07:34:23.829344:	Training iteration: 1127, Loss: 0.005347592290490866
2018-10-13 07:36:20.854355:	Training iteration: 1128, Loss: 0.004479934461414814
2018-10-13 07:38:15.097838:	Training iteration: 1129, Loss: 0.004278924316167831
2018-10-13 07:40:12.174486:	Training iteration: 1130, Loss: 0.005344051867723465
2018-10-13 07:42:05.199575:	Training iteration: 1131, Loss: 0.006276416592299938
2018-10-13 07:43:59.474625:	Training iteration: 1132, Loss: 0.004635265097022057
2018-10-13 07:45:58.662286:	Training iteration: 1133, Loss: 0.005349511746317148
2018-10-13 07:47:55.443895:	Training iteration: 1134, Loss: 0.004416555631905794
2018-10-13 07:49:52.870819:	Training iteration: 1135, Loss: 0.005267246626317501
2018-10-13 07:51:49.089640:	Training iteration: 1136, Loss: 0.0062355888076126575
2018-10-13 07:53:43.703121:	Training iteration: 1137, Loss: 0.0057761697098612785
2018-10-13 07:55:38.182807:	Training iteration: 1138, Loss: 0.006698795594274998
2018-10-13 07:57:34.094056:	Training iteration: 1139, Loss: 0.004685486666858196
2018-10-13 07:59:29.271841:	Training iteration: 1140, Loss: 0.0037568151019513607
2018-10-13 08:01:25.997891:	Training iteration: 1141, Loss: 0.006280715577304363
2018-10-13 08:03:22.627400:	Training iteration: 1142, Loss: 0.004603723529726267
2018-10-13 08:05:13.045827:	Training iteration: 1143, Loss: 0.005691391881555319
2018-10-13 08:07:03.544848:	Training iteration: 1144, Loss: 0.0077428147196769714
2018-10-13 08:08:54.362544:	Training iteration: 1145, Loss: 0.007032984402030706
2018-10-13 08:10:48.019254:	Training iteration: 1146, Loss: 0.005511150695383549
2018-10-13 08:12:43.728370:	Training iteration: 1147, Loss: 0.00444954726845026
2018-10-13 08:14:39.479512:	Training iteration: 1148, Loss: 0.009037565439939499
2018-10-13 08:16:33.245510:	Training iteration: 1149, Loss: 0.006299364380538464
2018-10-13 08:18:23.982247:	Training iteration: 1150, Loss: 0.00330081838183105
2018-10-13 08:20:16.973742:	Training iteration: 1151, Loss: 0.005313630681484938
2018-10-13 08:22:10.378048:	Training iteration: 1152, Loss: 0.005177016369998455
2018-10-13 08:24:04.519772:	Training iteration: 1153, Loss: 0.005335919093340635
2018-10-13 08:25:58.953726:	Training iteration: 1154, Loss: 0.004995460156351328
2018-10-13 08:27:52.465619:	Training iteration: 1155, Loss: 0.005354475695639849
2018-10-13 08:29:46.443271:	Training iteration: 1156, Loss: 0.005212108138948679
2018-10-13 08:31:37.944453:	Training iteration: 1157, Loss: 0.007830947637557983
2018-10-13 08:33:29.493573:	Training iteration: 1158, Loss: 0.006040395237505436
2018-10-13 08:35:23.831184:	Training iteration: 1159, Loss: 0.006313186138868332
2018-10-13 08:37:18.378910:	Training iteration: 1160, Loss: 0.005692801438271999
2018-10-13 08:39:10.833613:	Training iteration: 1161, Loss: 0.005431339610368013
2018-10-13 08:41:05.666082:	Training iteration: 1162, Loss: 0.0067926435731351376
2018-10-13 08:43:01.809129:	Training iteration: 1163, Loss: 0.0054667978547513485
2018-10-13 08:44:57.314351:	Training iteration: 1164, Loss: 0.004708940628916025
2018-10-13 08:46:51.175655:	Training iteration: 1165, Loss: 0.005435676779597998
2018-10-13 08:48:44.545595:	Training iteration: 1166, Loss: 0.005571681074798107
2018-10-13 08:50:38.912989:	Training iteration: 1167, Loss: 0.0072832657024264336
2018-10-13 08:52:30.414861:	Training iteration: 1168, Loss: 0.005285993218421936
2018-10-13 08:54:27.190732:	Training iteration: 1169, Loss: 0.0037344966549426317
2018-10-13 08:56:20.542568:	Training iteration: 1170, Loss: 0.006112777628004551
2018-10-13 08:58:15.052038:	Training iteration: 1171, Loss: 0.0050826892256736755
2018-10-13 09:00:08.017140:	Training iteration: 1172, Loss: 0.004999014548957348
2018-10-13 09:02:03.731064:	Training iteration: 1173, Loss: 0.004502161405980587
2018-10-13 09:03:57.794668:	Training iteration: 1174, Loss: 0.004729533102363348
2018-10-13 09:05:53.277543:	Training iteration: 1175, Loss: 0.005269908346235752
2018-10-13 09:07:46.936843:	Training iteration: 1176, Loss: 0.005841035395860672
2018-10-13 09:09:40.659914:	Training iteration: 1177, Loss: 0.003957408480346203
2018-10-13 09:11:37.200049:	Training iteration: 1178, Loss: 0.006757476832717657
2018-10-13 09:13:30.306688:	Training iteration: 1179, Loss: 0.0060567534528672695
2018-10-13 09:15:24.296904:	Training iteration: 1180, Loss: 0.00500054145231843
2018-10-13 09:17:18.358804:	Training iteration: 1181, Loss: 0.005810887087136507
2018-10-13 09:19:10.273258:	Training iteration: 1182, Loss: 0.00490018492564559
2018-10-13 09:21:04.604828:	Training iteration: 1183, Loss: 0.005684774834662676
2018-10-13 09:22:59.673931:	Training iteration: 1184, Loss: 0.004396919161081314
2018-10-13 09:24:52.304463:	Training iteration: 1185, Loss: 0.005539244972169399
2018-10-13 09:26:41.167779:	Training iteration: 1186, Loss: 0.006325668189674616
2018-10-13 09:28:35.207643:	Training iteration: 1187, Loss: 0.004214592278003693
2018-10-13 09:30:25.737233:	Training iteration: 1188, Loss: 0.006731802131980658
2018-10-13 09:32:21.208882:	Training iteration: 1189, Loss: 0.006271676626056433
2018-10-13 09:34:17.250510:	Training iteration: 1190, Loss: 0.004653216805309057
2018-10-13 09:36:13.688412:	Training iteration: 1191, Loss: 0.004492518957704306
2018-10-13 09:38:06.628608:	Training iteration: 1192, Loss: 0.004138606134802103
2018-10-13 09:40:00.496450:	Training iteration: 1193, Loss: 0.0058736191131174564
2018-10-13 09:41:53.852417:	Training iteration: 1194, Loss: 0.0063512735068798065
2018-10-13 09:43:45.651778:	Training iteration: 1195, Loss: 0.006130184978246689
2018-10-13 09:45:39.166535:	Training iteration: 1196, Loss: 0.0046345847658813
2018-10-13 09:47:29.474663:	Training iteration: 1197, Loss: 0.00477088475599885
2018-10-13 09:49:21.606985:	Training iteration: 1198, Loss: 0.005072874017059803
2018-10-13 09:51:16.191156:	Training iteration: 1199, Loss: 0.00460185157135129
2018-10-13 09:53:09.138262:	Training iteration: 1200, Loss: 0.005147202871739864
2018-10-13 09:55:05.006170:	Training iteration: 1201, Loss: 0.00610151793807745
2018-10-13 09:56:57.151404:	Training iteration: 1202, Loss: 0.00430686678737402
2018-10-13 09:58:50.842630:	Training iteration: 1203, Loss: 0.004849463701248169
2018-10-13 10:00:44.185511:	Training iteration: 1204, Loss: 0.00611183512955904
2018-10-13 10:02:39.120849:	Training iteration: 1205, Loss: 0.0070149824023246765
2018-10-13 10:04:33.541269:	Training iteration: 1206, Loss: 0.006656757090240717
2018-10-13 10:06:27.632181:	Training iteration: 1207, Loss: 0.005274225026369095
2018-10-13 10:08:21.414368:	Training iteration: 1208, Loss: 0.004468594677746296
2018-10-13 10:10:11.898179:	Training iteration: 1209, Loss: 0.004099281970411539
2018-10-13 10:12:06.738504:	Training iteration: 1210, Loss: 0.004575773142278194
2018-10-13 10:13:59.276463:	Training iteration: 1211, Loss: 0.005060712806880474
2018-10-13 10:15:48.999286:	Training iteration: 1212, Loss: 0.005557962693274021
2018-10-13 10:17:41.911379:	Training iteration: 1213, Loss: 0.004892623517662287
2018-10-13 10:19:33.755325:	Training iteration: 1214, Loss: 0.004907590337097645
2018-10-13 10:21:29.363872:	Training iteration: 1215, Loss: 0.005345816258341074
2018-10-13 10:23:24.545475:	Training iteration: 1216, Loss: 0.004464027937501669
2018-10-13 10:25:18.569891:	Training iteration: 1217, Loss: 0.005005663726478815
2018-10-13 10:27:15.058452:	Training iteration: 1218, Loss: 0.0076163532212376595
2018-10-13 10:29:10.914337:	Training iteration: 1219, Loss: 0.004442958161234856
2018-10-13 10:31:05.684090:	Training iteration: 1220, Loss: 0.005090481135994196
2018-10-13 10:32:58.447924:	Training iteration: 1221, Loss: 0.005343875847756863
2018-10-13 10:34:52.816941:	Training iteration: 1222, Loss: 0.00478169322013855
2018-10-13 10:36:46.106898:	Training iteration: 1223, Loss: 0.0059185815043747425
2018-10-13 10:38:38.963916:	Training iteration: 1224, Loss: 0.006246146280318499
2018-10-13 10:40:31.209644:	Training iteration: 1225, Loss: 0.0071754008531570435
2018-10-13 10:42:26.652214:	Training iteration: 1226, Loss: 0.004627516958862543
2018-10-13 10:44:21.309314:	Training iteration: 1227, Loss: 0.005350370425730944
2018-10-13 10:46:13.264452:	Training iteration: 1228, Loss: 0.006147963460534811
2018-10-13 10:48:08.769085:	Training iteration: 1229, Loss: 0.0062975226901471615
2018-10-13 10:50:02.496735:	Training iteration: 1230, Loss: 0.004744858015328646
2018-10-13 10:51:54.057177:	Training iteration: 1231, Loss: 0.003992958460003138
2018-10-13 10:53:51.166553:	Training iteration: 1232, Loss: 0.005935183726251125
2018-10-13 10:55:48.837721:	Training iteration: 1233, Loss: 0.004740291740745306
2018-10-13 10:57:44.371130:	Training iteration: 1234, Loss: 0.0042824880219995975
2018-10-13 10:59:39.667050:	Training iteration: 1235, Loss: 0.0052447011694312096
2018-10-13 11:01:34.276709:	Training iteration: 1236, Loss: 0.006532423198223114
2018-10-13 11:03:25.586148:	Training iteration: 1237, Loss: 0.005659046582877636
2018-10-13 11:05:20.318259:	Training iteration: 1238, Loss: 0.0034665532875806093
2018-10-13 11:07:14.972256:	Training iteration: 1239, Loss: 0.004912075586616993
2018-10-13 11:09:08.387118:	Training iteration: 1240, Loss: 0.005046589765697718
2018-10-13 11:11:01.338966:	Training iteration: 1241, Loss: 0.006164243910461664
2018-10-13 11:12:57.251839:	Training iteration: 1242, Loss: 0.006857548840343952
2018-10-13 11:14:47.663139:	Training iteration: 1243, Loss: 0.004627744201570749
2018-10-13 11:16:42.151548:	Training iteration: 1244, Loss: 0.004949502646923065
2018-10-13 11:18:34.293629:	Training iteration: 1245, Loss: 0.006000977009534836
2018-10-13 11:20:25.147617:	Training iteration: 1246, Loss: 0.005404827184975147
2018-10-13 11:22:17.831186:	Training iteration: 1247, Loss: 0.004216521978378296
2018-10-13 11:24:12.667736:	Training iteration: 1248, Loss: 0.005286934785544872
2018-10-13 11:26:07.156429:	Training iteration: 1249, Loss: 0.00607335614040494
2018-10-13 11:27:59.118244:	Training iteration: 1250, Loss: 0.005283812992274761
2018-10-13 11:29:55.340113:	Training iteration: 1251, Loss: 0.0052248528227210045
2018-10-13 11:31:47.583183:	Training iteration: 1252, Loss: 0.005496338941156864
2018-10-13 11:33:41.082888:	Training iteration: 1253, Loss: 0.005473329685628414
2018-10-13 11:35:31.954198:	Training iteration: 1254, Loss: 0.004162924829870462
2018-10-13 11:37:25.267319:	Training iteration: 1255, Loss: 0.005663364194333553
2018-10-13 11:39:16.266143:	Training iteration: 1256, Loss: 0.005648833699524403
2018-10-13 11:41:09.514616:	Training iteration: 1257, Loss: 0.005426711402833462
2018-10-13 11:43:05.210713:	Training iteration: 1258, Loss: 0.006890648044645786
2018-10-13 11:45:00.437385:	Training iteration: 1259, Loss: 0.0053807469084858894
run-end: run #1267: 7 fetches; 2 feeds
929 dumped tensor(s) passing filter "has_inf_or_nan":

t (ms)       Size (B) Op type              Tensor name
[10713.198]  1.25M    RealDiv              Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv:0
[10715.897]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul_1/StackPushV2:0
[10722.325]  1.25M    Mul                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2:0
[10725.413]  1.25M    Add                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_2:0
[10727.057]  1.25M    ExpandDims           Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/ExpandDims:0
[10729.552]  1.25M    Tile                 Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Tile:0
[10733.784]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/mul/StackPushV2:0
[10733.914]  1.25M    Mul                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3:0
[10736.318]  1.25M    Sum                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_1:0
[10738.483]  1.25M    Add                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3:0
[10784.931]  1.25M    NextIteration        Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/NextIteration_1:0
[10790.619]  1.25M    Merge                Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Merge_1:0
[10793.620]  1.25M    Switch               Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Switch_1:1
[10796.517]  1.25M    Reshape              Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Reshape:0
[10799.041]  1.25M    Softmax              Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax:0
[10800.846]  1.25M    Reshape              Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Reshape_1:0
[10801.060]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/mul/StackPushV2:0
[10802.643]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/mul_1/StackPushV2:0
[10802.841]  1.25M    Mul                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul:0
[10804.600]  1.25M    Transpose            Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/transpose:0
[10806.205]  1.25M    Sum                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum:0
[10808.695]  1.25M    Add                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add:0
[10810.285]  1.25M    Mul                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul:0
[10810.426]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Neg/StackPushV2:0
[10812.559]  1.25M    Sum                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/Sum:0
[10814.134]  1.25M    Sqrt                 Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/Sqrt:0
[10815.783]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/RealDiv/StackPushV2:0
[10815.936]  1.25M    Mul                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1:0
[10816.161]  1.25M    RealDiv              Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv:0
[10818.211]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul_1/StackPushV2:0
[10818.775]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Neg/StackPushV2:0
[10818.933]  1.25M    Add                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1:0
[10821.082]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/RealDiv/StackPushV2:0
[10821.211]  1.25M    RealDiv              Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1:0
[10823.056]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul/StackPushV2:0
[10823.249]  1.25M    Mul                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2:0
[10825.068]  1.25M    Add                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_2:0
[10826.672]  1.25M    ExpandDims           Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/ExpandDims:0
[10828.266]  1.25M    Tile                 Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Tile:0
[10829.794]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/mul/StackPushV2:0
[10829.988]  1.25M    Mul                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3:0
[10831.794]  1.25M    Sum                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_1:0
[10833.482]  1.25M    Add                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3:0
[10835.322]  1.25M    NextIteration        Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/NextIteration_1:0
[10838.766]  1.25M    Merge                Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Merge_1:0
[10841.779]  1.25M    Switch               Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Switch_1:1
[11532.539]  1.25M    Reshape              Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Reshape:0
[11535.159]  1.25M    Softmax              Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax:0
[11537.448]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/mul/StackPushV2:0
[11537.651]  1.25M    Reshape              Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Reshape_1:0
[11540.114]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/mul_1/StackPushV2:0
[11540.375]  1.25M    Mul                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul:0
[11542.754]  1.25M    Transpose            Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/transpose:0
[11544.720]  1.25M    Sum                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum:0
[11547.132]  1.25M    Add                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add:0
[11548.781]  1.25M    Mul                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul:0
[11548.905]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Neg/StackPushV2:0
[11551.565]  1.25M    Sum                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/Sum:0
[11553.110]  1.25M    Sqrt                 Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/Sqrt:0
[11554.722]  1.25M    RealDiv              Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv:0
[11554.846]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/RealDiv/StackPushV2:0
[11555.086]  1.25M    Mul                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1:0
[11557.472]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul_1/StackPushV2:0
[11557.681]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Neg/StackPushV2:0
[11557.868]  1.25M    Add                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1:0
[11560.782]  1.25M    RealDiv              Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1:0
[11560.957]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/RealDiv/StackPushV2:0
[11563.345]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul/StackPushV2:0
[11563.540]  1.25M    Mul                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2:0
[11566.163]  1.25M    Add                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_2:0
[11568.609]  1.25M    ExpandDims           Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/ExpandDims:0
[11571.242]  1.25M    Tile                 Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Tile:0
[11573.735]  1.25M    StackPushV2          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/mul/StackPushV2:0
[11573.914]  1.25M    Mul                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3:0
[11576.492]  1.25M    Sum                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_1:0
[11578.893]  1.25M    Add                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3:0
[11580.823]  1.25M    NextIteration        Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/NextIteration_1:0
[11584.009]  1.25M    Merge                Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Merge_1:0
[11587.757]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/RealDiv/StackPopV2:0
[11587.768]  1.25M    TensorArrayReadV3    Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/TensorArrayReadV3:0
[11587.768]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul/StackPopV2:0
[11587.784]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul_1/StackPopV2:0
[11588.007]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Neg/StackPopV2:0
[11591.247]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/RealDiv/StackPopV2:0
[11591.258]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Neg/StackPopV2:0
[11591.282]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/mul_1/StackPopV2:0
[11591.282]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/mul/StackPopV2:0
[11591.304]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/mul/StackPopV2:0
[11591.556]  1.25M    Switch               Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Switch_1:0
[11592.061]  1.25M    Neg                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Neg:0
[11593.177]  1.25M    Add                  Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/add:0
[11595.194]  1.25M    Neg                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Neg:0
[11596.044]  1.25M    Exit                 Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Exit_1:0
[11596.550]  1.25M    Squeeze              Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/Squeeze:0
[11597.417]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/RealDiv_1:0
[11598.021]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/RealDiv_1:0
[11599.224]  1.25M    Mul                  Magnitude_Model/mul:0
[11599.691]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/RealDiv_2:0
[11600.185]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/RealDiv_2:0
[11601.810]  1.25M    Sub                  Magnitude_Model/sub:0
[11604.326]  1.25M    Abs                  Magnitude_Model/Abs:0
[11606.162]  204      Mean                 Magnitude_Model/Mean:0
[11619.682]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/mul:0
[11620.108]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/mul_grad/mul_1:0
[11622.324]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/Sum:0
[11622.750]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/mul_grad/Sum_1:0
[11624.697]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/Reshape:0
[11625.144]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/mul_grad/Reshape_1:0
[11627.123]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/tuple/control_dependency:0
[11629.283]  1.25M    Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3/Enter_grad/Add:0
[11647.417]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul:0
[11647.613]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul_1:0
[11649.301]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/Sum:0
[11649.487]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/Sum_1:0
[11651.098]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/Reshape:0
[11651.295]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/Reshape_1:0
[11652.946]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/tuple/control_dependency:0
[11653.123]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/tuple/control_dependency_1:0
[11654.844]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/RealDiv:0
[11655.048]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/mul:0
[11655.179]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/RealDiv:0
[11655.415]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/mul:0
[11657.680]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Sum_1:0
[11657.807]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Sum:0
[11658.295]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Sum:0
[11658.649]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Sum_1:0
[11660.004]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Reshape_1:0
[11660.134]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Reshape:0
[11661.624]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Reshape:0
[11661.765]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Reshape_1:0
[11662.929]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/tuple/control_dependency_1:0
[11662.931]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/tuple/control_dependency:0
[11663.880]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/tuple/control_dependency_1:0
[11664.287]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/tuple/control_dependency:0
[11665.848]  391      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/Sum:0
[11666.066]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/Sum_1:0
[11666.073]  399      Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/Reshape:0
[11667.595]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/Reshape_1:0
[11669.097]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/tuple/control_dependency_1:0
[11670.663]  1.25M    AddN                 Magnitude_Model/gradients/AddN_1:0
[11672.183]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/mul:0
[11673.727]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/Sum:0
[11673.921]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/Sum_1:0
[11675.630]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/Reshape:0
[11675.825]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/Reshape_1:0
[11677.497]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/tuple/control_dependency:0
[11677.680]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/tuple/control_dependency_1:0
[11679.570]  1.25M    AddN                 Magnitude_Model/gradients/AddN_2:0
[11681.118]  1.25M    SqrtGrad             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/Sqrt_grad/SqrtGrad:0
[11682.674]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/Sum_grad/Reshape:0
[11684.201]  1.25M    Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/Sum_grad/Tile:0
[11685.871]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/mul:0
[11687.429]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/Sum:0
[11687.607]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/Sum_1:0
[11689.537]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/Reshape_1:0
[11690.009]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/Reshape:0
[11691.210]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/tuple/control_dependency_1:0
[11692.502]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/tuple/control_dependency:0
[11694.887]  1.25M    AddN                 Magnitude_Model/gradients/AddN_3:0
[11697.397]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/Sum:0
[11697.399]  256.39k  Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/Sum_1:0
[11697.963]  256.41k  Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/Reshape_1:0
[11699.882]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/Reshape:0
[11699.888]  256.44k  Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/tuple/control_dependency_1:0
[11700.483]  256.41k  Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add/Enter_grad/Add:0
[11701.424]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/tuple/control_dependency:0
[11702.819]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_grad/Reshape:0
[11704.215]  1.25M    Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_grad/Tile:0
[11705.642]  1.25M    Transpose            Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/transpose_grad/transpose:0
[11707.119]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/mul:0
[11707.283]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/mul_1:0
[11709.065]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/Sum:0
[11709.244]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/Sum_1:0
[11710.942]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/Reshape:0
[11711.000]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/Reshape_1:0
[11713.051]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/tuple/control_dependency_1:0
[11713.365]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/tuple/control_dependency:0
[11714.882]  1.25M    Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul/Enter_grad/Add:0
[11715.873]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Reshape_1_grad/Reshape:0
[11718.227]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/mul:0
[11720.575]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/Sum:0
[11722.920]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/Reshape:0
[11724.954]  1.25M    Sub                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/sub:0
[11726.418]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/mul_1:0
[11727.831]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Reshape_grad/Reshape:0
[11729.267]  1.25M    AddN                 Magnitude_Model/gradients/AddN_5:0
[11731.014]  1.25M    NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3/Enter_grad/NextIteration:0
[11731.381]  1.25M    NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Switch_1_grad_1/NextIteration:0
[11731.448]  256.43k  NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add/Enter_grad/NextIteration:0
[11731.465]  1.25M    NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul/Enter_grad/NextIteration:0
[11734.181]  1.25M    Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3/Enter_grad/b_acc_1:0
[11734.245]  256.42k  Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add/Enter_grad/b_acc_2:0
[11734.435]  1.25M    Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul/Enter_grad/b_acc_1:0
[11734.691]  1.25M    Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Switch_1_grad/b_switch:0
[11735.714]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/RealDiv/StackPopV2:0
[11735.756]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Neg/StackPopV2:0
[11736.447]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul_1/StackPopV2:0
[11736.745]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/RealDiv/StackPopV2:0
[11736.801]  256.42k  Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add/Enter_grad/Switch:1
[11736.956]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Neg/StackPopV2:0
[11739.350]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/mul_1/StackPopV2:0
[11739.731]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/mul/StackPopV2:0
[11739.866]  1.25M    Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3/Enter_grad/Switch:1
[11740.511]  1.25M    Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul/Enter_grad/Switch:1
[11741.206]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/mul/StackPopV2:0
[11741.294]  1.25M    Neg                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Neg:0
[11743.195]  1.25M    Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Merge_1_grad/Switch:1
[11743.940]  1.25M    Neg                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Neg:0
[11743.955]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul/StackPopV2:0
[11745.834]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/RealDiv_1:0
[11746.846]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Merge_1_grad/tuple/control_dependency_1:0
[11747.114]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/RealDiv_1:0
[11748.720]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/RealDiv_2:0
[11749.614]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/RealDiv_2:0
[11749.860]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3_grad/Sum_1:0
[11750.053]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3_grad/Sum:0
[11752.510]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3_grad/Reshape_1:0
[11752.680]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3_grad/Reshape:0
[11754.503]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3_grad/tuple/control_dependency:0
[11754.847]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3_grad/tuple/control_dependency_1:0
[11757.027]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_1_grad/Reshape:0
[11758.929]  1.25M    Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_1_grad/Tile:0
[11760.764]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/mul_1:0
[11760.935]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/mul:0
[11762.864]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/Sum_1:0
[11763.033]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/Sum:0
[11764.704]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/Reshape_1:0
[11764.896]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/Reshape:0
[11766.554]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/tuple/control_dependency_1:0
[11766.729]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/tuple/control_dependency:0
[11768.311]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Tile_grad/Reshape_1:0
[11768.581]  1.25M    Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3/Enter_grad/Add:0
[11770.038]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Tile_grad/Sum:0
[11771.458]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/ExpandDims_grad/Reshape:0
[11773.017]  1.25M    AddN                 Magnitude_Model/gradients/AddN:0
[11774.513]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_2_grad/Sum:0
[11774.521]  395      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_2_grad/Sum_1:0
[11774.679]  403      Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_2_grad/Reshape_1:0
[11776.126]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_2_grad/Reshape:0
[11777.710]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_2_grad/tuple/control_dependency:0
[11779.257]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul:0
[11779.443]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul_1:0
[11781.159]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/Sum:0
[11781.335]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/Sum_1:0
[11782.982]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/Reshape:0
[11783.183]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/Reshape_1:0
[11784.926]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/tuple/control_dependency:0
[11785.102]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/tuple/control_dependency_1:0
[11786.816]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/RealDiv:0
[11787.026]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/mul:0
[11787.254]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/RealDiv:0
[11787.407]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/mul:0
[11788.896]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Sum:0
[11789.935]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Sum_1:0
[11790.039]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Sum:0
[11790.532]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Sum_1:0
[11790.742]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Reshape:0
[11792.841]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Reshape:0
[11792.941]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Reshape_1:0
[11793.158]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Reshape_1:0
[11793.692]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/tuple/control_dependency:0
[11795.035]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/tuple/control_dependency:0
[11795.757]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/tuple/control_dependency_1:0
[11795.964]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/tuple/control_dependency_1:0
[11798.287]  391      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/Sum:0
[11798.294]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/Sum_1:0
[11798.561]  399      Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/Reshape:0
[11799.896]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/Reshape_1:0
[11801.662]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/tuple/control_dependency_1:0
[11803.210]  1.25M    AddN                 Magnitude_Model/gradients/AddN_1:0
[11804.785]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/mul:0
[11806.358]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/Sum:0
[11806.533]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/Sum_1:0
[11808.634]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/Reshape:0
[11808.734]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/Reshape_1:0
[11811.040]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/tuple/control_dependency:0
[11811.046]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/tuple/control_dependency_1:0
[11813.280]  1.25M    AddN                 Magnitude_Model/gradients/AddN_2:0
[11814.825]  1.25M    SqrtGrad             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/Sqrt_grad/SqrtGrad:0
[11816.372]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/Sum_grad/Reshape:0
[11817.969]  1.25M    Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/Sum_grad/Tile:0
[11819.528]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/mul:0
[11821.093]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/Sum:0
[11821.271]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/Sum_1:0
[11823.457]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/Reshape_1:0
[11823.464]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/Reshape:0
[11825.955]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/tuple/control_dependency_1:0
[11825.961]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/tuple/control_dependency:0
[11828.209]  1.25M    AddN                 Magnitude_Model/gradients/AddN_3:0
[11829.841]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/Sum:0
[11829.847]  256.39k  Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/Sum_1:0
[11830.716]  256.41k  Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/Reshape_1:0
[11831.672]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/Reshape:0
[11831.738]  256.44k  Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/tuple/control_dependency_1:0
[11832.567]  256.41k  Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add/Enter_grad/Add:0
[11833.545]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/tuple/control_dependency:0
[11835.090]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_grad/Reshape:0
[11836.632]  1.25M    Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_grad/Tile:0
[11838.138]  1.25M    Transpose            Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/transpose_grad/transpose:0
[11839.757]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/mul:0
[11839.937]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/mul_1:0
[11842.001]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/Sum:0
[11842.080]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/Sum_1:0
[11844.445]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/Reshape:0
[11844.451]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/Reshape_1:0
[11846.902]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/tuple/control_dependency_1:0
[11846.908]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/tuple/control_dependency:0
[11849.134]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Reshape_1_grad/Reshape:0
[11849.310]  1.25M    Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul/Enter_grad/Add:0
[11851.331]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/mul:0
[11852.874]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/Sum:0
[11854.394]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/Reshape:0
[11855.955]  1.25M    Sub                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/sub:0
[11857.489]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/mul_1:0
[11859.007]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Reshape_grad/Reshape:0
[11860.578]  1.25M    AddN                 Magnitude_Model/gradients/AddN_5:0
[11862.482]  1.25M    NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Switch_1_grad_1/NextIteration:0
[11862.493]  256.43k  NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add/Enter_grad/NextIteration:0
[11862.727]  1.25M    NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul/Enter_grad/NextIteration:0
[11862.887]  1.25M    NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3/Enter_grad/NextIteration:0
[11865.900]  1.25M    Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3/Enter_grad/b_acc_1:0
[11865.984]  256.42k  Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add/Enter_grad/b_acc_2:0
[11866.169]  1.25M    Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul/Enter_grad/b_acc_1:0
[11866.437]  1.25M    Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Switch_1_grad/b_switch:0
[11869.647]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul_1/StackPopV2:0
[11869.717]  256.42k  Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add/Enter_grad/Switch:1
[11870.038]  1.25M    StackPopV2           Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/mul/StackPopV2:0
[11872.942]  1.25M    Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul/Enter_grad/Switch:1
[11873.690]  1.25M    Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3/Enter_grad/Switch:1
[11873.943]  1.25M    Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Merge_1_grad/Switch:1
[11878.970]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Merge_1_grad/tuple/control_dependency_1:0
[11879.204]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/RealDiv_1:0
[11881.678]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/RealDiv_2:0
[11881.866]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3_grad/Sum:0
[11882.298]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3_grad/Sum_1:0
[11884.453]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3_grad/Reshape:0
[11884.697]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3_grad/Reshape_1:0
[11886.235]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3_grad/tuple/control_dependency:0
[11886.525]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_3_grad/tuple/control_dependency_1:0
[11888.345]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_1_grad/Reshape:0
[11889.904]  1.25M    Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_1_grad/Tile:0
[11891.520]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/mul_1:0
[11891.726]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/mul:0
[11893.438]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/Sum_1:0
[11893.616]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/Sum:0
[11895.250]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/Reshape_1:0
[11895.444]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/Reshape:0
[11897.081]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/tuple/control_dependency_1:0
[11897.243]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3_grad/tuple/control_dependency:0
[11898.907]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Tile_grad/Reshape_1:0
[11899.082]  1.25M    Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3/Enter_grad/Add:0
[11900.766]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Tile_grad/Sum:0
[11902.304]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/ExpandDims_grad/Reshape:0
[11903.881]  1.25M    AddN                 Magnitude_Model/gradients/AddN:0
[11905.496]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_2_grad/Sum:0
[11905.506]  395      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_2_grad/Sum_1:0
[11905.678]  403      Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_2_grad/Reshape_1:0
[11907.211]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_2_grad/Reshape:0
[11908.928]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_2_grad/tuple/control_dependency:0
[11910.575]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul:0
[11910.737]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/mul_1:0
[11912.442]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/Sum:0
[11912.643]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/Sum_1:0
[11914.291]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/Reshape:0
[11914.433]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/Reshape_1:0
[11916.135]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/tuple/control_dependency:0
[11916.333]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_2_grad/tuple/control_dependency_1:0
[11918.025]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/RealDiv:0
[11918.198]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/mul:0
[11918.396]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/RealDiv:0
[11918.704]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/mul:0
[11920.526]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Sum:0
[11920.863]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Sum:0
[11921.590]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Sum_1:0
[11921.955]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Sum_1:0
[11922.945]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Reshape:0
[11923.197]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Reshape:0
[11924.716]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/Reshape_1:0
[11924.906]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/Reshape_1:0
[11925.109]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/tuple/control_dependency:0
[11925.351]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/tuple/control_dependency:0
[11927.494]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_1_grad/tuple/control_dependency_1:0
[11927.940]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/truediv_grad/tuple/control_dependency_1:0
[11929.086]  391      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/Sum:0
[11929.313]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/Sum_1:0
[11929.322]  399      Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/Reshape:0
[11930.962]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/Reshape_1:0
[11932.377]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_1_grad/tuple/control_dependency_1:0
[11933.966]  1.25M    AddN                 Magnitude_Model/gradients/AddN_1:0
[11935.418]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/mul:0
[11936.814]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/Sum:0
[11936.997]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/Sum_1:0
[11938.518]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/Reshape:0
[11938.687]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/Reshape_1:0
[11940.272]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/tuple/control_dependency:0
[11940.721]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_1_grad/tuple/control_dependency_1:0
[11943.167]  1.25M    AddN                 Magnitude_Model/gradients/AddN_2:0
[11945.548]  1.25M    SqrtGrad             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/Sqrt_grad/SqrtGrad:0
[11947.860]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/Sum_grad/Reshape:0
[11950.122]  1.25M    Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/Sum_grad/Tile:0
[11952.313]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/mul:0
[11953.729]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/Sum:0
[11953.913]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/Sum_1:0
[11955.590]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/Reshape_1:0
[11956.372]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/Reshape:0
[11957.020]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/tuple/control_dependency_1:0
[11958.904]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/norm/mul_grad/tuple/control_dependency:0
[11961.335]  1.25M    AddN                 Magnitude_Model/gradients/AddN_3:0
[11963.699]  256.39k  Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/Sum_1:0
[11963.808]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/Sum:0
[11964.516]  256.41k  Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/Reshape_1:0
[11965.399]  256.44k  Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/tuple/control_dependency_1:0
[11965.597]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/Reshape:0
[11966.229]  256.41k  Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add/Enter_grad/Add:0
[11967.319]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add_grad/tuple/control_dependency:0
[11969.024]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_grad/Reshape:0
[11970.591]  1.25M    Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Sum_grad/Tile:0
[11972.118]  1.25M    Transpose            Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/transpose_grad/transpose:0
[11973.701]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/mul:0
[11973.876]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/mul_1:0
[11975.543]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/Sum:0
[11975.754]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/Sum_1:0
[11977.278]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/Reshape:0
[11978.319]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/Reshape_1:0
[11978.849]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/tuple/control_dependency:0
[11980.569]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Reshape_1_grad/Reshape:0
[11980.785]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_grad/tuple/control_dependency_1:0
[11982.569]  1.25M    Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul/Enter_grad/Add:0
[11983.080]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/mul:0
[11985.530]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/Sum:0
[11987.924]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/Reshape:0
[11990.309]  1.25M    Sub                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/sub:0
[11992.439]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Softmax_grad/mul_1:0
[11993.837]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Reshape_grad/Reshape:0
[11995.268]  1.25M    AddN                 Magnitude_Model/gradients/AddN_5:0
[11996.988]  1.25M    NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Switch_1_grad_1/NextIteration:0
[11997.055]  256.43k  NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add/Enter_grad/NextIteration:0
[11997.403]  1.25M    NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3/Enter_grad/NextIteration:0
[11997.414]  1.25M    NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul/Enter_grad/NextIteration:0
[12000.142]  1.25M    Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3/Enter_grad/b_acc_1:0
[12000.160]  256.42k  Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add/Enter_grad/b_acc_2:0
[12000.442]  1.25M    Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul/Enter_grad/b_acc_1:0
[12001.360]  1.25M    Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Switch_1_grad/b_switch:0
[12001.589]  256.42k  Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add/Enter_grad/Switch:0
[12002.782]  256.42k  Exit                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/add/Enter_grad/b_acc_3:0
[12003.781]  256.42k  Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/Tile_grad/Reshape_1:0
[12004.077]  1.25M    Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3/Enter_grad/Switch:0
[12004.303]  1.25M    Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul/Enter_grad/Switch:0
[12004.675]  392      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/Tile_grad/Sum:0
[12005.136]  392      ApplyAdam            Magnitude_Model/Adam/update_Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/b/ApplyAdam:0
[12005.458]  1.25M    Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/Merge_1_grad/Switch:0
[12007.123]  1.25M    Exit                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul/Enter_grad/b_acc_2:0
[12007.424]  1.25M    Exit                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/while/mul_3/Enter_grad/b_acc_2:0
[12009.769]  1.25M    Transpose            Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/transpose_1_grad/transpose:0
[12012.370]  1.25M    AddN                 Magnitude_Model/gradients/AddN_4:0
[12014.683]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/Reshape_1_grad/Reshape:0
[12019.645]  470      Conv2DBackpropFilter Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/convolution_grad/Conv2DBackpropFilter:0
[12019.648]  10.00M   Conv2DBackpropInput  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/convolution_grad/Conv2DBackpropInput:0
[12019.821]  482      Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/convolution_grad/tuple/control_dependency_1:0
[12020.072]  420      ApplyAdam            Magnitude_Model/Adam/update_Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/W/ApplyAdam:0
[12031.115]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/convolution_grad/tuple/control_dependency:0
[12042.680]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/Reshape_grad/Reshape:0
[12054.340]  10.00M   Transpose            Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Reconstruction/reconstruction/transpose_grad/transpose:0
[12066.025]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/add_grad/Sum:0
[12066.031]  354      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/add_grad/Sum_1:0
[12066.335]  362      Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/add_grad/Reshape_1:0
[12078.502]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/add_grad/Reshape:0
[12089.585]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/add_grad/tuple/control_dependency:0
[12103.175]  10.00M   TensorArrayReadV3    Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3:0
[12116.332]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency:0
[12127.672]  10.00M   AddN                 Magnitude_Model/gradients/AddN_6:0
[12139.164]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/Sum:0
[12139.172]  370      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/Sum_1:0
[12139.597]  378      Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/Reshape_1:0
[12150.739]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/Reshape:0
[12162.094]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/tuple/control_dependency:0
[12173.710]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/mul:0
[12175.195]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/mul_1:0
[12187.505]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/Sum:0
[12187.736]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/Sum_1:0
[12189.709]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/Reshape_1:0
[12197.749]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/tuple/control_dependency_1:0
[12199.283]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/Reshape:0
[12199.479]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/RealDiv:0
[12199.700]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/mul:0
[12201.731]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/Sum:0
[12202.658]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/Sum_1:0
[12204.942]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/Reshape:0
[12205.074]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/Reshape_1:0
[12206.959]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/tuple/control_dependency:0
[12208.155]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/tuple/control_dependency_1:0
[12209.785]  366      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/Sum:0
[12210.052]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/Sum_1:0
[12210.068]  374      Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/Reshape:0
[12211.789]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/Reshape_1:0
[12213.487]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/tuple/control_dependency_1:0
[12215.183]  1.25M    AddN                 Magnitude_Model/gradients/AddN_7:0
[12217.646]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/tuple/control_dependency:0
[12217.926]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/mul:0
[12219.846]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/Sum:0
[12220.048]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/Sum_1:0
[12222.403]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/Reshape_1:0
[12223.055]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/Reshape:0
[12224.467]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/tuple/control_dependency_1:0
[12225.888]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/tuple/control_dependency:0
[12231.582]  10.00M   RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/RealDiv:0
[12233.131]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/mul:0
[12245.782]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/Sum:0
[12245.962]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/Sum_1:0
[12248.094]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/Reshape_1:0
[12256.199]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/tuple/control_dependency_1:0
[12257.962]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/Reshape:0
[12257.990]  1.25M    AddN                 Magnitude_Model/gradients/AddN_8:0
[12260.090]  1.25M    SqrtGrad             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/Sqrt_grad/SqrtGrad:0
[12262.285]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/Sum_grad/Reshape:0
[12265.990]  10.00M   Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/Sum_grad/Tile:0
[12269.972]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/tuple/control_dependency:0
[12281.842]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/mul:0
[12293.108]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/Sum_1:0
[12294.529]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/Sum:0
[12307.172]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/Reshape_1:0
[12308.902]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/Reshape:0
[12320.183]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/tuple/control_dependency_1:0
[12322.589]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/tuple/control_dependency:0
[12335.659]  10.00M   AddN                 Magnitude_Model/gradients/AddN_9:0
[12346.543]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/Sum:0
[12346.787]  2.00M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/Sum_1:0
[12349.944]  2.00M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/Reshape_1:0
[12361.526]  2.00M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/tuple/control_dependency_1:0
[12363.084]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/Reshape:0
[12364.436]  2.00M    Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add/Enter_grad/Add:0
[12375.961]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/tuple/control_dependency:0
[12387.556]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Sum_grad/Reshape:0
[12410.701]  80.00M   Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Sum_grad/Tile:0
[12560.317]  80.00M   Transpose            Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/transpose_grad/transpose:0
[12702.078]  80.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/mul:0
[12714.459]  80.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/mul_1:0
[12856.380]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/Sum:0
[12882.616]  80.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/Sum_1:0
[12884.189]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/Reshape:0
[13013.423]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/tuple/control_dependency:0
[13025.824]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/Reshape_1:0
[13028.482]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Reshape_1_grad/Reshape:0
[13041.206]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/mul:0
[13054.688]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/Sum:0
[13067.846]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/Reshape:0
[13080.231]  10.00M   Sub                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/sub:0
[13095.947]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/mul_1:0
[13111.082]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Reshape_grad/Reshape:0
[13126.219]  10.00M   AddN                 Magnitude_Model/gradients/AddN_11:0
[13180.706]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/tuple/control_dependency_1:0
[13323.961]  80.00M   Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul/Enter_grad/Add:0
[13480.667]  10.00M   NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Switch_1_grad_1/NextIteration:0
[13480.943]  2.00M    NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add/Enter_grad/NextIteration:0
[13480.973]  80.00M   NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul/Enter_grad/NextIteration:0
[13519.310]  2.00M    Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add/Enter_grad/b_acc_2:0
[13524.692]  10.00M   Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Switch_1_grad/b_switch:0
[13532.336]  80.00M   Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul/Enter_grad/b_acc_1:0
[13559.615]  2.00M    Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add/Enter_grad/Switch:1
[13567.283]  10.00M   Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Merge_1_grad/Switch:1
[13603.094]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Merge_1_grad/tuple/control_dependency_1:0
[13642.209]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_3_grad/Sum_1:0
[13642.221]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_3_grad/Sum:0
[13681.263]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_3_grad/Reshape:0
[13683.324]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_3_grad/Reshape_1:0
[13714.749]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_3_grad/tuple/control_dependency_1:0
[13714.754]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_3_grad/tuple/control_dependency:0
[13746.171]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Sum_1_grad/Reshape:0
[13802.778]  80.00M   Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Sum_1_grad/Tile:0
[13989.915]  80.00M   Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul/Enter_grad/Switch:1
[14086.928]  80.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/mul:0
[14099.309]  80.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/mul_1:0
[14302.434]  80.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/Sum:0
[14314.727]  80.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/Sum_1:0
[14469.432]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/Reshape:0
[14483.874]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/Reshape_1:0
[14639.510]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/tuple/control_dependency:0
[14657.739]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/tuple/control_dependency_1:0
[14819.506]  80.00M   Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3/Enter_grad/Add:0
[14833.182]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Tile_grad/Reshape_1:0
[14983.324]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Tile_grad/Sum:0
[14994.725]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/ExpandDims_grad/Reshape:0
[15006.729]  10.00M   AddN                 Magnitude_Model/gradients/AddN_6:0
[15018.546]  370      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/Sum_1:0
[15018.553]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/Sum:0
[15018.861]  378      Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/Reshape_1:0
[15030.412]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/Reshape:0
[15042.185]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/tuple/control_dependency:0
[15054.064]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/mul:0
[15055.455]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/mul_1:0
[15067.466]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/Sum:0
[15067.994]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/Sum_1:0
[15070.180]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/Reshape_1:0
[15080.266]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/tuple/control_dependency_1:0
[15080.276]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/Reshape:0
[15082.360]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/RealDiv:0
[15082.456]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/mul:0
[15085.402]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/Sum_1:0
[15085.638]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/Sum:0
[15088.279]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/Reshape_1:0
[15088.387]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/Reshape:0
[15091.249]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/tuple/control_dependency_1:0
[15091.352]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/tuple/control_dependency:0
[15094.391]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/tuple/control_dependency:0
[15094.480]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/Sum_1:0
[15094.502]  366      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/Sum:0
[15094.751]  374      Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/Reshape:0
[15096.733]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/Reshape_1:0
[15098.762]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/tuple/control_dependency_1:0
[15100.566]  1.25M    AddN                 Magnitude_Model/gradients/AddN_7:0
[15107.638]  10.00M   RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/RealDiv:0
[15109.343]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/mul:0
[15112.257]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/mul:0
[15115.750]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/Sum:0
[15115.890]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/Sum_1:0
[15118.888]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/Reshape:0
[15119.032]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/Reshape_1:0
[15121.366]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/tuple/control_dependency:0
[15122.982]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/Sum:0
[15123.158]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/tuple/control_dependency_1:0
[15123.518]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/Sum_1:0
[15125.862]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/Reshape_1:0
[15133.252]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/tuple/control_dependency_1:0
[15134.779]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/Reshape:0
[15135.087]  1.25M    AddN                 Magnitude_Model/gradients/AddN_8:0
[15137.026]  1.25M    SqrtGrad             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/Sqrt_grad/SqrtGrad:0
[15139.094]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/Sum_grad/Reshape:0
[15142.444]  10.00M   Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/Sum_grad/Tile:0
[15147.995]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/tuple/control_dependency:0
[15156.029]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/mul:0
[15167.196]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/Sum:0
[15168.758]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/Sum_1:0
[15181.139]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/Reshape:0
[15182.698]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/Reshape_1:0
[15195.495]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/tuple/control_dependency:0
[15197.052]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/tuple/control_dependency_1:0
[15210.519]  10.00M   AddN                 Magnitude_Model/gradients/AddN_9:0
[15222.190]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/Sum:0
[15222.334]  2.00M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/Sum_1:0
[15225.373]  2.00M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/Reshape_1:0
[15235.721]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/Reshape:0
[15235.727]  2.00M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/tuple/control_dependency_1:0
[15238.917]  2.00M    Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add/Enter_grad/Add:0
[15248.203]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/tuple/control_dependency:0
[15259.578]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Sum_grad/Reshape:0
[15282.753]  80.00M   Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Sum_grad/Tile:0
[15435.171]  80.00M   Transpose            Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/transpose_grad/transpose:0
[15577.792]  80.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/mul:0
[15589.867]  80.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/mul_1:0
[15736.651]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/Sum:0
[15751.580]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/Reshape:0
[15877.973]  80.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/Sum_1:0
[16145.294]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/tuple/control_dependency:0
[16157.835]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/Reshape_1:0
[17387.251]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/tuple/control_dependency_1:0
[17422.121]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Reshape_1_grad/Reshape:0
[17435.787]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/mul:0
[17448.373]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/Sum:0
[17460.564]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/Reshape:0
[17473.943]  10.00M   Sub                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/sub:0
[17487.657]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/mul_1:0
[17501.568]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Reshape_grad/Reshape:0
[17516.889]  10.00M   AddN                 Magnitude_Model/gradients/AddN_11:0
[17571.307]  80.00M   Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul/Enter_grad/Add:0
[17714.896]  80.00M   NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul/Enter_grad/NextIteration:0
[17727.307]  80.00M   NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3/Enter_grad/NextIteration:0
[17728.927]  10.00M   NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Switch_1_grad_1/NextIteration:0
[17729.125]  2.00M    NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add/Enter_grad/NextIteration:0
[17766.311]  80.00M   Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3/Enter_grad/b_acc_1:0
[17766.581]  2.00M    Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add/Enter_grad/b_acc_2:0
[17768.292]  10.00M   Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Switch_1_grad/b_switch:0
[17782.294]  80.00M   Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul/Enter_grad/b_acc_1:0
[17811.516]  2.00M    Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add/Enter_grad/Switch:1
[17812.444]  10.00M   Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Merge_1_grad/Switch:1
[17860.860]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Merge_1_grad/tuple/control_dependency_1:0
[17887.555]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_3_grad/Sum:0
[17889.720]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_3_grad/Sum_1:0
[17919.590]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_3_grad/Reshape:0
[17921.698]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_3_grad/Reshape_1:0
[17945.869]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_3_grad/tuple/control_dependency:0
[17947.897]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_3_grad/tuple/control_dependency_1:0
[17978.211]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Sum_1_grad/Reshape:0
[18016.140]  80.00M   Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Sum_1_grad/Tile:0
[18208.787]  80.00M   Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul/Enter_grad/Switch:1
[18288.544]  80.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/mul:0
[18300.900]  80.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/mul_1:0
[18313.254]  80.00M   Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3/Enter_grad/Switch:1
[18512.193]  80.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/Sum:0
[18536.980]  80.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/Sum_1:0
[18699.522]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/Reshape:0
[18838.321]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/Reshape_1:0
[18869.188]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/tuple/control_dependency:0
[19142.915]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3_grad/tuple/control_dependency_1:0
[19223.876]  80.00M   Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3/Enter_grad/Add:0
[19425.175]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Tile_grad/Reshape_1:0
[19656.473]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Tile_grad/Sum:0
[19690.221]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/ExpandDims_grad/Reshape:0
[19705.613]  10.00M   AddN                 Magnitude_Model/gradients/AddN_6:0
[19734.365]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/Sum:0
[19734.384]  370      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/Sum_1:0
[19734.687]  378      Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/Reshape_1:0
[19748.047]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/Reshape:0
[19759.785]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_2_grad/tuple/control_dependency:0
[19771.661]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/mul:0
[19773.175]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/mul_1:0
[19786.222]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/Sum_1:0
[19786.228]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/Sum:0
[19788.334]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/Reshape_1:0
[19796.920]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/tuple/control_dependency_1:0
[19798.461]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/Reshape:0
[19798.761]  1.25M    RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/RealDiv:0
[19798.965]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/mul:0
[19801.298]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/Sum_1:0
[19801.946]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/Sum:0
[19803.354]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/Reshape_1:0
[19805.238]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/Reshape:0
[19807.759]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/tuple/control_dependency:0
[19815.410]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_2_grad/tuple/control_dependency:0
[19816.118]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_1_grad/tuple/control_dependency_1:0
[19818.101]  366      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/Sum:0
[19818.393]  374      Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/Reshape:0
[19818.404]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/Sum_1:0
[19821.278]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/Reshape_1:0
[19823.911]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_1_grad/tuple/control_dependency_1:0
[19825.663]  1.25M    AddN                 Magnitude_Model/gradients/AddN_7:0
[19827.835]  10.00M   RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/RealDiv:0
[19829.433]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/mul:0
[19829.606]  1.25M    Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/mul:0
[19832.493]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/Sum:0
[19832.619]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/Sum_1:0
[19835.777]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/Reshape_1:0
[19836.364]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/Reshape:0
[19838.520]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/tuple/control_dependency_1:0
[19839.665]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_1_grad/tuple/control_dependency:0
[19844.605]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/Sum_1:0
[19846.292]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/Reshape_1:0
[19852.475]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/Sum:0
[19990.402]  1.25M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/tuple/control_dependency_1:0
[19992.017]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/Reshape:0
[19993.035]  1.25M    AddN                 Magnitude_Model/gradients/AddN_8:0
[19995.691]  1.25M    SqrtGrad             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/Sqrt_grad/SqrtGrad:0
[19998.493]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/Sum_grad/Reshape:0
[20002.412]  10.00M   Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/Sum_grad/Tile:0
[20009.494]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/truediv_grad/tuple/control_dependency:0
[20016.414]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/mul:0
[20027.588]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/Sum:0
[20029.129]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/Sum_1:0
[20041.278]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/Reshape:0
[20042.823]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/Reshape_1:0
[20055.310]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/tuple/control_dependency:0
[20056.846]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/norm/mul_grad/tuple/control_dependency_1:0
[20070.269]  10.00M   AddN                 Magnitude_Model/gradients/AddN_9:0
[20082.142]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/Sum:0
[20082.242]  2.00M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/Sum_1:0
[20085.216]  2.00M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/Reshape_1:0
[20093.920]  2.00M    Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/tuple/control_dependency_1:0
[20095.428]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/Reshape:0
[20096.734]  2.00M    Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add/Enter_grad/Add:0
[20111.470]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add_grad/tuple/control_dependency:0
[20122.944]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Sum_grad/Reshape:0
[20145.922]  80.00M   Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Sum_grad/Tile:0
[20399.940]  80.00M   Transpose            Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/transpose_grad/transpose:0
[20597.619]  80.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/mul:0
[20609.904]  80.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/mul_1:0
[20770.556]  80.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/Sum_1:0
[20778.794]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/Sum:0
[20791.375]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/Reshape:0
[20910.458]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/tuple/control_dependency:0
[20922.731]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/Reshape_1:0
[20925.278]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Reshape_1_grad/Reshape:0
[20937.286]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/mul:0
[20950.350]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/Sum:0
[20963.347]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/Reshape:0
[20976.629]  10.00M   Sub                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/sub:0
[21018.493]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Softmax_grad/mul_1:0
[21049.085]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Reshape_grad/Reshape:0
[21088.519]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_grad/tuple/control_dependency_1:0
[21773.330]  10.00M   AddN                 Magnitude_Model/gradients/AddN_11:0
[22200.614]  80.00M   Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul/Enter_grad/Add:0
[22346.064]  80.00M   NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3/Enter_grad/NextIteration:0
[22360.001]  2.00M    NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add/Enter_grad/NextIteration:0
[22360.034]  10.00M   NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Switch_1_grad_1/NextIteration:0
[22360.052]  80.00M   NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul/Enter_grad/NextIteration:0
[22397.135]  80.00M   Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3/Enter_grad/b_acc_1:0
[22397.455]  2.00M    Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add/Enter_grad/b_acc_2:0
[22399.110]  10.00M   Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Switch_1_grad/b_switch:0
[22411.668]  80.00M   Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul/Enter_grad/b_acc_1:0
[22411.905]  2.00M    Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add/Enter_grad/Switch:0
[22416.525]  2.00M    Exit                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/add/Enter_grad/b_acc_3:0
[22422.778]  2.00M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/Tile_grad/Reshape_1:0
[22428.607]  396      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/Tile_grad/Sum:0
[22428.933]  396      ApplyAdam            Magnitude_Model/Adam/update_Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/b/ApplyAdam:0
[22431.695]  10.00M   Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/Merge_1_grad/Switch:0
[22772.246]  80.00M   Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3/Enter_grad/Switch:0
[22796.702]  80.00M   Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul/Enter_grad/Switch:0
[22947.393]  80.00M   Exit                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul_3/Enter_grad/b_acc_2:0
[22970.935]  80.00M   Exit                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/while/mul/Enter_grad/b_acc_2:0
[23150.075]  80.00M   Transpose            Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/transpose_1_grad/transpose:0
[26541.633]  80.00M   AddN                 Magnitude_Model/gradients/AddN_10:0
[26686.405]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/Reshape_1_grad/Reshape:0
[26853.641]  671      Conv2DBackpropFilter Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/convolution_grad/Conv2DBackpropFilter:0
[26853.663]  80.00M   Conv2DBackpropInput  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/convolution_grad/Conv2DBackpropInput:0
[26853.936]  683      Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/convolution_grad/tuple/control_dependency_1:0
[26854.252]  622      ApplyAdam            Magnitude_Model/Adam/update_Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/W/ApplyAdam:0
[27001.291]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/convolution_grad/tuple/control_dependency:0
[27147.368]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/Reshape_grad/Reshape:0
[27298.337]  80.00M   Transpose            Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Seg_Caps/seg_caps/transpose_grad/transpose:0
[27447.881]  80.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/add_grad/Sum:0
[27447.890]  368      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/add_grad/Sum_1:0
[27448.326]  376      Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/add_grad/Reshape_1:0
[27595.336]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/add_grad/Reshape:0
[27742.831]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/add_grad/tuple/control_dependency:0
[27894.821]  80.00M   TensorArrayReadV3    Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3:0
[28039.889]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency:0
[28423.258]  80.00M   AddN                 Magnitude_Model/gradients/AddN_12:0
[28570.990]  80.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_2_grad/Sum:0
[28571.007]  384      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_2_grad/Sum_1:0
[28571.468]  393      Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_2_grad/Reshape_1:0
[28716.629]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_2_grad/Reshape:0
[28863.510]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_2_grad/tuple/control_dependency:0
[29010.822]  80.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_2_grad/mul:0
[29023.103]  80.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_2_grad/mul_1:0
[29177.263]  80.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_2_grad/Sum:0
[29178.749]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_2_grad/Sum_1:0
[29191.041]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_2_grad/Reshape_1:0
[29328.269]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_2_grad/Reshape:0
[29328.295]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_2_grad/tuple/control_dependency_1:0
[29343.966]  10.00M   RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_1_grad/RealDiv:0
[29345.527]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_1_grad/mul:0
[29361.098]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_1_grad/Sum:0
[29362.580]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_1_grad/Sum_1:0
[29377.552]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_1_grad/Reshape:0
[29379.049]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_1_grad/Reshape_1:0
[29393.035]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_1_grad/tuple/control_dependency:0
[29396.105]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_1_grad/tuple/control_dependency_1:0
[29410.055]  380      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_1_grad/Sum:0
[29411.678]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_1_grad/Sum_1:0
[29411.686]  389      Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_1_grad/Reshape:0
[29429.092]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_1_grad/Reshape_1:0
[29444.027]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_1_grad/tuple/control_dependency_1:0
[29458.089]  10.00M   AddN                 Magnitude_Model/gradients/AddN_13:0
[29471.936]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_1_grad/mul:0
[29484.360]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_1_grad/Sum:0
[29485.935]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_1_grad/Sum_1:0
[29501.632]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_2_grad/tuple/control_dependency:0
[29503.297]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_1_grad/Reshape_1:0
[29504.934]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_1_grad/Reshape:0
[29520.039]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_1_grad/tuple/control_dependency_1:0
[29524.701]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_1_grad/tuple/control_dependency:0
[29645.598]  80.00M   RealDiv              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_grad/RealDiv:0
[29657.861]  80.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_grad/mul:0
[29813.788]  80.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_grad/Sum:0
[29815.356]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_grad/Sum_1:0
[29827.301]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_grad/Reshape_1:0
[29945.572]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_grad/tuple/control_dependency_1:0
[29957.815]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_grad/Reshape:0
[29959.379]  10.00M   AddN                 Magnitude_Model/gradients/AddN_14:0
[29974.681]  10.00M   SqrtGrad             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/norm/Sqrt_grad/SqrtGrad:0
[29987.907]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/norm/Sum_grad/Reshape:0
[30013.205]  80.00M   Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/norm/Sum_grad/Tile:0
[30108.244]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/truediv_grad/tuple/control_dependency:0
[30179.183]  80.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/norm/mul_grad/mul:0
[30336.771]  80.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/norm/mul_grad/Sum:0
[30349.150]  80.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/norm/mul_grad/Sum_1:0
[30501.741]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/norm/mul_grad/Reshape:0
[30514.842]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/norm/mul_grad/Reshape_1:0
[30676.310]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/norm/mul_grad/tuple/control_dependency:0
[30693.116]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/norm/mul_grad/tuple/control_dependency_1:0
[30860.991]  80.00M   AddN                 Magnitude_Model/gradients/AddN_15:0
[31006.701]  80.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_grad/Sum:0
[31009.109]  16.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_grad/Sum_1:0
[31028.880]  16.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_grad/Reshape_1:0
[31147.289]  16.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_grad/tuple/control_dependency_1:0
[31159.658]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_grad/Reshape:0
[31173.842]  16.00M   Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add/Enter_grad/Add:0
[31303.989]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add_grad/tuple/control_dependency:0
[31447.981]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Sum_grad/Reshape:0
[31592.248]  80.00M   Tile                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Sum_grad/Tile:0
[31743.734]  80.00M   Transpose            Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/transpose_grad/transpose:0
[31885.298]  80.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_grad/mul:0
[31897.787]  80.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_grad/mul_1:0
[32064.231]  80.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_grad/Sum_1:0
[32065.816]  10.00M   Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_grad/Sum:0
[32080.919]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_grad/Reshape:0
[32193.396]  10.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_grad/tuple/control_dependency:0
[32205.708]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_grad/Reshape_1:0
[32207.137]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Reshape_1_grad/Reshape:0
[32223.652]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Softmax_grad/mul:0
[32234.578]  1.25M    Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Softmax_grad/Sum:0
[32236.418]  1.25M    Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Softmax_grad/Reshape:0
[32239.605]  10.00M   Sub                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Softmax_grad/sub:0
[32252.815]  10.00M   Mul                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Softmax_grad/mul_1:0
[32266.295]  10.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Reshape_grad/Reshape:0
[32280.115]  10.00M   AddN                 Magnitude_Model/gradients/AddN_17:0
[32354.995]  80.00M   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul_grad/tuple/control_dependency_1:0
[32500.210]  80.00M   Add                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul/Enter_grad/Add:0
[32647.652]  16.00M   NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add/Enter_grad/NextIteration:0
[32649.227]  10.00M   NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Switch_1_grad_1/NextIteration:0
[32661.706]  80.00M   NextIteration        Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul/Enter_grad/NextIteration:0
[35292.586]  16.00M   Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add/Enter_grad/b_acc_2:0
[35294.148]  10.00M   Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Switch_1_grad/b_switch:0
[35307.123]  80.00M   Merge                Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul/Enter_grad/b_acc_1:0
[35321.368]  10.00M   Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/Merge_1_grad/Switch:0
[35332.250]  16.00M   Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add/Enter_grad/Switch:0
[35367.617]  16.00M   Exit                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/add/Enter_grad/b_acc_3:0
[35398.990]  16.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/Tile_grad/Reshape_1:0
[35424.239]  636      Sum                  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/Tile_grad/Sum:0
[35424.540]  636      ApplyAdam            Magnitude_Model/Adam/update_Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/b/ApplyAdam:0
[35556.997]  80.00M   Switch               Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul/Enter_grad/Switch:0
[35727.200]  80.00M   Exit                 Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/while/mul/Enter_grad/b_acc_2:0
[35904.480]  80.00M   Transpose            Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/transpose_1_grad/transpose:0
[36051.537]  80.00M   AddN                 Magnitude_Model/gradients/AddN_16:0
[36197.054]  80.00M   Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/Reshape_1_grad/Reshape:0
[36380.534]  800.42k  Conv2DBackpropFilter Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/convolution_grad/Conv2DBackpropFilter:0
[36380.562]  160.00M  Conv2DBackpropInput  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/convolution_grad/Conv2DBackpropInput:0
[36382.351]  800.44k  Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/convolution_grad/tuple/control_dependency_1:0
[36384.080]  800.38k  ApplyAdam            Magnitude_Model/Adam/update_Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/W/ApplyAdam:0
[36670.272]  160.00M  Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/convolution_grad/tuple/control_dependency:0
[36953.641]  160.00M  Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/Reshape_grad/Reshape:0
[37233.834]  160.00M  Transpose            Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Primary_Caps/primarycaps/transpose_grad/transpose:0
[37515.977]  160.00M  Reshape              Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Convolution/reshape_1/Reshape_grad/Reshape:0
[37801.472]  160.00M  Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Convolution/conv2d/BiasAdd_grad/tuple/control_dependency:0
[37801.483]  891      BiasAddGrad          Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Convolution/conv2d/BiasAdd_grad/BiasAddGrad:0
[37801.998]  922      Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Convolution/conv2d/BiasAdd_grad/tuple/control_dependency_1:0
[37802.433]  875      ApplyAdam            Magnitude_Model/Adam/update_Magnitude_Model/SegCaps_CapsNetBasic/Convolution/conv2d/bias/ApplyAdam:0
[38060.755]  1.25M    Conv2DBackpropInput  Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Convolution/conv2d/Conv2D_grad/Conv2DBackpropInput:0
[38060.766]  12.90k   Conv2DBackpropFilter Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Convolution/conv2d/Conv2D_grad/Conv2DBackpropFilter:0
[38061.248]  12.91k   Identity             Magnitude_Model/gradients/Magnitude_Model/SegCaps_CapsNetBasic/Convolution/conv2d/Conv2D_grad/tuple/control_dependency_1:0
[38061.907]  12.87k   ApplyAdam            Magnitude_Model/Adam/update_Magnitude_Model/SegCaps_CapsNetBasic/Convolution/conv2d/kernel/ApplyAdam:0

tfdbg> 