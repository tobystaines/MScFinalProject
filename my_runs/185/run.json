{
  "artifacts": [],
  "command": "do_experiment",
  "experiment": {
    "base_dir": "/home/enterprise.internal.city.ac.uk/acvn728/MScFinalProject",
    "dependencies": [
      "numpy==1.15.2",
      "sacred==0.7.4",
      "tensorflow-gpu==1.11.0"
    ],
    "mainfile": "main.py",
    "name": "UNet_Speech_Separation",
    "repositories": [],
    "sources": [
      [
        "audio_models.py",
        "_sources/audio_models_22d6c8090cad901be1e70bed4020f5b2.py"
      ],
      [
        "dataset.py",
        "_sources/dataset_20f5331d613553a1d9af5429739bb5c9.py"
      ],
      [
        "main.py",
        "_sources/main_5850c5171826bb9d6664750578f31a36.py"
      ],
      [
        "train.py",
        "_sources/train_f1323023dbe26ea7acee378f6c407bc7.py"
      ]
    ]
  },
  "fail_trace": [
    "Traceback (most recent call last):\n",
    "  File \"/home/enterprise.internal.city.ac.uk/acvn728/.local/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\", line 686, in _call_cpp_shape_fn_impl\n    input_tensors_as_shapes, status)\n",
    "  File \"/home/enterprise.internal.city.ac.uk/acvn728/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\n    c_api.TF_GetCode(self.status.status))\n",
    "tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimension 2 in both shapes must be equal, but are 18 and 17 for 'Magnitude_Model/voice-mask-unet/decoder/layer-2/concat' (op: 'ConcatV2') with input shapes: [?,8,18,256], [?,8,17,256], [] and with computed input tensors: input[2] = <3>.\n",
    "\nDuring handling of the above exception, another exception occurred:\n\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/enterprise.internal.city.ac.uk/acvn728/.local/lib/python3.5/site-packages/sacred/config/captured_function.py\", line 46, in captured_function\n    result = wrapped(*args, **kwargs)\n",
    "  File \"main.py\", line 124, in do_experiment\n    model_config['data_type'], name='Magnitude_Model')\n",
    "  File \"/home/enterprise.internal.city.ac.uk/acvn728/MScFinalProject/audio_models.py\", line 35, in __init__\n    self.voice_mask_network = UNet(mixed_input, variant, data_type, is_training=is_training, reuse=False, name='voice-mask-unet')\n",
    "  File \"/home/enterprise.internal.city.ac.uk/acvn728/MScFinalProject/audio_models.py\", line 92, in __init__\n    self.decoder = UNetDecoder(self.encoder.output, self.encoder, data_type, is_training, reuse)\n",
    "  File \"/home/enterprise.internal.city.ac.uk/acvn728/MScFinalProject/audio_models.py\", line 159, in __init__\n    net = mf.relu(mf.concat(net, encoder.l5))\n",
    "  File \"/home/enterprise.internal.city.ac.uk/acvn728/MScFinalProject/model_functions.py\", line 6, in concat\n    return tf.concat([x, y], axis=3)\n",
    "  File \"/home/enterprise.internal.city.ac.uk/acvn728/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1099, in concat\n    return gen_array_ops._concat_v2(values=values, axis=axis, name=name)\n",
    "  File \"/home/enterprise.internal.city.ac.uk/acvn728/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 706, in _concat_v2\n    \"ConcatV2\", values=values, axis=axis, name=name)\n",
    "  File \"/home/enterprise.internal.city.ac.uk/acvn728/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n",
    "  File \"/home/enterprise.internal.city.ac.uk/acvn728/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2958, in create_op\n    set_shapes_for_outputs(ret)\n",
    "  File \"/home/enterprise.internal.city.ac.uk/acvn728/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2209, in set_shapes_for_outputs\n    shapes = shape_func(op)\n",
    "  File \"/home/enterprise.internal.city.ac.uk/acvn728/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2159, in call_with_requiring\n    return call_cpp_shape_fn(op, require_shape_fn=True)\n",
    "  File \"/home/enterprise.internal.city.ac.uk/acvn728/.local/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\", line 627, in call_cpp_shape_fn\n    require_shape_fn)\n",
    "  File \"/home/enterprise.internal.city.ac.uk/acvn728/.local/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\", line 691, in _call_cpp_shape_fn_impl\n    raise ValueError(err.message)\n",
    "ValueError: Dimension 2 in both shapes must be equal, but are 18 and 17 for 'Magnitude_Model/voice-mask-unet/decoder/layer-2/concat' (op: 'ConcatV2') with input shapes: [?,8,18,256], [?,8,17,256], [] and with computed input tensors: input[2] = <3>.\n"
  ],
  "heartbeat": "2018-11-07T07:42:38.632525",
  "host": {
    "ENV": {},
    "cpu": "AMD Ryzen 7 1700 Eight-Core Processor",
    "gpus": {
      "driver_version": "396.44",
      "gpus": [
        {
          "model": "GeForce GTX 1080 Ti",
          "persistence_mode": false,
          "total_memory": 11177
        },
        {
          "model": "GeForce GTX 1080 Ti",
          "persistence_mode": false,
          "total_memory": 11178
        }
      ]
    },
    "hostname": "africa",
    "os": [
      "Linux",
      "Linux-4.15.0-36-generic-x86_64-with-Ubuntu-16.04-xenial"
    ],
    "python_version": "3.5.2"
  },
  "meta": {
    "command": "do_experiment",
    "options": {
      "--beat_interval": null,
      "--capture": null,
      "--comment": null,
      "--debug": false,
      "--enforce_clean": false,
      "--file_storage": null,
      "--force": false,
      "--help": false,
      "--loglevel": null,
      "--mongo_db": null,
      "--name": null,
      "--pdb": false,
      "--print_config": false,
      "--priority": null,
      "--queue": false,
      "--sql": null,
      "--tiny_db": null,
      "--unobserved": false,
      "COMMAND": null,
      "UPDATE": [
        "model_config.data_type=mag_phase_real_imag"
      ],
      "help": false,
      "with": true
    }
  },
  "resources": [],
  "result": null,
  "start_time": "2018-11-07T07:40:45.778985",
  "status": "FAILED",
  "stop_time": "2018-11-07T07:42:38.639409"
}