INFO - UNet_Speech_Separation - Running command 'do_experiment'
INFO - UNet_Speech_Separation - Started run with ID "267"
Experiment ID: 267
Preparing dataset
Dataset ready
2018-11-28 07:51:48.116172: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-11-28 07:51:48.286512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-11-28 07:51:48.287200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:27:00.0
totalMemory: 10.92GiB freeMemory: 10.76GiB
2018-11-28 07:51:48.287217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 1
2018-11-28 07:51:48.587849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-11-28 07:51:48.587880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      1 
2018-11-28 07:51:48.587886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 1:   N 
2018-11-28 07:51:48.588169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10405 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:27:00.0, compute capability: 6.1)
Session started
Iterators created
Creating model
WARNING:tensorflow:From /home/enterprise.internal.city.ac.uk/acvn728/MScFinalProject/SegCaps/capsule_layers.py:330: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead
WARNING - tensorflow - From /home/enterprise.internal.city.ac.uk/acvn728/MScFinalProject/SegCaps/capsule_layers.py:330: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead
WARNING:tensorflow:From /home/enterprise.internal.city.ac.uk/acvn728/MScFinalProject/SegCaps/capsule_layers.py:359: calling norm (from tensorflow.python.ops.linalg_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING - tensorflow - From /home/enterprise.internal.city.ac.uk/acvn728/MScFinalProject/SegCaps/capsule_layers.py:359: calling norm (from tensorflow.python.ops.linalg_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
Starting training
2018-11-28 07:51:52.673811: W tensorflow/core/framework/allocator.cc:113] Allocation of 67108864 exceeds 10% of system memory.
2018-11-28 07:51:52.748983: W tensorflow/core/framework/allocator.cc:113] Allocation of 67108864 exceeds 10% of system memory.
2018-11-28 07:51:52.843066: W tensorflow/core/framework/allocator.cc:113] Allocation of 67108864 exceeds 10% of system memory.
2018-11-28 07:51:52.904352: W tensorflow/core/framework/allocator.cc:113] Allocation of 67108864 exceeds 10% of system memory.
2018-11-28 07:51:53.006227: W tensorflow/core/framework/allocator.cc:113] Allocation of 67108864 exceeds 10% of system memory.
2018-11-28 07:52:04.144665: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:98] Filling up shuffle buffer (this may take a while): 313 of 1000
2018-11-28 07:52:14.128963: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:98] Filling up shuffle buffer (this may take a while): 720 of 1000
2018-11-28 07:52:21.488793: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:136] Shuffle buffer filled.
2018-11-28 07:53:19.156397:	Training iteration: 200, Loss: 0.007277978118509054
2018-11-28 07:54:15.107589:	Training iteration: 400, Loss: 0.005524054169654846
2018-11-28 07:55:10.891216:	Training iteration: 600, Loss: 0.004718815442174673
2018-11-28 07:56:06.707479:	Training iteration: 800, Loss: 0.005097556859254837
2018-11-28 07:57:02.589623:	Training iteration: 1000, Loss: 0.004369043279439211
2018-11-28 07:57:59.056652:	Training iteration: 1200, Loss: 0.004496526438742876
2018-11-28 07:58:55.747743:	Training iteration: 1400, Loss: 0.00609184056520462
2018-11-28 07:59:52.134042:	Training iteration: 1600, Loss: 0.003465903690084815
2018-11-28 08:00:47.882141:	Training iteration: 1800, Loss: 0.0059988051652908325
2018-11-28 08:01:45.144524:	Training iteration: 2000, Loss: 0.003946732264012098
2018-11-28 08:02:41.961589:	Training iteration: 2200, Loss: 0.004460811614990234
2018-11-28 08:03:39.224378:	Training iteration: 2400, Loss: 0.005450107157230377
2018-11-28 08:04:36.394777:	Training iteration: 2600, Loss: 0.004403542727231979
2018-11-28 08:05:34.009665:	Training iteration: 2800, Loss: 0.006725673098117113
2018-11-28 08:06:31.358144:	Training iteration: 3000, Loss: 0.006596997380256653
2018-11-28 08:07:28.261751:	Training iteration: 3200, Loss: 0.0059661888517439365
2018-11-28 08:08:25.601985:	Training iteration: 3400, Loss: 0.004757039248943329
2018-11-28 08:09:23.248477:	Training iteration: 3600, Loss: 0.004009635653346777
2018-11-28 08:10:20.531199:	Training iteration: 3800, Loss: 0.004920509178191423
2018-11-28 08:11:17.408007:	Training iteration: 4000, Loss: 0.006320396438241005
2018-11-28 08:12:16.814440:	Training iteration: 4200, Loss: 0.0029096847865730524
2018-11-28 08:13:15.406741:	Training iteration: 4400, Loss: 0.005641620140522718
2018-11-28 08:14:12.659897:	Training iteration: 4600, Loss: 0.005788888782262802
2018-11-28 08:15:10.643090:	Training iteration: 4800, Loss: 0.005226057022809982
2018-11-28 08:16:08.266161:	Training iteration: 5000, Loss: 0.005539941135793924
2018-11-28 08:17:06.925736:	Training iteration: 5200, Loss: 0.00641745887696743
2018-11-28 08:18:04.374734:	Training iteration: 5400, Loss: 0.00577668147161603
2018-11-28 08:19:03.014675:	Training iteration: 5600, Loss: 0.007156447973102331
2018-11-28 08:20:00.876474:	Training iteration: 5800, Loss: 0.005921164061874151
2018-11-28 08:20:59.572790:	Training iteration: 6000, Loss: 0.004696559626609087
2018-11-28 08:21:57.580456:	Training iteration: 6200, Loss: 0.0061035919934511185
2018-11-28 08:22:57.010289:	Training iteration: 6400, Loss: 0.006486322730779648
2018-11-28 08:23:54.693408:	Training iteration: 6600, Loss: 0.003735746257007122
2018-11-28 08:24:52.705976:	Training iteration: 6800, Loss: 0.004374129697680473
2018-11-28 08:25:50.423903:	Training iteration: 7000, Loss: 0.00428268127143383
2018-11-28 08:26:49.495538:	Training iteration: 7200, Loss: 0.003211297793313861
2018-11-28 08:27:47.163290:	Training iteration: 7400, Loss: 0.0036511814687401056
2018-11-28 08:28:44.752108:	Training iteration: 7600, Loss: 0.0054683685302734375
2018-11-28 08:29:43.634211:	Training iteration: 7800, Loss: 0.005833630915731192
2018-11-28 08:30:40.741560:	Training iteration: 8000, Loss: 0.0033368051517754793
2018-11-28 08:31:37.222590:	Training iteration: 8200, Loss: 0.003624027594923973
2018-11-28 08:32:05.198820: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:98] Filling up shuffle buffer (this may take a while): 333 of 1000
2018-11-28 08:32:15.295211: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:98] Filling up shuffle buffer (this may take a while): 715 of 1000
2018-11-28 08:32:22.379873: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:136] Shuffle buffer filled.
2018-11-28 08:33:01.182390:	Training iteration: 8400, Loss: 0.005734328180551529
2018-11-28 08:33:59.538450:	Training iteration: 8600, Loss: 0.008609223179519176
2018-11-28 08:34:57.375665:	Training iteration: 8800, Loss: 0.006352350115776062
2018-11-28 08:35:55.646404:	Training iteration: 9000, Loss: 0.007357353810220957
2018-11-28 08:36:54.116327:	Training iteration: 9200, Loss: 0.006705891340970993
2018-11-28 08:37:52.457411:	Training iteration: 9400, Loss: 0.00813505332916975
2018-11-28 08:38:51.397391:	Training iteration: 9600, Loss: 0.00722871208563447
2018-11-28 08:39:48.733181:	Training iteration: 9800, Loss: 0.00666462816298008
2018-11-28 08:40:47.205523:	Training iteration: 10000, Loss: 0.007740458939224482
2018-11-28 08:41:44.345278:	Training iteration: 10200, Loss: 0.005531436298042536
2018-11-28 08:42:43.922903:	Training iteration: 10400, Loss: 0.00788173358887434
2018-11-28 08:43:41.738424:	Training iteration: 10600, Loss: 0.0043638101778924465
2018-11-28 08:44:40.150049:	Training iteration: 10800, Loss: 0.0066620707511901855
2018-11-28 08:45:38.607184:	Training iteration: 11000, Loss: 0.004569010343402624
2018-11-28 08:46:36.036024:	Training iteration: 11200, Loss: 0.006475120782852173
2018-11-28 08:47:34.995279:	Training iteration: 11400, Loss: 0.005923884455114603
2018-11-28 08:48:33.055937:	Training iteration: 11600, Loss: 0.008193129673600197
2018-11-28 08:49:31.651098:	Training iteration: 11800, Loss: 0.006644127424806356
2018-11-28 08:50:29.320712:	Training iteration: 12000, Loss: 0.0059510222636163235
2018-11-28 08:51:29.294713:	Training iteration: 12200, Loss: 0.004781009629368782
2018-11-28 08:52:26.671942:	Training iteration: 12400, Loss: 0.005554331466555595
2018-11-28 08:53:24.501291:	Training iteration: 12600, Loss: 0.006222279276698828
2018-11-28 08:54:21.649164:	Training iteration: 12800, Loss: 0.005753129720687866
2018-11-28 08:55:19.091851:	Training iteration: 13000, Loss: 0.006815811153501272
2018-11-28 08:56:16.631655:	Training iteration: 13200, Loss: 0.006855988409370184
2018-11-28 08:57:13.856699:	Training iteration: 13400, Loss: 0.005521818995475769
2018-11-28 08:58:12.201023:	Training iteration: 13600, Loss: 0.004879880230873823
2018-11-28 08:59:09.224290:	Training iteration: 13800, Loss: 0.005621497984975576
2018-11-28 09:00:08.492166:	Training iteration: 14000, Loss: 0.005491532385349274
2018-11-28 09:01:08.476859:	Training iteration: 14200, Loss: 0.00514984829351306
2018-11-28 09:02:05.832293:	Training iteration: 14400, Loss: 0.0055940705351531506
2018-11-28 09:03:03.989861:	Training iteration: 14600, Loss: 0.006067765410989523
2018-11-28 09:04:02.380433:	Training iteration: 14800, Loss: 0.005342463031411171
2018-11-28 09:05:02.693445:	Training iteration: 15000, Loss: 0.00588312977924943
2018-11-28 09:06:01.310596:	Training iteration: 15200, Loss: 0.00762209901586175
2018-11-28 09:06:58.968426:	Training iteration: 15400, Loss: 0.004410783294588327
2018-11-28 09:07:56.019712:	Training iteration: 15600, Loss: 0.009576425887644291
2018-11-28 09:08:53.638037:	Training iteration: 15800, Loss: 0.004713940899819136
2018-11-28 09:09:51.564451:	Training iteration: 16000, Loss: 0.006157900672405958
2018-11-28 09:10:52.449140:	Training iteration: 16200, Loss: 0.0052610598504543304
2018-11-28 09:11:48.558539:	Training iteration: 16400, Loss: 0.006606169044971466
2018-11-28 09:12:48.137736: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:98] Filling up shuffle buffer (this may take a while): 339 of 1000
2018-11-28 09:12:58.170572: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:98] Filling up shuffle buffer (this may take a while): 751 of 1000
2018-11-28 09:13:04.057676: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:136] Shuffle buffer filled.
2018-11-28 09:13:11.146666:	Training iteration: 16600, Loss: 0.009616948664188385
2018-11-28 09:14:08.165647:	Training iteration: 16800, Loss: 0.005407559219747782
2018-11-28 09:15:05.823032:	Training iteration: 17000, Loss: 0.006493465509265661
2018-11-28 09:16:03.679008:	Training iteration: 17200, Loss: 0.009354992769658566
2018-11-28 09:17:01.163623:	Training iteration: 17400, Loss: 0.005582768470048904
2018-11-28 09:17:59.892713:	Training iteration: 17600, Loss: 0.007676790934056044
2018-11-28 09:18:58.096326:	Training iteration: 17800, Loss: 0.005167297553271055
2018-11-28 09:19:55.870151:	Training iteration: 18000, Loss: 0.006551758851855993
2018-11-28 09:20:52.639213:	Training iteration: 18200, Loss: 0.006700213998556137
2018-11-28 09:21:51.004645:	Training iteration: 18400, Loss: 0.0065894401632249355
2018-11-28 09:22:49.010807:	Training iteration: 18600, Loss: 0.00560486176982522
2018-11-28 09:23:48.584991:	Training iteration: 18800, Loss: 0.006043713539838791
2018-11-28 09:24:46.523996:	Training iteration: 19000, Loss: 0.004917227663099766
2018-11-28 09:25:44.374983:	Training iteration: 19200, Loss: 0.007956627756357193
2018-11-28 09:26:41.966429:	Training iteration: 19400, Loss: 0.005308227613568306
