INFO - UNet_Speech_Separation - Running command 'do_experiment'
INFO - UNet_Speech_Separation - Started run with ID "149"
Experiment ID: 149
Preparing dataset
Dataset ready
2018-10-21 12:14:35.671933: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-10-21 12:14:35.942835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-10-21 12:14:35.944391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:26:00.0
totalMemory: 10.91GiB freeMemory: 10.76GiB
2018-10-21 12:14:35.944412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:26:00.0, compute capability: 6.1)
Session started
Iterators created
Creating model
Running initialisation test
Starting testing
2018-10-21 12:14:48.391711:	Entering test loop
2018-10-21 12:14:58.922376: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 469 of 1000
2018-10-21 12:15:08.019252: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-21 12:15:16.731448:	Testing iteration: 0, Loss: 0.0067664943635463715
2018-10-21 12:17:10.747443:	Testing iteration: 200, Loss: 0.0048614260740578175
2018-10-21 12:19:05.567822:	Testing iteration: 400, Loss: 0.005713187158107758
2018-10-21 12:21:05.916506:	Testing iteration: 600, Loss: 0.007568668108433485
2018-10-21 12:23:08.580985:	Testing iteration: 800, Loss: 0.003867474151775241
2018-10-21 12:25:15.186852:	Testing iteration: 1000, Loss: 0.004866656381636858
2018-10-21 12:26:14.237378: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 586 of 1000
2018-10-21 12:26:20.700023: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-21 12:27:45.771777:	Testing iteration: 1200, Loss: 0.004695537965744734
2018-10-21 12:30:00.034911:	Testing iteration: 1400, Loss: 0.006452595815062523
2018-10-21 12:32:15.929225:	Testing iteration: 1600, Loss: 0.005985687952488661
2018-10-21 12:34:37.727806:	Testing iteration: 1800, Loss: 0.005522201303392649
2018-10-21 12:37:04.175368:	Testing iteration: 2000, Loss: 0.0063097551465034485
2018-10-21 12:39:04.275037: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 603 of 1000
2018-10-21 12:39:10.462029: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-21 12:39:46.463969:	Testing iteration: 2200, Loss: 0.0067658028565347195
2018-10-21 12:42:15.951047:	Testing iteration: 2400, Loss: 0.009105042554438114
2018-10-21 12:44:47.889483:	Testing iteration: 2600, Loss: 0.010166799649596214
2018-10-21 12:47:23.332191:	Testing iteration: 2800, Loss: 0.007524014916270971
2018-10-21 12:50:01.176643:	Testing iteration: 3000, Loss: 0.007472439203411341
2018-10-21 12:52:44.563422:	Testing iteration: 3200, Loss: 0.004548377823084593
2018-10-21 12:53:17.577103: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 606 of 1000
2018-10-21 12:53:23.446316: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-21 12:55:44.357811:	Testing iteration: 3400, Loss: 0.010156634263694286
2018-10-21 12:58:34.138067:	Testing iteration: 3600, Loss: 0.0041009485721588135
2018-10-21 13:01:38.682377:	Testing iteration: 3800, Loss: 0.0069780475459992886
2018-10-21 13:05:00.094384:	Testing iteration: 4000, Loss: 0.005777793470770121
2018-10-21 13:08:22.914739:	Testing iteration: 4200, Loss: 0.0068930648267269135
2018-10-21 13:10:21.267283: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 618 of 1000
2018-10-21 13:10:27.615506: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-21 13:12:02.825152:	Testing iteration: 4400, Loss: 0.006802053656429052
2018-10-21 13:15:14.416328:	Testing iteration: 4600, Loss: 0.009296963922679424
2018-10-21 13:18:22.872658:	Testing iteration: 4800, Loss: 0.012321126647293568
2018-10-21 13:21:32.716080:	Testing iteration: 5000, Loss: 0.006777389440685511
2018-10-21 13:24:45.477632:	Testing iteration: 5200, Loss: 0.009041144512593746
2018-10-21 13:28:02.278496:	Testing iteration: 5400, Loss: 0.007462214212864637
2018-10-21 13:31:19.869434:	Testing iteration: 5600, Loss: 0.0066007934510707855
2018-10-21 13:34:41.569262:	Testing iteration: 5800, Loss: 0.008079192601144314
2018-10-21 13:38:06.825837:	Testing iteration: 6000, Loss: 0.009128127247095108
2018-10-21 13:41:34.191175:	Testing iteration: 6200, Loss: 0.004442439414560795
Test pass complete
Mean loss over test set: 0.006722370703282082
Data saved to dumps/149 for later audio metric calculation
Starting training
2018-10-21 13:43:10.516080: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 692 of 1000
2018-10-21 13:43:14.507791: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-21 13:44:42.705171:	Training iteration: 200, Loss: 0.0037726934533566236
2018-10-21 13:46:18.734494:	Training iteration: 400, Loss: 0.004040947183966637
2018-10-21 13:48:01.059356:	Training iteration: 600, Loss: 0.0041722399182617664
2018-10-21 13:49:45.051175:	Training iteration: 800, Loss: 0.005352379288524389
2018-10-21 13:51:30.012897:	Training iteration: 1000, Loss: 0.0031208230648189783
2018-10-21 13:53:18.196084:	Training iteration: 1200, Loss: 0.0037995281163603067
2018-10-21 13:55:06.110586:	Training iteration: 1400, Loss: 0.004604616668075323
2018-10-21 13:56:54.032369:	Training iteration: 1600, Loss: 0.004598718602210283
2018-10-21 13:58:40.685123:	Training iteration: 1800, Loss: 0.003837287425994873
2018-10-21 14:00:28.058159:	Training iteration: 2000, Loss: 0.004872603341937065
2018-10-21 14:02:14.847446:	Training iteration: 2200, Loss: 0.002542734844610095
2018-10-21 14:04:03.736764:	Training iteration: 2400, Loss: 0.006266981363296509
2018-10-21 14:05:53.204489:	Training iteration: 2600, Loss: 0.004347190726548433
2018-10-21 14:07:43.584004:	Training iteration: 2800, Loss: 0.004915768280625343
2018-10-21 14:09:27.815328:	Training iteration: 3000, Loss: 0.005650512408465147
2018-10-21 14:11:13.144621:	Training iteration: 3200, Loss: 0.003979028668254614
2018-10-21 14:12:58.923009:	Training iteration: 3400, Loss: 0.003765036351978779
2018-10-21 14:14:44.395628:	Training iteration: 3600, Loss: 0.0040371776558458805
2018-10-21 14:16:29.852519:	Training iteration: 3800, Loss: 0.004439252428710461
2018-10-21 14:18:17.041870:	Training iteration: 4000, Loss: 0.005553100723773241
2018-10-21 14:20:04.432413:	Training iteration: 4200, Loss: 0.002881592372432351
2018-10-21 14:21:51.686121:	Training iteration: 4400, Loss: 0.0034376420080661774
2018-10-21 14:23:38.179938:	Training iteration: 4600, Loss: 0.004397931043058634
2018-10-21 14:25:24.365100:	Training iteration: 4800, Loss: 0.005932917352765799
2018-10-21 14:27:09.538034:	Training iteration: 5000, Loss: 0.005023652222007513
2018-10-21 14:28:55.893225:	Training iteration: 5200, Loss: 0.004208942409604788
2018-10-21 14:30:42.569083:	Training iteration: 5400, Loss: 0.0034269343595951796
2018-10-21 14:32:30.491559:	Training iteration: 5600, Loss: 0.005241965409368277
2018-10-21 14:34:17.875079:	Training iteration: 5800, Loss: 0.0036563079338520765
2018-10-21 14:36:04.372649:	Training iteration: 6000, Loss: 0.003989153541624546
2018-10-21 14:37:49.826573:	Training iteration: 6200, Loss: 0.0046133059076964855
2018-10-21 14:39:38.120326:	Training iteration: 6400, Loss: 0.004190834239125252
2018-10-21 14:41:26.610189:	Training iteration: 6600, Loss: 0.0034785978496074677
2018-10-21 14:43:15.860765:	Training iteration: 6800, Loss: 0.004301533568650484
2018-10-21 14:45:03.964146:	Training iteration: 7000, Loss: 0.004884280730038881
2018-10-21 14:46:53.450525:	Training iteration: 7200, Loss: 0.004045052453875542
2018-10-21 14:48:42.176476:	Training iteration: 7400, Loss: 0.004717858508229256
2018-10-21 14:50:30.438927:	Training iteration: 7600, Loss: 0.0040185716934502125
2018-10-21 14:52:17.896466:	Training iteration: 7800, Loss: 0.004369428846985102
2018-10-21 14:54:03.657399:	Training iteration: 8000, Loss: 0.005783951375633478
2018-10-21 14:55:51.746180:	Training iteration: 8200, Loss: 0.004078024532645941
2018-10-21 14:56:35.048587: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 642 of 1000
2018-10-21 14:56:39.950467: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-21 14:57:47.895101:	Training iteration: 8400, Loss: 0.006537502631545067
2018-10-21 14:59:34.319926:	Training iteration: 8600, Loss: 0.00686138728633523
2018-10-21 15:01:24.916625:	Training iteration: 8800, Loss: 0.004093351308256388
2018-10-21 15:03:11.164668:	Training iteration: 9000, Loss: 0.004184307996183634
2018-10-21 15:04:57.962730:	Training iteration: 9200, Loss: 0.003728957613930106
2018-10-21 15:06:47.812309:	Training iteration: 9400, Loss: 0.004763621371239424
2018-10-21 15:08:35.342489:	Training iteration: 9600, Loss: 0.004674328025430441
2018-10-21 15:10:24.075431:	Training iteration: 9800, Loss: 0.005813965108245611
2018-10-21 15:12:14.430022:	Training iteration: 10000, Loss: 0.004321030806750059
Checkpoint
2018-10-21 15:14:18.754365:	Training iteration: 10200, Loss: 0.005622869823127985
2018-10-21 15:16:02.065809:	Training iteration: 10400, Loss: 0.004407168831676245
2018-10-21 15:17:48.856836:	Training iteration: 10600, Loss: 0.004608117043972015
2018-10-21 15:19:35.239700:	Training iteration: 10800, Loss: 0.004551224410533905
2018-10-21 15:21:21.443409:	Training iteration: 11000, Loss: 0.005580951925367117
2018-10-21 15:23:07.663243:	Training iteration: 11200, Loss: 0.004218424204736948
2018-10-21 15:24:53.954434:	Training iteration: 11400, Loss: 0.0055897594429552555
2018-10-21 15:26:38.478281:	Training iteration: 11600, Loss: 0.00651344982907176
2018-10-21 15:28:24.189356:	Training iteration: 11800, Loss: 0.004975136369466782
2018-10-21 15:30:11.520507:	Training iteration: 12000, Loss: 0.005701734218746424
2018-10-21 15:31:56.948342:	Training iteration: 12200, Loss: 0.004095959011465311
2018-10-21 15:33:43.401207:	Training iteration: 12400, Loss: 0.003544008359313011
2018-10-21 15:35:29.623278:	Training iteration: 12600, Loss: 0.005294140428304672
2018-10-21 15:37:19.424392:	Training iteration: 12800, Loss: 0.003959173336625099
2018-10-21 15:38:51.865793:	Training iteration: 13000, Loss: 0.004244996700435877
2018-10-21 15:40:19.446772:	Training iteration: 13200, Loss: 0.0038694695103913546
2018-10-21 15:41:46.582434:	Training iteration: 13400, Loss: 0.005783988628536463
2018-10-21 15:43:12.582497:	Training iteration: 13600, Loss: 0.005817478056997061
2018-10-21 15:44:37.649067:	Training iteration: 13800, Loss: 0.00456068804487586
2018-10-21 15:46:05.099871:	Training iteration: 14000, Loss: 0.0047765509225428104
2018-10-21 15:47:38.657402:	Training iteration: 14200, Loss: 0.0044247801415622234
2018-10-21 15:49:19.961366:	Training iteration: 14400, Loss: 0.005338374059647322
2018-10-21 15:51:04.353967:	Training iteration: 14600, Loss: 0.004980985075235367
2018-10-21 15:53:05.113451:	Training iteration: 14800, Loss: 0.004015162121504545
2018-10-21 15:54:47.690795:	Training iteration: 15000, Loss: 0.004945915192365646
2018-10-21 15:56:36.191905:	Training iteration: 15200, Loss: 0.0036298104096204042
2018-10-21 15:58:27.340586:	Training iteration: 15400, Loss: 0.005385936703532934
2018-10-21 16:00:20.801355:	Training iteration: 15600, Loss: 0.0037600763607770205
2018-10-21 16:02:19.387355:	Training iteration: 15800, Loss: 0.0045217047445476055
2018-10-21 16:04:19.866428:	Training iteration: 16000, Loss: 0.0048203556798398495
2018-10-21 16:06:20.698215:	Training iteration: 16200, Loss: 0.0050347899086773396
2018-10-21 16:08:20.279528:	Training iteration: 16400, Loss: 0.005184689536690712
2018-10-21 16:10:13.089956: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 631 of 1000
2018-10-21 16:10:17.933958: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-21 16:10:28.916511:	Training iteration: 16600, Loss: 0.006448822561651468
2018-10-21 16:12:19.916481:	Training iteration: 16800, Loss: 0.004867831710726023
2018-10-21 16:14:12.702258:	Training iteration: 17000, Loss: 0.005336580332368612
2018-10-21 16:15:59.775076:	Training iteration: 17200, Loss: 0.005315958056598902
2018-10-21 16:17:47.150681:	Training iteration: 17400, Loss: 0.008662131614983082
2018-10-21 16:19:34.630007:	Training iteration: 17600, Loss: 0.0060807145200669765
2018-10-21 16:21:22.873845:	Training iteration: 17800, Loss: 0.004506553988903761
2018-10-21 16:23:11.351942:	Training iteration: 18000, Loss: 0.005689407233148813
2018-10-21 16:25:01.864518:	Training iteration: 18200, Loss: 0.004799462854862213
2018-10-21 16:26:51.311924:	Training iteration: 18400, Loss: 0.0050361971370875835
2018-10-21 16:28:39.637904:	Training iteration: 18600, Loss: 0.005273330956697464
2018-10-21 16:30:27.044609:	Training iteration: 18800, Loss: 0.005923168733716011
2018-10-21 16:32:13.707545:	Training iteration: 19000, Loss: 0.005755996331572533
2018-10-21 16:34:03.608357:	Training iteration: 19200, Loss: 0.004024003632366657
2018-10-21 16:35:53.890201:	Training iteration: 19400, Loss: 0.005356708075851202
2018-10-21 16:37:42.381874:	Training iteration: 19600, Loss: 0.004822164308279753
2018-10-21 16:39:31.567287:	Training iteration: 19800, Loss: 0.004129207693040371
2018-10-21 16:41:18.732259:	Training iteration: 20000, Loss: 0.004732923582196236
Checkpoint
2018-10-21 16:43:49.232100:	Training iteration: 20200, Loss: 0.005631677806377411
2018-10-21 16:45:29.798003:	Training iteration: 20400, Loss: 0.004930447321385145
2018-10-21 16:47:13.274050:	Training iteration: 20600, Loss: 0.006695280317217112
2018-10-21 16:48:56.900395:	Training iteration: 20800, Loss: 0.0048722680658102036
2018-10-21 16:50:43.127346:	Training iteration: 21000, Loss: 0.004515289794653654
2018-10-21 16:52:30.038543:	Training iteration: 21200, Loss: 0.006878615822643042
2018-10-21 16:54:18.130137:	Training iteration: 21400, Loss: 0.005369042977690697
2018-10-21 16:56:05.168008:	Training iteration: 21600, Loss: 0.0032893826719373465
2018-10-21 16:57:52.073184:	Training iteration: 21800, Loss: 0.00567741459235549
2018-10-21 16:59:39.319099:	Training iteration: 22000, Loss: 0.003762936219573021
2018-10-21 17:01:25.217605:	Training iteration: 22200, Loss: 0.00709480931982398
2018-10-21 17:03:13.750735:	Training iteration: 22400, Loss: 0.004565655253827572
2018-10-21 17:05:01.974266:	Training iteration: 22600, Loss: 0.004134416114538908
2018-10-21 17:06:48.959794:	Training iteration: 22800, Loss: 0.00445933360606432
2018-10-21 17:08:37.102621:	Training iteration: 23000, Loss: 0.0047761257737874985
2018-10-21 17:10:26.503938:	Training iteration: 23200, Loss: 0.006490966770797968
2018-10-21 17:12:17.668040:	Training iteration: 23400, Loss: 0.005479301791638136
2018-10-21 17:14:09.857462:	Training iteration: 23600, Loss: 0.004304150119423866
2018-10-21 17:16:01.892162:	Training iteration: 23800, Loss: 0.005655287299305201
2018-10-21 17:17:52.463087:	Training iteration: 24000, Loss: 0.0054082684218883514
2018-10-21 17:19:39.997575:	Training iteration: 24200, Loss: 0.006090777460485697
2018-10-21 17:21:26.586942:	Training iteration: 24400, Loss: 0.00369894877076149
2018-10-21 17:23:13.746373:	Training iteration: 24600, Loss: 0.004281382542103529
2018-10-21 17:25:02.814095:	Training iteration: 24800, Loss: 0.006234075874090195
2018-10-21 17:25:57.698491: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 661 of 1000
2018-10-21 17:26:02.183969: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-21 17:27:00.817918:	Training iteration: 25000, Loss: 0.004215410444885492
2018-10-21 17:28:48.354826:	Training iteration: 25200, Loss: 0.003845197381451726
2018-10-21 17:30:36.433575:	Training iteration: 25400, Loss: 0.003920992370694876
2018-10-21 17:32:24.945351:	Training iteration: 25600, Loss: 0.0044617061503231525
2018-10-21 17:34:11.977530:	Training iteration: 25800, Loss: 0.003642231924459338
2018-10-21 17:36:00.893938:	Training iteration: 26000, Loss: 0.006205336656421423
2018-10-21 17:37:49.996472:	Training iteration: 26200, Loss: 0.0042540766298770905
2018-10-21 17:39:36.673851:	Training iteration: 26400, Loss: 0.004998540971428156
2018-10-21 17:41:21.722012:	Training iteration: 26600, Loss: 0.0040438175201416016
2018-10-21 17:43:12.527214:	Training iteration: 26800, Loss: 0.006615743041038513
2018-10-21 17:45:00.132862:	Training iteration: 27000, Loss: 0.004113791044801474
2018-10-21 17:46:48.820223:	Training iteration: 27200, Loss: 0.00529438117519021
2018-10-21 17:48:36.402742:	Training iteration: 27400, Loss: 0.006298985332250595
2018-10-21 17:50:23.992535:	Training iteration: 27600, Loss: 0.0037615057080984116
2018-10-21 17:52:12.154586:	Training iteration: 27800, Loss: 0.003439035266637802
2018-10-21 17:54:02.311487:	Training iteration: 28000, Loss: 0.005555763375014067
2018-10-21 17:55:51.687642:	Training iteration: 28200, Loss: 0.0050086588598787785
2018-10-21 17:57:41.264807:	Training iteration: 28400, Loss: 0.005677816923707724
2018-10-21 17:59:31.512824:	Training iteration: 28600, Loss: 0.0038973602931946516
2018-10-21 18:01:21.112813:	Training iteration: 28800, Loss: 0.0036103276070207357
2018-10-21 18:03:12.733046:	Training iteration: 29000, Loss: 0.0027827646117657423
2018-10-21 18:05:02.849546:	Training iteration: 29200, Loss: 0.004931362811475992
2018-10-21 18:06:50.370787:	Training iteration: 29400, Loss: 0.005077969282865524
2018-10-21 18:08:38.718541:	Training iteration: 29600, Loss: 0.003868143307045102
2018-10-21 18:10:27.813376:	Training iteration: 29800, Loss: 0.004204252269119024
2018-10-21 18:12:17.611475:	Training iteration: 30000, Loss: 0.00598873570561409
Checkpoint
2018-10-21 18:14:07.844306:	Training iteration: 30200, Loss: 0.005401221569627523
2018-10-21 18:15:56.489219:	Training iteration: 30400, Loss: 0.0028752803336828947
2018-10-21 18:17:44.391083:	Training iteration: 30600, Loss: 0.004662145860493183
2018-10-21 18:19:34.397654:	Training iteration: 30800, Loss: 0.005600946489721537
2018-10-21 18:21:27.141674:	Training iteration: 31000, Loss: 0.003795548574998975
2018-10-21 18:23:18.743779:	Training iteration: 31200, Loss: 0.003380751935765147
2018-10-21 18:25:11.622190:	Training iteration: 31400, Loss: 0.004735768307000399
2018-10-21 18:27:03.809690:	Training iteration: 31600, Loss: 0.004456364084035158
2018-10-21 18:28:54.880417:	Training iteration: 31800, Loss: 0.004860505927354097
2018-10-21 18:30:44.750552:	Training iteration: 32000, Loss: 0.004325216170400381
2018-10-21 18:32:34.373465:	Training iteration: 32200, Loss: 0.0036490755155682564
2018-10-21 18:34:25.684988:	Training iteration: 32400, Loss: 0.004856365267187357
2018-10-21 18:36:17.377821:	Training iteration: 32600, Loss: 0.005225112196058035
2018-10-21 18:38:08.771215:	Training iteration: 32800, Loss: 0.005779445171356201
2018-10-21 18:39:57.824869:	Training iteration: 33000, Loss: 0.003518257988616824
2018-10-21 18:41:49.510369:	Training iteration: 33200, Loss: 0.004583823960274458
2018-10-21 18:43:41.634450:	Training iteration: 33400, Loss: 0.004115989897400141
2018-10-21 18:45:23.176103: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 720 of 1000
2018-10-21 18:45:26.302523: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-21 18:45:43.920517:	Training iteration: 33600, Loss: 0.007016906514763832
2018-10-21 18:47:31.724022:	Training iteration: 33800, Loss: 0.006462448742240667
2018-10-21 18:49:20.988146:	Training iteration: 34000, Loss: 0.008300799876451492
2018-10-21 18:51:10.366501:	Training iteration: 34200, Loss: 0.004849076736718416
2018-10-21 18:53:01.189127:	Training iteration: 34400, Loss: 0.006728440057486296
2018-10-21 18:54:51.495967:	Training iteration: 34600, Loss: 0.0066247135400772095
2018-10-21 18:56:41.164599:	Training iteration: 34800, Loss: 0.004763510078191757
2018-10-21 18:58:30.868513:	Training iteration: 35000, Loss: 0.003498772857710719
2018-10-21 19:00:20.668272:	Training iteration: 35200, Loss: 0.003877554088830948
2018-10-21 19:02:10.010893:	Training iteration: 35400, Loss: 0.005445197224617004
2018-10-21 19:03:59.363413:	Training iteration: 35600, Loss: 0.00542322127148509
2018-10-21 19:05:47.424124:	Training iteration: 35800, Loss: 0.00835817214101553
2018-10-21 19:07:35.573690:	Training iteration: 36000, Loss: 0.009067405946552753
2018-10-21 19:09:23.006396:	Training iteration: 36200, Loss: 0.004740412812680006
2018-10-21 19:11:11.312857:	Training iteration: 36400, Loss: 0.004996582865715027
2018-10-21 19:12:59.738065:	Training iteration: 36600, Loss: 0.003388046519830823
2018-10-21 19:14:49.178671:	Training iteration: 36800, Loss: 0.004853413440287113
2018-10-21 19:16:37.975754:	Training iteration: 37000, Loss: 0.004671166185289621
2018-10-21 19:18:28.340955:	Training iteration: 37200, Loss: 0.0032426349353045225
2018-10-21 19:20:18.544840:	Training iteration: 37400, Loss: 0.005789484828710556
2018-10-21 19:22:10.097244:	Training iteration: 37600, Loss: 0.005435949191451073
2018-10-21 19:23:57.518116:	Training iteration: 37800, Loss: 0.005204298533499241
2018-10-21 19:25:45.697186:	Training iteration: 38000, Loss: 0.005562978330999613
2018-10-21 19:27:35.648752:	Training iteration: 38200, Loss: 0.006859338376671076
2018-10-21 19:29:26.197090:	Training iteration: 38400, Loss: 0.007833237759768963
2018-10-21 19:31:16.693010:	Training iteration: 38600, Loss: 0.004051674623042345
2018-10-21 19:33:05.780081:	Training iteration: 38800, Loss: 0.004250612575560808
2018-10-21 19:34:55.057271:	Training iteration: 39000, Loss: 0.005702211055904627
2018-10-21 19:36:45.005570:	Training iteration: 39200, Loss: 0.004606613889336586
2018-10-21 19:38:34.474302:	Training iteration: 39400, Loss: 0.003071095561608672
2018-10-21 19:40:22.188439:	Training iteration: 39600, Loss: 0.0034194334875792265
2018-10-21 19:42:09.985496:	Training iteration: 39800, Loss: 0.003488769056275487
2018-10-21 19:44:00.765473:	Training iteration: 40000, Loss: 0.004917967598885298
Checkpoint
2018-10-21 19:45:52.219644:	Training iteration: 40200, Loss: 0.008124075829982758
2018-10-21 19:47:40.073883:	Training iteration: 40400, Loss: 0.003511110320687294
2018-10-21 19:49:29.823503:	Training iteration: 40600, Loss: 0.00648132711648941
2018-10-21 19:51:22.287258:	Training iteration: 40800, Loss: 0.005947371479123831
2018-10-21 19:53:14.524159:	Training iteration: 41000, Loss: 0.00721761817112565
2018-10-21 19:55:09.435771:	Training iteration: 41200, Loss: 0.003917214926332235
2018-10-21 19:57:03.676043:	Training iteration: 41400, Loss: 0.006819050759077072
2018-10-21 19:58:56.238330:	Training iteration: 41600, Loss: 0.005684154573827982
2018-10-21 20:00:52.105677:	Training iteration: 41800, Loss: 0.0035674944519996643
2018-10-21 20:02:46.062738:	Training iteration: 42000, Loss: 0.00548192672431469
2018-10-21 20:04:42.280955:	Training iteration: 42200, Loss: 0.006606787908822298
2018-10-21 20:06:34.962933:	Training iteration: 42400, Loss: 0.006742683704942465
2018-10-21 20:08:29.608815:	Training iteration: 42600, Loss: 0.00912133976817131
2018-10-21 20:10:24.447003:	Training iteration: 42800, Loss: 0.0047606793232262135
2018-10-21 20:12:17.576260:	Training iteration: 43000, Loss: 0.006663425359874964
2018-10-21 20:14:08.894814:	Training iteration: 43200, Loss: 0.00766144460067153
2018-10-21 20:16:00.127203:	Training iteration: 43400, Loss: 0.0063780671916902065
2018-10-21 20:17:49.599204:	Training iteration: 43600, Loss: 0.004957374185323715
2018-10-21 20:19:39.860029:	Training iteration: 43800, Loss: 0.005125824827700853
2018-10-21 20:21:30.747317:	Training iteration: 44000, Loss: 0.005597698036581278
2018-10-21 20:23:21.269289:	Training iteration: 44200, Loss: 0.00700734369456768
2018-10-21 20:25:11.189444:	Training iteration: 44400, Loss: 0.0038762844633311033
2018-10-21 20:27:01.840648:	Training iteration: 44600, Loss: 0.007153382059186697
2018-10-21 20:28:50.572578:	Training iteration: 44800, Loss: 0.004779379814863205
2018-10-21 20:30:38.247130:	Training iteration: 45000, Loss: 0.010891617275774479
2018-10-21 20:32:27.399927:	Training iteration: 45200, Loss: 0.00746935373172164
2018-10-21 20:34:15.342283:	Training iteration: 45400, Loss: 0.0066754757426679134
2018-10-21 20:36:04.501287:	Training iteration: 45600, Loss: 0.00799452792853117
2018-10-21 20:37:53.077259:	Training iteration: 45800, Loss: 0.006988395005464554
2018-10-21 20:39:44.206365:	Training iteration: 46000, Loss: 0.004932987969368696
2018-10-21 20:41:33.460869:	Training iteration: 46200, Loss: 0.004527607467025518
2018-10-21 20:43:21.611722:	Training iteration: 46400, Loss: 0.007987109944224358
2018-10-21 20:45:07.416030:	Training iteration: 46600, Loss: 0.006446583662182093
2018-10-21 20:46:54.331150:	Training iteration: 46800, Loss: 0.00825469195842743
2018-10-21 20:48:40.917495:	Training iteration: 47000, Loss: 0.0041452632285654545
2018-10-21 20:50:27.378832:	Training iteration: 47200, Loss: 0.006689500063657761
2018-10-21 20:52:15.236420:	Training iteration: 47400, Loss: 0.006478801369667053
2018-10-21 20:54:04.183832:	Training iteration: 47600, Loss: 0.0053203110583126545
2018-10-21 20:55:51.572881:	Training iteration: 47800, Loss: 0.0042138188146054745
2018-10-21 20:57:40.869157:	Training iteration: 48000, Loss: 0.004259031731635332
2018-10-21 20:59:14.883371:	Training iteration: 48200, Loss: 0.005187679547816515
2018-10-21 21:00:55.215061:	Training iteration: 48400, Loss: 0.005395069252699614
2018-10-21 21:02:39.635977:	Training iteration: 48600, Loss: 0.00831468403339386
2018-10-21 21:04:25.635311:	Training iteration: 48800, Loss: 0.0069135078229010105
2018-10-21 21:06:12.438078:	Training iteration: 49000, Loss: 0.008034073747694492
2018-10-21 21:07:58.635610:	Training iteration: 49200, Loss: 0.005280064418911934
2018-10-21 21:09:44.917984:	Training iteration: 49400, Loss: 0.00743850925937295
2018-10-21 21:11:31.984862:	Training iteration: 49600, Loss: 0.00570099800825119
2018-10-21 21:13:19.256390:	Training iteration: 49800, Loss: 0.007264683023095131
2018-10-21 21:15:08.060132:	Training iteration: 50000, Loss: 0.006581742316484451
Checkpoint
2018-10-21 21:16:57.898114:	Training iteration: 50200, Loss: 0.0052603743970394135
2018-10-21 21:18:45.017888:	Training iteration: 50400, Loss: 0.007216181606054306
2018-10-21 21:20:31.391430:	Training iteration: 50600, Loss: 0.005863734986633062
2018-10-21 21:22:20.200229:	Training iteration: 50800, Loss: 0.003995532635599375
2018-10-21 21:24:08.440480:	Training iteration: 51000, Loss: 0.008589275181293488
2018-10-21 21:25:57.128139:	Training iteration: 51200, Loss: 0.006887430790811777
2018-10-21 21:27:45.852798:	Training iteration: 51400, Loss: 0.004514607135206461
2018-10-21 21:29:33.993947:	Training iteration: 51600, Loss: 0.011661347001791
2018-10-21 21:31:22.332120:	Training iteration: 51800, Loss: 0.007009891327470541
2018-10-21 21:33:12.293536:	Training iteration: 52000, Loss: 0.004554403480142355
2018-10-21 21:35:02.769896:	Training iteration: 52200, Loss: 0.004638811107724905
2018-10-21 21:36:50.880417:	Training iteration: 52400, Loss: 0.007954242639243603
2018-10-21 21:38:38.809190:	Training iteration: 52600, Loss: 0.009285062551498413
2018-10-21 21:40:27.526409:	Training iteration: 52800, Loss: 0.0061895283870399
2018-10-21 21:42:15.141852:	Training iteration: 53000, Loss: 0.004750473890453577
2018-10-21 21:44:02.986071:	Training iteration: 53200, Loss: 0.0037820052821189165
2018-10-21 21:45:51.364109:	Training iteration: 53400, Loss: 0.004379295278340578
2018-10-21 21:47:39.609356:	Training iteration: 53600, Loss: 0.004329513292759657
2018-10-21 21:49:27.160589:	Training iteration: 53800, Loss: 0.007002662867307663
2018-10-21 21:51:14.249440:	Training iteration: 54000, Loss: 0.005219649523496628
2018-10-21 21:53:00.943336:	Training iteration: 54200, Loss: 0.0033481114078313112
2018-10-21 21:54:49.631433:	Training iteration: 54400, Loss: 0.0051173013634979725
2018-10-21 21:56:38.254795:	Training iteration: 54600, Loss: 0.0031820200383663177
2018-10-21 21:58:27.852030:	Training iteration: 54800, Loss: 0.006685107480734587
2018-10-21 22:00:15.160931:	Training iteration: 55000, Loss: 0.004308927338570356
2018-10-21 22:02:00.791062:	Training iteration: 55200, Loss: 0.007068139035254717
2018-10-21 22:03:47.827020:	Training iteration: 55400, Loss: 0.0038737349677830935
2018-10-21 22:05:34.592266:	Training iteration: 55600, Loss: 0.005362195428460836
2018-10-21 22:07:23.321101:	Training iteration: 55800, Loss: 0.007059136405587196
2018-10-21 22:09:13.243848:	Training iteration: 56000, Loss: 0.008466645143926144
2018-10-21 22:11:01.753710:	Training iteration: 56200, Loss: 0.004992831964045763
2018-10-21 22:12:53.752650:	Training iteration: 56400, Loss: 0.008902009576559067
2018-10-21 22:14:44.077182:	Training iteration: 56600, Loss: 0.004504029173403978
2018-10-21 22:16:33.426825:	Training iteration: 56800, Loss: 0.0053314934484660625
2018-10-21 22:18:21.467687:	Training iteration: 57000, Loss: 0.008844410069286823
2018-10-21 22:20:10.424271:	Training iteration: 57200, Loss: 0.00563775934278965
2018-10-21 22:22:00.173255:	Training iteration: 57400, Loss: 0.0036998651921749115
2018-10-21 22:23:51.368391:	Training iteration: 57600, Loss: 0.006746351253241301
2018-10-21 22:25:42.595893:	Training iteration: 57800, Loss: 0.005356110632419586
2018-10-21 22:27:32.861515:	Training iteration: 58000, Loss: 0.0028189278673380613
2018-10-21 22:29:20.867874:	Training iteration: 58200, Loss: 0.005045974627137184
2018-10-21 22:31:10.355391:	Training iteration: 58400, Loss: 0.0041547599248588085
2018-10-21 22:32:56.111448:	Training iteration: 58600, Loss: 0.0054999166168272495
2018-10-21 22:34:44.778063:	Training iteration: 58800, Loss: 0.007408348377794027
2018-10-21 22:36:34.171631:	Training iteration: 59000, Loss: 0.003856225870549679
2018-10-21 22:38:21.638179:	Training iteration: 59200, Loss: 0.004190923646092415
2018-10-21 22:40:09.706513:	Training iteration: 59400, Loss: 0.0050157043151557446
2018-10-21 22:41:58.428474:	Training iteration: 59600, Loss: 0.0045067667961120605
2018-10-21 22:43:48.160321:	Training iteration: 59800, Loss: 0.004989513661712408
2018-10-21 22:45:39.453804:	Training iteration: 60000, Loss: 0.004545015748590231
Checkpoint
2018-10-21 22:47:31.208618:	Training iteration: 60200, Loss: 0.007426382973790169
2018-10-21 22:49:19.993147:	Training iteration: 60400, Loss: 0.005902457982301712
2018-10-21 22:51:07.831673:	Training iteration: 60600, Loss: 0.005054414737969637
2018-10-21 22:52:56.402820:	Training iteration: 60800, Loss: 0.008741769939661026
2018-10-21 22:54:44.803997:	Training iteration: 61000, Loss: 0.004400686826556921
2018-10-21 22:56:34.106083:	Training iteration: 61200, Loss: 0.006048053037375212
2018-10-21 22:58:21.477343:	Training iteration: 61400, Loss: 0.004618094768375158
2018-10-21 23:00:09.325263:	Training iteration: 61600, Loss: 0.008037727326154709
2018-10-21 23:01:58.611285:	Training iteration: 61800, Loss: 0.005752407014369965
2018-10-21 23:03:45.351454:	Training iteration: 62000, Loss: 0.005562891718000174
2018-10-21 23:05:30.660493:	Training iteration: 62200, Loss: 0.0061959158629179
2018-10-21 23:07:16.174994:	Training iteration: 62400, Loss: 0.0035639237612485886
2018-10-21 23:09:03.560804:	Training iteration: 62600, Loss: 0.009478184394538403
2018-10-21 23:10:51.882877:	Training iteration: 62800, Loss: 0.0060341390781104565
2018-10-21 23:12:38.673544:	Training iteration: 63000, Loss: 0.009359347634017467
2018-10-21 23:14:24.778845:	Training iteration: 63200, Loss: 0.004075673408806324
2018-10-21 23:16:11.465206:	Training iteration: 63400, Loss: 0.00820866134017706
2018-10-21 23:17:59.283124:	Training iteration: 63600, Loss: 0.006848569493740797
2018-10-21 23:19:46.240971:	Training iteration: 63800, Loss: 0.008320939727127552
2018-10-21 23:21:35.062506:	Training iteration: 64000, Loss: 0.00840615201741457
2018-10-21 23:23:23.364405:	Training iteration: 64200, Loss: 0.012011236511170864
2018-10-21 23:25:10.773357:	Training iteration: 64400, Loss: 0.0038216973189264536
2018-10-21 23:26:58.994904:	Training iteration: 64600, Loss: 0.003594551933929324
2018-10-21 23:28:46.461470:	Training iteration: 64800, Loss: 0.004863489884883165
2018-10-21 23:30:34.624518:	Training iteration: 65000, Loss: 0.004581726621836424
2018-10-21 23:32:22.209738:	Training iteration: 65200, Loss: 0.0053322226740419865
2018-10-21 23:34:10.749343:	Training iteration: 65400, Loss: 0.005856575444340706
2018-10-21 23:35:58.999867:	Training iteration: 65600, Loss: 0.005004414822906256
2018-10-21 23:37:46.100889:	Training iteration: 65800, Loss: 0.005387600511312485
2018-10-21 23:39:33.891490:	Training iteration: 66000, Loss: 0.00997703056782484
2018-10-21 23:41:21.992682:	Training iteration: 66200, Loss: 0.004865328315645456
2018-10-21 23:43:10.760331:	Training iteration: 66400, Loss: 0.004437791649252176
2018-10-21 23:44:59.972627:	Training iteration: 66600, Loss: 0.004555757623165846
2018-10-21 23:46:48.585754:	Training iteration: 66800, Loss: 0.004114571958780289
2018-10-21 23:48:38.277391:	Training iteration: 67000, Loss: 0.007015701849013567
2018-10-21 23:50:30.142972:	Training iteration: 67200, Loss: 0.00414067879319191
2018-10-21 23:52:21.559679:	Training iteration: 67400, Loss: 0.004924467299133539
2018-10-21 23:54:13.089070:	Training iteration: 67600, Loss: 0.004344699438661337
2018-10-21 23:56:05.349687:	Training iteration: 67800, Loss: 0.005461327265948057
2018-10-21 23:57:58.901996:	Training iteration: 68000, Loss: 0.004373180214315653
2018-10-21 23:59:49.101198:	Training iteration: 68200, Loss: 0.003957963082939386
2018-10-22 00:01:40.730905:	Training iteration: 68400, Loss: 0.007538292091339827
2018-10-22 00:03:34.218588:	Training iteration: 68600, Loss: 0.005127046722918749
2018-10-22 00:05:27.364788:	Training iteration: 68800, Loss: 0.005450190510600805
2018-10-22 00:07:22.356099:	Training iteration: 69000, Loss: 0.006613302510231733
2018-10-22 00:09:15.757678:	Training iteration: 69200, Loss: 0.004688641522079706
2018-10-22 00:11:07.255345:	Training iteration: 69400, Loss: 0.004088318906724453
2018-10-22 00:12:56.182496:	Training iteration: 69600, Loss: 0.005764196161180735
2018-10-22 00:14:44.712046:	Training iteration: 69800, Loss: 0.0049310773611068726
2018-10-22 00:16:32.473672:	Training iteration: 70000, Loss: 0.005547078792005777
Checkpoint
2018-10-22 00:18:24.087618:	Training iteration: 70200, Loss: 0.003518499666824937
2018-10-22 00:20:14.748895:	Training iteration: 70400, Loss: 0.005047349724918604
2018-10-22 00:22:06.491155:	Training iteration: 70600, Loss: 0.006914117839187384
2018-10-22 00:23:57.217854:	Training iteration: 70800, Loss: 0.006084675434976816
2018-10-22 00:25:47.994722:	Training iteration: 71000, Loss: 0.006733367685228586
2018-10-22 00:27:38.360075:	Training iteration: 71200, Loss: 0.006653787102550268
2018-10-22 00:29:26.352988:	Training iteration: 71400, Loss: 0.005024620797485113
2018-10-22 00:31:14.151102:	Training iteration: 71600, Loss: 0.005913719534873962
2018-10-22 00:33:02.539809:	Training iteration: 71800, Loss: 0.006393488496541977
2018-10-22 00:34:50.854726:	Training iteration: 72000, Loss: 0.005049120634794235
2018-10-22 00:36:37.653963:	Training iteration: 72200, Loss: 0.007887756451964378
2018-10-22 00:38:24.390701:	Training iteration: 72400, Loss: 0.004456155002117157
2018-10-22 00:40:11.695095:	Training iteration: 72600, Loss: 0.004428191110491753
2018-10-22 00:41:58.966039:	Training iteration: 72800, Loss: 0.005547558888792992
2018-10-22 00:43:47.356157:	Training iteration: 73000, Loss: 0.004498774651437998
2018-10-22 00:45:34.486972:	Training iteration: 73200, Loss: 0.005369298625737429
2018-10-22 00:47:20.726384:	Training iteration: 73400, Loss: 0.0058089750818908215
2018-10-22 00:49:08.547620:	Training iteration: 73600, Loss: 0.004876564722508192
2018-10-22 00:50:58.036551:	Training iteration: 73800, Loss: 0.005642857402563095
2018-10-22 00:52:48.455860:	Training iteration: 74000, Loss: 0.006148507818579674
2018-10-22 00:54:36.105494:	Training iteration: 74200, Loss: 0.004900874104350805
2018-10-22 00:56:22.628673:	Training iteration: 74400, Loss: 0.004755750764161348
2018-10-22 00:58:13.445720:	Training iteration: 74600, Loss: 0.0061731901951134205
2018-10-22 01:00:06.493917:	Training iteration: 74800, Loss: 0.005568691994994879
2018-10-22 01:01:57.464860:	Training iteration: 75000, Loss: 0.0044552721083164215
2018-10-22 01:03:49.043836:	Training iteration: 75200, Loss: 0.008381289429962635
2018-10-22 01:05:39.696876:	Training iteration: 75400, Loss: 0.0072968690656125546
2018-10-22 01:07:30.890112:	Training iteration: 75600, Loss: 0.005308844149112701
2018-10-22 01:09:21.540035:	Training iteration: 75800, Loss: 0.0073171635158360004
2018-10-22 01:11:11.011505:	Training iteration: 76000, Loss: 0.008531083352863789
2018-10-22 01:12:58.310878:	Training iteration: 76200, Loss: 0.005357093643397093
2018-10-22 01:14:47.690269:	Training iteration: 76400, Loss: 0.006265776231884956
2018-10-22 01:16:33.486351:	Training iteration: 76600, Loss: 0.004960687831044197
2018-10-22 01:18:21.616221:	Training iteration: 76800, Loss: 0.006640932057052851
2018-10-22 01:20:11.018634:	Training iteration: 77000, Loss: 0.005018012132495642
2018-10-22 01:22:02.616237:	Training iteration: 77200, Loss: 0.005124275106936693
2018-10-22 01:23:52.845806:	Training iteration: 77400, Loss: 0.005454763770103455
2018-10-22 01:25:42.252749:	Training iteration: 77600, Loss: 0.0072085014544427395
2018-10-22 01:27:31.819117:	Training iteration: 77800, Loss: 0.0035268592182546854
2018-10-22 01:29:21.933872:	Training iteration: 78000, Loss: 0.004741842392832041
2018-10-22 01:31:11.803937:	Training iteration: 78200, Loss: 0.005787333473563194
2018-10-22 01:33:01.907300:	Training iteration: 78400, Loss: 0.004705002065747976
2018-10-22 01:34:49.960490:	Training iteration: 78600, Loss: 0.003663487732410431
2018-10-22 01:36:37.882122:	Training iteration: 78800, Loss: 0.005464873742312193
2018-10-22 01:38:25.101016:	Training iteration: 79000, Loss: 0.006244182121008635
2018-10-22 01:40:11.554209:	Training iteration: 79200, Loss: 0.008034499362111092
2018-10-22 01:41:59.975251:	Training iteration: 79400, Loss: 0.011049437336623669
2018-10-22 01:43:49.626353:	Training iteration: 79600, Loss: 0.006899021565914154
2018-10-22 01:45:38.012794:	Training iteration: 79800, Loss: 0.007506217807531357
2018-10-22 01:47:09.548374:	Epoch 0 finished after 79969 iterations.
Validating
2018-10-22 01:47:13.299487:	Entering validation loop
2018-10-22 01:47:23.919931: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 597 of 1000
2018-10-22 01:47:30.008100: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-22 01:48:09.762692:	Validation iteration: 200, Loss: 0.006744939833879471
2018-10-22 01:48:53.783434:	Validation iteration: 400, Loss: 0.006857837084680796
2018-10-22 01:49:40.925241:	Validation iteration: 600, Loss: 0.004964159335941076
2018-10-22 01:50:26.217427:	Validation iteration: 800, Loss: 0.00623699463903904
2018-10-22 01:51:11.689760:	Validation iteration: 1000, Loss: 0.003957616165280342
2018-10-22 01:51:56.740695:	Validation iteration: 1200, Loss: 0.0068263523280620575
2018-10-22 01:52:50.167412: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 611 of 1000
2018-10-22 01:52:56.055189: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-22 01:52:57.687178:	Validation iteration: 1400, Loss: 0.00614334037527442
2018-10-22 01:53:38.197247:	Validation iteration: 1600, Loss: 0.005921881180256605
2018-10-22 01:54:22.680850:	Validation iteration: 1800, Loss: 0.006983477622270584
2018-10-22 01:55:07.492375:	Validation iteration: 2000, Loss: 0.0057160635478794575
2018-10-22 01:55:54.590205:	Validation iteration: 2200, Loss: 0.0065560657531023026
2018-10-22 01:56:39.595265:	Validation iteration: 2400, Loss: 0.006138049066066742
2018-10-22 01:57:23.298692:	Validation iteration: 2600, Loss: 0.004462870769202709
2018-10-22 01:58:15.007474: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 456 of 1000
2018-10-22 01:58:22.425667: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-22 01:58:25.523322:	Validation iteration: 2800, Loss: 0.0054214331321418285
2018-10-22 01:59:06.171369:	Validation iteration: 3000, Loss: 0.004878150764852762
2018-10-22 01:59:50.488332:	Validation iteration: 3200, Loss: 0.005133924074470997
2018-10-22 02:00:35.349649:	Validation iteration: 3400, Loss: 0.005993615835905075
2018-10-22 02:01:19.767274:	Validation iteration: 3600, Loss: 0.006654147524386644
2018-10-22 02:02:05.121289:	Validation iteration: 3800, Loss: 0.007160215172916651
2018-10-22 02:02:50.052880:	Validation iteration: 4000, Loss: 0.005284463986754417
2018-10-22 02:03:39.363570: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 672 of 1000
2018-10-22 02:03:43.783349: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-22 02:03:48.476098:	Validation iteration: 4200, Loss: 0.006545318756252527
2018-10-22 02:04:30.624627:	Validation iteration: 4400, Loss: 0.009286249987781048
2018-10-22 02:05:16.526972:	Validation iteration: 4600, Loss: 0.0065985447727143764
2018-10-22 02:06:00.914055:	Validation iteration: 4800, Loss: 0.006089319940656424
2018-10-22 02:06:45.041873:	Validation iteration: 5000, Loss: 0.006759652402251959
2018-10-22 02:07:29.744450:	Validation iteration: 5200, Loss: 0.006282883230596781
2018-10-22 02:08:14.313662:	Validation iteration: 5400, Loss: 0.007638797163963318
2018-10-22 02:09:02.273598: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 492 of 1000
2018-10-22 02:09:10.567899: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-22 02:09:16.719831:	Validation iteration: 5600, Loss: 0.004355830606073141
2018-10-22 02:09:56.898582:	Validation iteration: 5800, Loss: 0.004534932319074869
2018-10-22 02:10:40.449500:	Validation iteration: 6000, Loss: 0.007900687865912914
2018-10-22 02:11:23.992870:	Validation iteration: 6200, Loss: 0.0079395342618227
2018-10-22 02:12:07.305728:	Validation iteration: 6400, Loss: 0.0065101576037704945
2018-10-22 02:12:51.296825:	Validation iteration: 6600, Loss: 0.006383089814335108
2018-10-22 02:13:36.572165:	Validation iteration: 6800, Loss: 0.005180991720408201
2018-10-22 02:14:20.825836:	Validation iteration: 7000, Loss: 0.00549321947619319
2018-10-22 02:15:04.694761:	Validation iteration: 7200, Loss: 0.008476425893604755
2018-10-22 02:15:49.052903:	Validation iteration: 7400, Loss: 0.006481265649199486
Validation check mean loss: 0.005970435526692621
Validation loss has improved!
New best validation cost!
2018-10-22 02:16:21.407784: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 689 of 1000
2018-10-22 02:16:25.479268: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-22 02:16:39.745625:	Training iteration: 80000, Loss: 0.004513969179242849
Checkpoint
2018-10-22 02:18:33.759464:	Training iteration: 80200, Loss: 0.0033721725922077894
2018-10-22 02:20:20.846084:	Training iteration: 80400, Loss: 0.0046802847646176815
2018-10-22 02:22:09.005031:	Training iteration: 80600, Loss: 0.00429380452260375
2018-10-22 02:23:56.410231:	Training iteration: 80800, Loss: 0.0037243098486214876
2018-10-22 02:25:44.247832:	Training iteration: 81000, Loss: 0.0034300757106393576
2018-10-22 02:27:32.786949:	Training iteration: 81200, Loss: 0.004624588880687952
2018-10-22 02:29:24.020271:	Training iteration: 81400, Loss: 0.005282364785671234
2018-10-22 02:31:15.176748:	Training iteration: 81600, Loss: 0.006241717841476202
2018-10-22 02:33:05.836107:	Training iteration: 81800, Loss: 0.004056263715028763
2018-10-22 02:34:55.751232:	Training iteration: 82000, Loss: 0.005353828426450491
2018-10-22 02:36:44.199677:	Training iteration: 82200, Loss: 0.006928803864866495
2018-10-22 02:38:32.398335:	Training iteration: 82400, Loss: 0.004018602892756462
2018-10-22 02:40:21.429006:	Training iteration: 82600, Loss: 0.005182372871786356
2018-10-22 02:42:08.942714:	Training iteration: 82800, Loss: 0.004154888913035393
2018-10-22 02:43:56.326585:	Training iteration: 83000, Loss: 0.004561448935419321
2018-10-22 02:45:43.458044:	Training iteration: 83200, Loss: 0.0034662168473005295
2018-10-22 02:47:30.046955:	Training iteration: 83400, Loss: 0.004353388678282499
2018-10-22 02:49:19.288756:	Training iteration: 83600, Loss: 0.00579808047041297
2018-10-22 02:51:08.596062:	Training iteration: 83800, Loss: 0.003977720160037279
2018-10-22 02:52:58.645850:	Training iteration: 84000, Loss: 0.0030321229714900255
2018-10-22 02:54:48.200831:	Training iteration: 84200, Loss: 0.004620676394551992
2018-10-22 02:56:38.288233:	Training iteration: 84400, Loss: 0.004294427577406168
2018-10-22 02:58:27.173066:	Training iteration: 84600, Loss: 0.003742433153092861
2018-10-22 03:00:16.450961:	Training iteration: 84800, Loss: 0.004211239982396364
2018-10-22 03:02:07.641250:	Training iteration: 85000, Loss: 0.004115115385502577
2018-10-22 03:03:58.734187:	Training iteration: 85200, Loss: 0.005387384910136461
2018-10-22 03:05:50.304695:	Training iteration: 85400, Loss: 0.005924752447754145
2018-10-22 03:07:41.362909:	Training iteration: 85600, Loss: 0.005862133577466011
2018-10-22 03:09:32.568729:	Training iteration: 85800, Loss: 0.0034369148779660463
2018-10-22 03:11:22.835202:	Training iteration: 86000, Loss: 0.005681672599166632
2018-10-22 03:13:13.791767:	Training iteration: 86200, Loss: 0.003869185922667384
2018-10-22 03:15:01.108773:	Training iteration: 86400, Loss: 0.0047508967109024525
2018-10-22 03:16:49.001285:	Training iteration: 86600, Loss: 0.004217421170324087
2018-10-22 03:18:36.503675:	Training iteration: 86800, Loss: 0.0033454063814133406
2018-10-22 03:20:25.327544:	Training iteration: 87000, Loss: 0.0029771907720714808
2018-10-22 03:22:13.786132:	Training iteration: 87200, Loss: 0.005623176693916321
2018-10-22 03:24:03.496921:	Training iteration: 87400, Loss: 0.006185585167258978
2018-10-22 03:25:53.468788:	Training iteration: 87600, Loss: 0.005335379391908646
2018-10-22 03:27:41.943314:	Training iteration: 87800, Loss: 0.0033585724886506796
2018-10-22 03:29:30.857434:	Training iteration: 88000, Loss: 0.004075656179338694
2018-10-22 03:31:19.551428:	Training iteration: 88200, Loss: 0.003616020083427429
2018-10-22 03:31:46.720739: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 652 of 1000
2018-10-22 03:31:51.519242: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-22 03:33:16.824945:	Training iteration: 88400, Loss: 0.005502550397068262
2018-10-22 03:35:04.882163:	Training iteration: 88600, Loss: 0.004255661275237799
2018-10-22 03:36:56.029463:	Training iteration: 88800, Loss: 0.0036543256137520075
2018-10-22 03:38:46.312699:	Training iteration: 89000, Loss: 0.004760124254971743
2018-10-22 03:40:36.832683:	Training iteration: 89200, Loss: 0.005277858581393957
2018-10-22 03:42:28.361203:	Training iteration: 89400, Loss: 0.005699096713215113
2018-10-22 03:44:20.194888:	Training iteration: 89600, Loss: 0.004906842950731516
2018-10-22 03:46:08.212503:	Training iteration: 89800, Loss: 0.004471533466130495
2018-10-22 03:47:57.333337:	Training iteration: 90000, Loss: 0.003849926171824336
Checkpoint
2018-10-22 03:49:48.979894:	Training iteration: 90200, Loss: 0.003888505743816495
2018-10-22 03:51:39.316342:	Training iteration: 90400, Loss: 0.00403545331209898
2018-10-22 03:53:27.880031:	Training iteration: 90600, Loss: 0.00447881780564785
2018-10-22 03:55:14.036728:	Training iteration: 90800, Loss: 0.005128644406795502
2018-10-22 03:57:00.629553:	Training iteration: 91000, Loss: 0.004030976444482803
2018-10-22 03:58:47.001148:	Training iteration: 91200, Loss: 0.006510943174362183
2018-10-22 04:00:35.421086:	Training iteration: 91400, Loss: 0.007629450410604477
2018-10-22 04:02:23.802617:	Training iteration: 91600, Loss: 0.0064164274372160435
2018-10-22 04:04:11.378148:	Training iteration: 91800, Loss: 0.004908181726932526
2018-10-22 04:05:59.480917:	Training iteration: 92000, Loss: 0.0035498712677508593
2018-10-22 04:07:47.299674:	Training iteration: 92200, Loss: 0.004521768540143967
2018-10-22 04:09:35.264685:	Training iteration: 92400, Loss: 0.004944149404764175
2018-10-22 04:11:23.775788:	Training iteration: 92600, Loss: 0.0045512765645980835
2018-10-22 04:13:11.910275:	Training iteration: 92800, Loss: 0.004095533397048712
2018-10-22 04:14:59.049840:	Training iteration: 93000, Loss: 0.007226273883134127
2018-10-22 04:16:46.982673:	Training iteration: 93200, Loss: 0.007038322743028402
2018-10-22 04:18:33.153611:	Training iteration: 93400, Loss: 0.0057656108401715755
2018-10-22 04:20:21.034395:	Training iteration: 93600, Loss: 0.003914929926395416
2018-10-22 04:22:08.044229:	Training iteration: 93800, Loss: 0.008004301227629185
2018-10-22 04:23:54.309517:	Training iteration: 94000, Loss: 0.0047346726059913635
2018-10-22 04:25:41.266653:	Training iteration: 94200, Loss: 0.005000115837901831
2018-10-22 04:27:28.900122:	Training iteration: 94400, Loss: 0.004547791555523872
2018-10-22 04:29:17.743914:	Training iteration: 94600, Loss: 0.004911277908831835
2018-10-22 04:31:07.918868:	Training iteration: 94800, Loss: 0.004984027240425348
2018-10-22 04:32:58.241099:	Training iteration: 95000, Loss: 0.005180466920137405
2018-10-22 04:34:47.190115:	Training iteration: 95200, Loss: 0.005267970263957977
2018-10-22 04:36:36.482670:	Training iteration: 95400, Loss: 0.005576420575380325
2018-10-22 04:38:25.061815:	Training iteration: 95600, Loss: 0.004910005256533623
2018-10-22 04:40:11.749924:	Training iteration: 95800, Loss: 0.004368361551314592
2018-10-22 04:42:01.082015:	Training iteration: 96000, Loss: 0.004147535655647516
2018-10-22 04:43:49.277594:	Training iteration: 96200, Loss: 0.00413426011800766
2018-10-22 04:45:37.862545:	Training iteration: 96400, Loss: 0.004802224691957235
2018-10-22 04:47:04.804731: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 680 of 1000
2018-10-22 04:47:08.926942: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-22 04:47:35.326910:	Training iteration: 96600, Loss: 0.006995069328695536
2018-10-22 04:49:20.044367:	Training iteration: 96800, Loss: 0.0056195869110524654
2018-10-22 04:51:07.640635:	Training iteration: 97000, Loss: 0.0056176818907260895
2018-10-22 04:52:55.440357:	Training iteration: 97200, Loss: 0.0042433603666722775
2018-10-22 04:54:43.884827:	Training iteration: 97400, Loss: 0.0053368923254311085
2018-10-22 04:56:30.273985:	Training iteration: 97600, Loss: 0.005202579777687788
2018-10-22 04:58:15.278425:	Training iteration: 97800, Loss: 0.004559702705591917
2018-10-22 05:00:02.187071:	Training iteration: 98000, Loss: 0.004518516361713409
2018-10-22 05:01:49.268010:	Training iteration: 98200, Loss: 0.005338850896805525
2018-10-22 05:03:36.485493:	Training iteration: 98400, Loss: 0.0030584298074245453
2018-10-22 05:05:23.061430:	Training iteration: 98600, Loss: 0.004868345335125923
2018-10-22 05:07:09.942342:	Training iteration: 98800, Loss: 0.006842608097940683
2018-10-22 05:08:56.794789:	Training iteration: 99000, Loss: 0.004499603062868118
2018-10-22 05:10:45.224351:	Training iteration: 99200, Loss: 0.005513206589967012
2018-10-22 05:12:30.011580:	Training iteration: 99400, Loss: 0.004855745937675238
2018-10-22 05:14:16.752935:	Training iteration: 99600, Loss: 0.006751274690032005
2018-10-22 05:16:02.609448:	Training iteration: 99800, Loss: 0.005532457958906889
2018-10-22 05:17:49.097942:	Training iteration: 100000, Loss: 0.004392996896058321
Checkpoint
2018-10-22 05:19:37.310654:	Training iteration: 100200, Loss: 0.004305216949433088
2018-10-22 05:21:23.329228:	Training iteration: 100400, Loss: 0.005346307065337896
2018-10-22 05:23:10.070817:	Training iteration: 100600, Loss: 0.0037687362637370825
2018-10-22 05:24:58.404757:	Training iteration: 100800, Loss: 0.0042801303789019585
2018-10-22 05:26:44.736983:	Training iteration: 101000, Loss: 0.0036649403627961874
2018-10-22 05:28:31.968634:	Training iteration: 101200, Loss: 0.0037330768536776304
2018-10-22 05:30:18.840428:	Training iteration: 101400, Loss: 0.006149856373667717
2018-10-22 05:32:06.282770:	Training iteration: 101600, Loss: 0.004757680464535952
2018-10-22 05:33:53.370816:	Training iteration: 101800, Loss: 0.006766524165868759
2018-10-22 05:35:40.309326:	Training iteration: 102000, Loss: 0.004174368921667337
2018-10-22 05:37:27.965492:	Training iteration: 102200, Loss: 0.005580151919275522
2018-10-22 05:39:15.594329:	Training iteration: 102400, Loss: 0.005615388974547386
2018-10-22 05:41:02.518200:	Training iteration: 102600, Loss: 0.0071727982722222805
2018-10-22 05:42:49.470147:	Training iteration: 102800, Loss: 0.004713414702564478
2018-10-22 05:44:35.374065:	Training iteration: 103000, Loss: 0.005937869194895029
2018-10-22 05:46:21.859368:	Training iteration: 103200, Loss: 0.004458706360310316
2018-10-22 05:48:10.105254:	Training iteration: 103400, Loss: 0.003939331043511629
2018-10-22 05:49:56.162265:	Training iteration: 103600, Loss: 0.004405206069350243
2018-10-22 05:51:43.095230:	Training iteration: 103800, Loss: 0.004450791049748659
2018-10-22 05:53:28.069646:	Training iteration: 104000, Loss: 0.0049581523053348064
2018-10-22 05:55:15.014543:	Training iteration: 104200, Loss: 0.008623114787042141
2018-10-22 05:57:02.504669:	Training iteration: 104400, Loss: 0.005669110920280218
2018-10-22 05:58:51.370650:	Training iteration: 104600, Loss: 0.00495051359757781
2018-10-22 06:00:40.183196:	Training iteration: 104800, Loss: 0.004266046918928623
2018-10-22 06:01:18.335500: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 659 of 1000
2018-10-22 06:01:22.654435: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-22 06:02:36.591557:	Training iteration: 105000, Loss: 0.004728769883513451
2018-10-22 06:04:22.078094:	Training iteration: 105200, Loss: 0.003960566129535437
2018-10-22 06:06:08.680611:	Training iteration: 105400, Loss: 0.003891815198585391
2018-10-22 06:07:57.505044:	Training iteration: 105600, Loss: 0.0024866655003279448
2018-10-22 06:09:46.203740:	Training iteration: 105800, Loss: 0.0038869641721248627
2018-10-22 06:11:35.192862:	Training iteration: 106000, Loss: 0.0035817541647702456
2018-10-22 06:13:24.782247:	Training iteration: 106200, Loss: 0.004953681956976652
2018-10-22 06:15:10.978405:	Training iteration: 106400, Loss: 0.004675381351262331
2018-10-22 06:16:58.427879:	Training iteration: 106600, Loss: 0.0033278700429946184
2018-10-22 06:18:45.555943:	Training iteration: 106800, Loss: 0.003496613586321473
2018-10-22 06:20:31.503856:	Training iteration: 107000, Loss: 0.0038886733818799257
2018-10-22 06:22:16.776402:	Training iteration: 107200, Loss: 0.006040047388523817
2018-10-22 06:24:02.811740:	Training iteration: 107400, Loss: 0.0030365868005901575
2018-10-22 06:25:49.708232:	Training iteration: 107600, Loss: 0.004690275061875582
2018-10-22 06:27:34.712359:	Training iteration: 107800, Loss: 0.003464776324108243
2018-10-22 06:29:19.386066:	Training iteration: 108000, Loss: 0.0038504283875226974
2018-10-22 06:31:03.697941:	Training iteration: 108200, Loss: 0.004785103723406792
2018-10-22 06:32:48.898180:	Training iteration: 108400, Loss: 0.004935434553772211
2018-10-22 06:34:33.615268:	Training iteration: 108600, Loss: 0.003959326539188623
2018-10-22 06:36:19.094741:	Training iteration: 108800, Loss: 0.006327961105853319
2018-10-22 06:38:04.478956:	Training iteration: 109000, Loss: 0.0054171145893633366
2018-10-22 06:39:49.785569:	Training iteration: 109200, Loss: 0.0033446263987571
2018-10-22 06:41:34.763011:	Training iteration: 109400, Loss: 0.005261907819658518
2018-10-22 06:43:19.391760:	Training iteration: 109600, Loss: 0.0048383441753685474
2018-10-22 06:45:03.847028:	Training iteration: 109800, Loss: 0.0034317236859351397
2018-10-22 06:46:48.040355:	Training iteration: 110000, Loss: 0.0038076138589531183
Checkpoint
2018-10-22 06:48:32.982805:	Training iteration: 110200, Loss: 0.005393424537032843
2018-10-22 06:50:17.849151:	Training iteration: 110400, Loss: 0.003392326645553112
2018-10-22 06:52:03.701790:	Training iteration: 110600, Loss: 0.00459284009411931
2018-10-22 06:53:49.088613:	Training iteration: 110800, Loss: 0.002900158753618598
2018-10-22 06:55:33.920595:	Training iteration: 111000, Loss: 0.005844354163855314
2018-10-22 06:57:18.651650:	Training iteration: 111200, Loss: 0.003356743371114135
2018-10-22 06:59:04.247483:	Training iteration: 111400, Loss: 0.004678503144532442
2018-10-22 07:00:51.038223:	Training iteration: 111600, Loss: 0.004345212131738663
2018-10-22 07:02:37.969304:	Training iteration: 111800, Loss: 0.004115859512239695
2018-10-22 07:04:23.814878:	Training iteration: 112000, Loss: 0.004918075632303953
2018-10-22 07:06:09.227592:	Training iteration: 112200, Loss: 0.004537621047347784
2018-10-22 07:07:54.554335:	Training iteration: 112400, Loss: 0.006059771403670311
2018-10-22 07:09:41.258814:	Training iteration: 112600, Loss: 0.0033611140679568052
2018-10-22 07:11:24.640068:	Training iteration: 112800, Loss: 0.0038506004493683577
2018-10-22 07:13:09.922387:	Training iteration: 113000, Loss: 0.003550683381035924
2018-10-22 07:14:53.996140:	Training iteration: 113200, Loss: 0.0048821368254721165
2018-10-22 07:16:37.033294:	Training iteration: 113400, Loss: 0.004032615572214127
2018-10-22 07:17:54.832818: I tensorflow/core/kernels/shuffle_dataset_op.cc:110] Filling up shuffle buffer (this may take a while): 664 of 1000
2018-10-22 07:17:59.040776: I tensorflow/core/kernels/shuffle_dataset_op.cc:121] Shuffle buffer filled.
2018-10-22 07:18:31.717076:	Training iteration: 113600, Loss: 0.006049970630556345
2018-10-22 07:20:14.526329:	Training iteration: 113800, Loss: 0.003951527178287506
2018-10-22 07:21:57.681963:	Training iteration: 114000, Loss: 0.004927827510982752
2018-10-22 07:23:42.405108:	Training iteration: 114200, Loss: 0.0056079961359500885
2018-10-22 07:25:23.233499:	Training iteration: 114400, Loss: 0.005927730817347765
2018-10-22 07:27:05.949353:	Training iteration: 114600, Loss: 0.0031341174617409706
2018-10-22 07:28:49.590132:	Training iteration: 114800, Loss: 0.003887988394126296
2018-10-22 07:30:33.569678:	Training iteration: 115000, Loss: 0.005063104908913374
2018-10-22 07:32:20.421135:	Training iteration: 115200, Loss: 0.00401883153244853
2018-10-22 07:34:05.812124:	Training iteration: 115400, Loss: 0.005655964370816946
2018-10-22 07:35:51.981918:	Training iteration: 115600, Loss: 0.008883458562195301
2018-10-22 07:37:37.740489:	Training iteration: 115800, Loss: 0.008090081624686718
2018-10-22 07:39:22.703326:	Training iteration: 116000, Loss: 0.007497405167669058
2018-10-22 07:41:07.447868:	Training iteration: 116200, Loss: 0.004937028978019953
2018-10-22 07:42:52.659372:	Training iteration: 116400, Loss: 0.005406104493886232
2018-10-22 07:44:36.678629:	Training iteration: 116600, Loss: 0.005402179900556803
2018-10-22 07:46:21.723529:	Training iteration: 116800, Loss: 0.004320499487221241
2018-10-22 07:48:06.186710:	Training iteration: 117000, Loss: 0.005083128344267607
2018-10-22 07:49:50.052087:	Training iteration: 117200, Loss: 0.008899698965251446
2018-10-22 07:51:34.115267:	Training iteration: 117400, Loss: 0.00578699866309762
2018-10-22 07:53:17.940411:	Training iteration: 117600, Loss: 0.004489387851208448
2018-10-22 07:55:01.299308:	Training iteration: 117800, Loss: 0.005913118366152048
2018-10-22 07:56:42.847415:	Training iteration: 118000, Loss: 0.00586478179320693
2018-10-22 07:58:26.117020:	Training iteration: 118200, Loss: 0.005648352205753326
2018-10-22 08:00:09.037429:	Training iteration: 118400, Loss: 0.005824262276291847
2018-10-22 08:01:51.346127:	Training iteration: 118600, Loss: 0.004400497768074274
2018-10-22 08:03:33.049962:	Training iteration: 118800, Loss: 0.0047450014390051365
2018-10-22 08:05:17.568321:	Training iteration: 119000, Loss: 0.004945374559611082
2018-10-22 08:07:00.963525:	Training iteration: 119200, Loss: 0.0035586438607424498
2018-10-22 08:08:46.301070:	Training iteration: 119400, Loss: 0.00418520625680685
2018-10-22 08:10:30.589944:	Training iteration: 119600, Loss: 0.004280091729015112
2018-10-22 08:12:14.883984:	Training iteration: 119800, Loss: 0.0050271302461624146
2018-10-22 08:13:58.901885:	Training iteration: 120000, Loss: 0.00617217319086194
Checkpoint
2018-10-22 08:15:45.035455:	Training iteration: 120200, Loss: 0.004805454518646002
2018-10-22 08:17:29.081336:	Training iteration: 120400, Loss: 0.003651060163974762
2018-10-22 08:19:12.964762:	Training iteration: 120600, Loss: 0.004905844572931528
2018-10-22 08:20:55.443064:	Training iteration: 120800, Loss: 0.006375855300575495
2018-10-22 08:22:40.026772:	Training iteration: 121000, Loss: 0.004266895819455385
2018-10-22 08:24:23.938816:	Training iteration: 121200, Loss: 0.004772070795297623
2018-10-22 08:26:07.670651:	Training iteration: 121400, Loss: 0.004916600417345762
2018-10-22 08:27:50.304119:	Training iteration: 121600, Loss: 0.006192445755004883
2018-10-22 08:29:32.392145:	Training iteration: 121800, Loss: 0.006274659186601639
2018-10-22 08:31:16.431321:	Training iteration: 122000, Loss: 0.004559928551316261
2018-10-22 08:33:01.042183:	Training iteration: 122200, Loss: 0.00903030950576067
2018-10-22 08:34:45.591228:	Training iteration: 122400, Loss: 0.005325356964021921
2018-10-22 08:36:31.282309:	Training iteration: 122600, Loss: 0.005823708605021238
