{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is adapted from https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/13B_Visual_Analysis_MNIST.ipynb. It allows you to find the input 'image' which would produce the maximum activation for a given filter (or random selection of filters, or all filters) in a given layer of a loaded, pre-trained, U-Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "import numpy as np\n",
    "import datetime\n",
    "#import capsnet\n",
    "from SegCaps import capsule_layers\n",
    "import dataset\n",
    "import model_functions as mf\n",
    "import audio_functions as af\n",
    "import audio_models\n",
    "\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['image.cmap'] = 'hot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((?, 256, 513, 4), (?, 256, 513, 4), (?, 256, 513, 4), (?, 65280, 1), (?, 65280, 1), (?, 65280, 1)), types: (tf.float32, tf.float32, tf.float32, tf.float32, tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Set variables\n",
    "sample_rate=16384\n",
    "n_fft=1024\n",
    "fft_hop=256\n",
    "patch_window=256\n",
    "patch_hop=128\n",
    "n_parallel_readers=16\n",
    "normalise=True\n",
    "batch_size = 1\n",
    "shuffle=False\n",
    "n_shuffle = 1\n",
    "mag_phase = True\n",
    "learning_rate = 0.0002\n",
    "model_variant = 'unet'\n",
    "data_type = 'mag'\n",
    "phase_weight = 0.0005\n",
    "\n",
    "checkpoint = '234/234-8'\n",
    "#model_base_dir = '/home/enterprise.internal.city.ac.uk/acvn728/checkpoints'\n",
    "model_base_dir = 'C:/Users/Toby/MSc_Project/MScFinalProjectCheckpoints'\n",
    "\n",
    "#directory_a = '/home/enterprise.internal.city.ac.uk/acvn728/miniCHiME/Mixed'\n",
    "#directory_b = '/home/enterprise.internal.city.ac.uk/acvn728/miniCHiME/Voice'\n",
    "#directory_c = '/home/enterprise.internal.city.ac.uk/acvn728/miniCHiME/Background'\n",
    "\n",
    "directory_a = 'C:/Users/Toby/MSc_Project/Test_Audio/miniCHiME/Mixed'\n",
    "directory_b = 'C:/Users/Toby/MSc_Project/Test_Audio/miniCHiME/Voice'\n",
    "directory_c = 'C:/Users/Toby/MSc_Project/Test_Audio/miniCHiME/Background'\n",
    "\n",
    "\n",
    "#  Create the pipeline\n",
    "tf.reset_default_graph()\n",
    "data = dataset.zip_files(directory_a, directory_b, directory_c)\n",
    "data = dataset.get_paired_dataset(data,\n",
    "                                  sample_rate,\n",
    "                                  n_fft,\n",
    "                                  fft_hop,\n",
    "                                  patch_window,\n",
    "                                  patch_hop,\n",
    "                                  n_parallel_readers,\n",
    "                                  batch_size,\n",
    "                                  n_shuffle,\n",
    "                                  normalise)\n",
    "\n",
    "#  Create the iterator\n",
    "pipe = data.make_initializable_iterator()\n",
    "mixed_spec, voice_spec, background_spec, mixed_audio, voice_audio, background_audio = pipe.get_next()\n",
    "\n",
    "#  Create variable placeholders\n",
    "is_training = tf.placeholder(shape=(), dtype=bool)\n",
    "mixed_phase = tf.expand_dims(mixed_spec[:, :, :-1, 3], 3)\n",
    "if data_type == 'mag':\n",
    "    mixed_input = tf.expand_dims(mixed_spec[:, :, :-1, 2], 3)\n",
    "    voice_input = tf.expand_dims(voice_spec[:, :, :-1, 2], 3)\n",
    "elif data_type in ['mag_phase', 'mag_phase_diff']:\n",
    "    mixed_input = mixed_spec[:, :, :-1, 2:4]\n",
    "    voice_input = voice_spec[:, :, :-1, 2:4]\n",
    "elif data_type == 'real_imag':\n",
    "    mixed_input = mixed_spec[:, :, :-1, 0:2]\n",
    "    voice_input = voice_spec[:, :, :-1, 0:2]\n",
    "elif data_type == 'mag_real_imag':\n",
    "    mixed_input = tf.concat([tf.expand_dims(mixed_spec[:, :, :-1, 2], 3), mixed_spec[:, :, :-1, 0:2]], 3)\n",
    "    voice_input = tf.concat([tf.expand_dims(voice_spec[:, :, :-1, 2], 3), voice_spec[:, :, :-1, 0:2]], 3)\n",
    "elif data_type == 'mag_phase_real_imag':\n",
    "    mixed_input = mixed_spec[:, :, :-1, :]\n",
    "    voice_input = voice_spec[:, :, :-1, :]\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model\n"
     ]
    }
   ],
   "source": [
    "# Build U-Net model\n",
    "print('Creating model')\n",
    "model = audio_models.MagnitudeModel(mixed_input, voice_input, mixed_phase, mixed_audio, \n",
    "                                    voice_audio, background_audio, model_variant, is_training, learning_rate, \n",
    "                                    data_type, phase_weight, name='Magnitude_Model')\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "tf_config.gpu_options.visible_device_list = str(1)\n",
    "sess = tf.Session(config=tf_config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/Toby/MSc_Project/MScFinalProjectCheckpoints\\234/234-8\n"
     ]
    }
   ],
   "source": [
    "# Load a saved checkpoint\n",
    "print('Loading checkpoint')\n",
    "checkpoint_path = os.path.join(model_base_dir, checkpoint)\n",
    "restorer = tf.train.Saver()\n",
    "restorer.restore(sess, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, smooth=True):\n",
    "    # Interpolation type.\n",
    "    if smooth:\n",
    "        interpolation = 'spline16'\n",
    "    else:\n",
    "        interpolation = 'nearest'\n",
    "    \n",
    "    num_cols = 4\n",
    "    num_rows = int(len(images) / num_cols)\n",
    "    \n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(16,int(num_rows * 2)))\n",
    "\n",
    "    # Adjust vertical spacing.\n",
    "    fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "    # For each entry in the grid.\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Get the i'th image and only use the desired pixels.\n",
    "        img = images[i, :, :]\n",
    "        \n",
    "        # Plot the image.\n",
    "        ax.imshow(img, interpolation=interpolation)\n",
    "\n",
    "        # Remove ticks.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for getting the names of all the convolutional layers in the neural network. We could have made this list manually, but for larger neural networks it is easier to do this with a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_conv_layer_names():\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    # Create a list of names for the operations in the graph\n",
    "    # for the Inception model where the operator-type is 'Conv2D'.\n",
    "    names = [op.name for op in graph.get_operations() if op.type=='Conv2D']\n",
    "\n",
    "    return names\n",
    "\n",
    "conv_names = get_conv_layer_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This function finds the input image that maximizes a given feature in the network. It essentially just performs optimization with gradient ascent. The image is initialized with small random values and is then iteratively updated using the gradient for the given feature with regard to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_image(conv_id=0, feature=0,\n",
    "                   num_iterations=30, show_progress=True):\n",
    "    \"\"\"\n",
    "    Find an image that maximizes the feature\n",
    "    given by the conv_id and feature number.\n",
    "\n",
    "    Parameters:\n",
    "    conv_id: Integer identifying the convolutional layer to\n",
    "             maximize. It is an index into conv_names.\n",
    "             If None then use the last fully-connected layer\n",
    "             before the softmax output.\n",
    "    feature: Index into the layer for the feature to maximize.\n",
    "    num_iteration: Number of optimization iterations to perform.\n",
    "    show_progress: Boolean whether to show the progress.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the loss-function that must be maximized.\n",
    "\n",
    "    # Get the name of the convolutional operator.\n",
    "    conv_name = conv_names[conv_id]\n",
    "\n",
    "    # Get the default TensorFlow graph.\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    # Get a reference to the tensor that is output by the\n",
    "    # operator. Note that \":0\" is added to the name for this.\n",
    "    tensor = graph.get_tensor_by_name(conv_name + \":0\")\n",
    "\n",
    "    # The loss-function is the average of all the\n",
    "    # tensor-values for the given feature. This\n",
    "    # ensures that we generate the whole input image.\n",
    "    # You can try and modify this so it only uses\n",
    "    # a part of the tensor.\n",
    "    loss = tf.reduce_mean(tensor[:,:,:,feature])\n",
    "\n",
    "    # Get the gradient for the loss-function with regard to\n",
    "    # the input image. This creates a mathematical\n",
    "    # function for calculating the gradient.\n",
    "    gradient = tf.gradients(loss, mixed_input)\n",
    "\n",
    "    # Generate a random image of the same size as the raw input.\n",
    "    # Each pixel is a small random value between 0.45 and 0.55,\n",
    "    # which is the middle of the valid range between 0 and 1.\n",
    "    img_shape = tuple(mixed_input.shape.as_list()[1:3])\n",
    "    image = 0.1 * np.random.uniform(size=img_shape) + 0.45\n",
    "\n",
    "    # Perform a number of optimization iterations to find\n",
    "    # the image that maximizes the loss-function.\n",
    "    for i in range(num_iterations):\n",
    "        # Reshape the array so it is a 4-rank tensor.\n",
    "        img_reshaped = image[np.newaxis,:,:,np.newaxis]\n",
    "\n",
    "        # Create a feed-dict for inputting the image to the graph.\n",
    "        feed_dict = {model.mixed_input: img_reshaped,\n",
    "                     model.is_training: False}\n",
    "\n",
    "        # Calculate the predicted class-scores,\n",
    "        # as well as the gradient and the loss-value.\n",
    "        grad, loss_value = sess.run([gradient, loss],\n",
    "                                     feed_dict=feed_dict)\n",
    "        \n",
    "        # Squeeze the dimensionality for the gradient-array.\n",
    "        grad = np.array(grad).squeeze()\n",
    "\n",
    "        # The gradient now tells us how much we need to change the\n",
    "        # input image in order to maximize the given feature.\n",
    "\n",
    "        # Calculate the step-size for updating the image.\n",
    "        # This step-size was found to give fast convergence.\n",
    "        # The addition of 1e-8 is to protect from div-by-zero.\n",
    "        step_size = 1.0 / (grad.std() + 1e-8)\n",
    "\n",
    "        # Update the image by adding the scaled gradient\n",
    "        # This is called gradient ascent.\n",
    "        image += step_size * grad\n",
    "\n",
    "        # Ensure all pixel-values in the image are between 0 and 1.\n",
    "        image = np.clip(image, 0.0, 1.0)\n",
    "\n",
    "        if show_progress:\n",
    "            print(\"Iteration:\", i)\n",
    "\n",
    "            # Convert the predicted class-scores to a one-dim array.\n",
    "            #pred = np.squeeze(pred)\n",
    "\n",
    "            # The predicted class for the Inception model.\n",
    "            #pred_cls = np.argmax(pred)\n",
    "\n",
    "            # The score (probability) for the predicted class.\n",
    "            #cls_score = pred[pred_cls]\n",
    "\n",
    "            # Print the predicted score etc.\n",
    "            #msg = \"Predicted class: {0}, score: {1:>7.2%}\"\n",
    "            #print(msg.format(pred_cls, cls_score))\n",
    "\n",
    "            # Print statistics for the gradient.\n",
    "            msg = \"Gradient min: {0:>9.6f}, max: {1:>9.6f}, stepsize: {2:>9.2f}\"\n",
    "            print(msg.format(grad.min(), grad.max(), step_size))\n",
    "\n",
    "            # Print the loss-value.\n",
    "            print(\"Loss:\", loss_value)\n",
    "\n",
    "            # Newline.\n",
    "            print()\n",
    "\n",
    "    return image.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_images(conv_id=0, num_iterations=30, num_filters=None):\n",
    "    \"\"\"\n",
    "    Find 10 images that maximize the 10 first features in the layer\n",
    "    given by the conv_id.\n",
    "    \n",
    "    Parameters:\n",
    "    conv_id: Integer identifying the convolutional layer to\n",
    "             maximize. It is an index into conv_names.\n",
    "             If None then use the last layer before the softmax output.\n",
    "    num_iterations: Number of optimization iterations to perform.\n",
    "    \"\"\"\n",
    "\n",
    "    # Which layer are we using?\n",
    "    if conv_id is None:\n",
    "        print(\"Final fully-connected layer before softmax.\")\n",
    "    else:\n",
    "        print(\"Layer:\", conv_names[conv_id])\n",
    "\n",
    "    # Initialize the array of images.\n",
    "    images = []\n",
    "    \n",
    "    # Get number of filters in layer\n",
    "    conv_name = conv_names[conv_id]\n",
    "    graph = tf.get_default_graph()\n",
    "    tensor = graph.get_tensor_by_name(conv_name + \":0\")\n",
    "    num_filters_in_layer = tensor.shape[-1]\n",
    "    \n",
    "    # If number of filters not specified, assume all are required\n",
    "    if num_filters is None:\n",
    "        num_filters = num_filters_in_layer\n",
    "        filters = np.arange(num_filters)\n",
    "    else:\n",
    "        # Randomly select which filters to use\n",
    "        filters = np.random.randint(0, num_filters_in_layer, num_filters)\n",
    "        \n",
    "    # For each feature do the following.\n",
    "    for conv_filter in filters:\n",
    "        print(\"Optimizing image for filter no.\", conv_filter)\n",
    "        \n",
    "        # Find the image that maximizes the given feature\n",
    "        # for the network layer identified by conv_id (or None).\n",
    "        image = optimize_image(conv_id=conv_id, feature=conv_filter,\n",
    "                               show_progress=False,\n",
    "                               num_iterations=num_iterations)\n",
    "\n",
    "        # Squeeze the dim of the array.\n",
    "        image = image.squeeze()\n",
    "\n",
    "        # Append to the list of images.\n",
    "        images.append(image)\n",
    "\n",
    "    # Convert to numpy-array so we can index all dimensions easily.\n",
    "    images = np.array(images)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Magnitude_Model/voice-mask-unet/encoder/layer-6/conv2d/Conv2D\n",
      "Optimizing image for feature no. 0\n",
      "Optimizing image for feature no. 1\n",
      "Optimizing image for feature no. 2\n",
      "Optimizing image for feature no. 3\n",
      "Optimizing image for feature no. 4\n",
      "Optimizing image for feature no. 5\n",
      "Optimizing image for feature no. 6\n",
      "Optimizing image for feature no. 7\n",
      "Optimizing image for feature no. 8\n",
      "Optimizing image for feature no. 9\n",
      "Optimizing image for feature no. 10\n",
      "Optimizing image for feature no. 11\n",
      "Optimizing image for feature no. 12\n",
      "Optimizing image for feature no. 13\n",
      "Optimizing image for feature no. 14\n",
      "Optimizing image for feature no. 15\n",
      "Optimizing image for feature no. 16\n",
      "Optimizing image for feature no. 17\n",
      "Optimizing image for feature no. 18\n",
      "Optimizing image for feature no. 19\n",
      "Optimizing image for feature no. 20\n",
      "Optimizing image for feature no. 21\n",
      "Optimizing image for feature no. 22\n",
      "Optimizing image for feature no. 23\n",
      "Optimizing image for feature no. 24\n",
      "Optimizing image for feature no. 25\n",
      "Optimizing image for feature no. 26\n",
      "Optimizing image for feature no. 27\n",
      "Optimizing image for feature no. 28\n",
      "Optimizing image for feature no. 29\n",
      "Optimizing image for feature no. 30\n",
      "Optimizing image for feature no. 31\n",
      "Optimizing image for feature no. 32\n",
      "Optimizing image for feature no. 33\n",
      "Optimizing image for feature no. 34\n",
      "Optimizing image for feature no. 35\n",
      "Optimizing image for feature no. 36\n",
      "Optimizing image for feature no. 37\n",
      "Optimizing image for feature no. 38\n",
      "Optimizing image for feature no. 39\n",
      "Optimizing image for feature no. 40\n",
      "Optimizing image for feature no. 41\n",
      "Optimizing image for feature no. 42\n",
      "Optimizing image for feature no. 43\n",
      "Optimizing image for feature no. 44\n",
      "Optimizing image for feature no. 45\n",
      "Optimizing image for feature no. 46\n",
      "Optimizing image for feature no. 47\n",
      "Optimizing image for feature no. 48\n",
      "Optimizing image for feature no. 49\n",
      "Optimizing image for feature no. 50\n",
      "Optimizing image for feature no. 51\n",
      "Optimizing image for feature no. 52\n",
      "Optimizing image for feature no. 53\n",
      "Optimizing image for feature no. 54\n",
      "Optimizing image for feature no. 55\n",
      "Optimizing image for feature no. 56\n",
      "Optimizing image for feature no. 57\n",
      "Optimizing image for feature no. 58\n",
      "Optimizing image for feature no. 59\n",
      "Optimizing image for feature no. 60\n",
      "Optimizing image for feature no. 61\n",
      "Optimizing image for feature no. 62\n",
      "Optimizing image for feature no. 63\n",
      "Optimizing image for feature no. 64\n",
      "Optimizing image for feature no. 65\n",
      "Optimizing image for feature no. 66\n",
      "Optimizing image for feature no. 67\n",
      "Optimizing image for feature no. 68\n",
      "Optimizing image for feature no. 69\n",
      "Optimizing image for feature no. 70\n",
      "Optimizing image for feature no. 71\n",
      "Optimizing image for feature no. 72\n",
      "Optimizing image for feature no. 73\n",
      "Optimizing image for feature no. 74\n",
      "Optimizing image for feature no. 75\n",
      "Optimizing image for feature no. 76\n",
      "Optimizing image for feature no. 77\n",
      "Optimizing image for feature no. 78\n",
      "Optimizing image for feature no. 79\n",
      "Optimizing image for feature no. 80\n",
      "Optimizing image for feature no. 81\n",
      "Optimizing image for feature no. 82\n",
      "Optimizing image for feature no. 83\n",
      "Optimizing image for feature no. 84\n",
      "Optimizing image for feature no. 85\n",
      "Optimizing image for feature no. 86\n",
      "Optimizing image for feature no. 87\n",
      "Optimizing image for feature no. 88\n",
      "Optimizing image for feature no. 89\n",
      "Optimizing image for feature no. 90\n",
      "Optimizing image for feature no. 91\n",
      "Optimizing image for feature no. 92\n",
      "Optimizing image for feature no. 93\n",
      "Optimizing image for feature no. 94\n",
      "Optimizing image for feature no. 95\n",
      "Optimizing image for feature no. 96\n",
      "Optimizing image for feature no. 97\n",
      "Optimizing image for feature no. 98\n",
      "Optimizing image for feature no. 99\n",
      "Optimizing image for feature no. 100\n",
      "Optimizing image for feature no. 101\n",
      "Optimizing image for feature no. 102\n",
      "Optimizing image for feature no. 103\n",
      "Optimizing image for feature no. 104\n",
      "Optimizing image for feature no. 105\n",
      "Optimizing image for feature no. 106\n",
      "Optimizing image for feature no. 107\n",
      "Optimizing image for feature no. 108\n",
      "Optimizing image for feature no. 109\n",
      "Optimizing image for feature no. 110\n",
      "Optimizing image for feature no. 111\n",
      "Optimizing image for feature no. 112\n",
      "Optimizing image for feature no. 113\n",
      "Optimizing image for feature no. 114\n",
      "Optimizing image for feature no. 115\n",
      "Optimizing image for feature no. 116\n",
      "Optimizing image for feature no. 117\n",
      "Optimizing image for feature no. 118\n",
      "Optimizing image for feature no. 119\n",
      "Optimizing image for feature no. 120\n",
      "Optimizing image for feature no. 121\n",
      "Optimizing image for feature no. 122\n",
      "Optimizing image for feature no. 123\n",
      "Optimizing image for feature no. 124\n",
      "Optimizing image for feature no. 125\n",
      "Optimizing image for feature no. 126\n",
      "Optimizing image for feature no. 127\n",
      "Optimizing image for feature no. 128\n",
      "Optimizing image for feature no. 129\n",
      "Optimizing image for feature no. 130\n",
      "Optimizing image for feature no. 131\n",
      "Optimizing image for feature no. 132\n",
      "Optimizing image for feature no. 133\n",
      "Optimizing image for feature no. 134\n",
      "Optimizing image for feature no. 135\n",
      "Optimizing image for feature no. 136\n",
      "Optimizing image for feature no. 137\n",
      "Optimizing image for feature no. 138\n",
      "Optimizing image for feature no. 139\n",
      "Optimizing image for feature no. 140\n",
      "Optimizing image for feature no. 141\n",
      "Optimizing image for feature no. 142\n",
      "Optimizing image for feature no. 143\n",
      "Optimizing image for feature no. 144\n",
      "Optimizing image for feature no. 145\n",
      "Optimizing image for feature no. 146\n",
      "Optimizing image for feature no. 147\n",
      "Optimizing image for feature no. 148\n",
      "Optimizing image for feature no. 149\n",
      "Optimizing image for feature no. 150\n",
      "Optimizing image for feature no. 151\n",
      "Optimizing image for feature no. 152\n",
      "Optimizing image for feature no. 153\n",
      "Optimizing image for feature no. 154\n",
      "Optimizing image for feature no. 155\n",
      "Optimizing image for feature no. 156\n",
      "Optimizing image for feature no. 157\n",
      "Optimizing image for feature no. 158\n",
      "Optimizing image for feature no. 159\n",
      "Optimizing image for feature no. 160\n",
      "Optimizing image for feature no. 161\n",
      "Optimizing image for feature no. 162\n",
      "Optimizing image for feature no. 163\n",
      "Optimizing image for feature no. 164\n",
      "Optimizing image for feature no. 165\n",
      "Optimizing image for feature no. 166\n",
      "Optimizing image for feature no. 167\n",
      "Optimizing image for feature no. 168\n",
      "Optimizing image for feature no. 169\n",
      "Optimizing image for feature no. 170\n",
      "Optimizing image for feature no. 171\n",
      "Optimizing image for feature no. 172\n",
      "Optimizing image for feature no. 173\n",
      "Optimizing image for feature no. 174\n",
      "Optimizing image for feature no. 175\n",
      "Optimizing image for feature no. 176\n",
      "Optimizing image for feature no. 177\n",
      "Optimizing image for feature no. 178\n",
      "Optimizing image for feature no. 179\n",
      "Optimizing image for feature no. 180\n",
      "Optimizing image for feature no. 181\n",
      "Optimizing image for feature no. 182\n",
      "Optimizing image for feature no. 183\n",
      "Optimizing image for feature no. 184\n",
      "Optimizing image for feature no. 185\n",
      "Optimizing image for feature no. 186\n",
      "Optimizing image for feature no. 187\n",
      "Optimizing image for feature no. 188\n",
      "Optimizing image for feature no. 189\n",
      "Optimizing image for feature no. 190\n",
      "Optimizing image for feature no. 191\n",
      "Optimizing image for feature no. 192\n",
      "Optimizing image for feature no. 193\n",
      "Optimizing image for feature no. 194\n",
      "Optimizing image for feature no. 195\n",
      "Optimizing image for feature no. 196\n",
      "Optimizing image for feature no. 197\n",
      "Optimizing image for feature no. 198\n",
      "Optimizing image for feature no. 199\n",
      "Optimizing image for feature no. 200\n",
      "Optimizing image for feature no. 201\n",
      "Optimizing image for feature no. 202\n",
      "Optimizing image for feature no. 203\n",
      "Optimizing image for feature no. 204\n",
      "Optimizing image for feature no. 205\n",
      "Optimizing image for feature no. 206\n",
      "Optimizing image for feature no. 207\n",
      "Optimizing image for feature no. 208\n",
      "Optimizing image for feature no. 209\n",
      "Optimizing image for feature no. 210\n",
      "Optimizing image for feature no. 211\n",
      "Optimizing image for feature no. 212\n",
      "Optimizing image for feature no. 213\n",
      "Optimizing image for feature no. 214\n",
      "Optimizing image for feature no. 215\n",
      "Optimizing image for feature no. 216\n",
      "Optimizing image for feature no. 217\n",
      "Optimizing image for feature no. 218\n",
      "Optimizing image for feature no. 219\n",
      "Optimizing image for feature no. 220\n",
      "Optimizing image for feature no. 221\n",
      "Optimizing image for feature no. 222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing image for feature no. 223\n",
      "Optimizing image for feature no. 224\n",
      "Optimizing image for feature no. 225\n",
      "Optimizing image for feature no. 226\n",
      "Optimizing image for feature no. 227\n",
      "Optimizing image for feature no. 228\n",
      "Optimizing image for feature no. 229\n",
      "Optimizing image for feature no. 230\n",
      "Optimizing image for feature no. 231\n",
      "Optimizing image for feature no. 232\n",
      "Optimizing image for feature no. 233\n",
      "Optimizing image for feature no. 234\n",
      "Optimizing image for feature no. 235\n",
      "Optimizing image for feature no. 236\n",
      "Optimizing image for feature no. 237\n",
      "Optimizing image for feature no. 238\n",
      "Optimizing image for feature no. 239\n",
      "Optimizing image for feature no. 240\n",
      "Optimizing image for feature no. 241\n",
      "Optimizing image for feature no. 242\n",
      "Optimizing image for feature no. 243\n",
      "Optimizing image for feature no. 244\n",
      "Optimizing image for feature no. 245\n",
      "Optimizing image for feature no. 246\n",
      "Optimizing image for feature no. 247\n",
      "Optimizing image for feature no. 248\n",
      "Optimizing image for feature no. 249\n",
      "Optimizing image for feature no. 250\n",
      "Optimizing image for feature no. 251\n",
      "Optimizing image for feature no. 252\n",
      "Optimizing image for feature no. 253\n",
      "Optimizing image for feature no. 254\n",
      "Optimizing image for feature no. 255\n",
      "Optimizing image for feature no. 256\n",
      "Optimizing image for feature no. 257\n",
      "Optimizing image for feature no. 258\n",
      "Optimizing image for feature no. 259\n",
      "Optimizing image for feature no. 260\n",
      "Optimizing image for feature no. 261\n",
      "Optimizing image for feature no. 262\n",
      "Optimizing image for feature no. 263\n",
      "Optimizing image for feature no. 264\n",
      "Optimizing image for feature no. 265\n",
      "Optimizing image for feature no. 266\n",
      "Optimizing image for feature no. 267\n",
      "Optimizing image for feature no. 268\n",
      "Optimizing image for feature no. 269\n",
      "Optimizing image for feature no. 270\n",
      "Optimizing image for feature no. 271\n",
      "Optimizing image for feature no. 272\n",
      "Optimizing image for feature no. 273\n",
      "Optimizing image for feature no. 274\n",
      "Optimizing image for feature no. 275\n",
      "Optimizing image for feature no. 276\n",
      "Optimizing image for feature no. 277\n",
      "Optimizing image for feature no. 278\n",
      "Optimizing image for feature no. 279\n",
      "Optimizing image for feature no. 280\n",
      "Optimizing image for feature no. 281\n",
      "Optimizing image for feature no. 282\n",
      "Optimizing image for feature no. 283\n",
      "Optimizing image for feature no. 284\n",
      "Optimizing image for feature no. 285\n",
      "Optimizing image for feature no. 286\n",
      "Optimizing image for feature no. 287\n",
      "Optimizing image for feature no. 288\n",
      "Optimizing image for feature no. 289\n",
      "Optimizing image for feature no. 290\n",
      "Optimizing image for feature no. 291\n",
      "Optimizing image for feature no. 292\n",
      "Optimizing image for feature no. 293\n",
      "Optimizing image for feature no. 294\n",
      "Optimizing image for feature no. 295\n",
      "Optimizing image for feature no. 296\n",
      "Optimizing image for feature no. 297\n",
      "Optimizing image for feature no. 298\n",
      "Optimizing image for feature no. 299\n",
      "Optimizing image for feature no. 300\n",
      "Optimizing image for feature no. 301\n",
      "Optimizing image for feature no. 302\n",
      "Optimizing image for feature no. 303\n",
      "Optimizing image for feature no. 304\n",
      "Optimizing image for feature no. 305\n",
      "Optimizing image for feature no. 306\n",
      "Optimizing image for feature no. 307\n",
      "Optimizing image for feature no. 308\n",
      "Optimizing image for feature no. 309\n",
      "Optimizing image for feature no. 310\n",
      "Optimizing image for feature no. 311\n",
      "Optimizing image for feature no. 312\n",
      "Optimizing image for feature no. 313\n",
      "Optimizing image for feature no. 314\n",
      "Optimizing image for feature no. 315\n",
      "Optimizing image for feature no. 316\n",
      "Optimizing image for feature no. 317\n",
      "Optimizing image for feature no. 318\n",
      "Optimizing image for feature no. 319\n",
      "Optimizing image for feature no. 320\n",
      "Optimizing image for feature no. 321\n",
      "Optimizing image for feature no. 322\n",
      "Optimizing image for feature no. 323\n",
      "Optimizing image for feature no. 324\n",
      "Optimizing image for feature no. 325\n",
      "Optimizing image for feature no. 326\n",
      "Optimizing image for feature no. 327\n",
      "Optimizing image for feature no. 328\n",
      "Optimizing image for feature no. 329\n",
      "Optimizing image for feature no. 330\n",
      "Optimizing image for feature no. 331\n",
      "Optimizing image for feature no. 332\n",
      "Optimizing image for feature no. 333\n",
      "Optimizing image for feature no. 334\n",
      "Optimizing image for feature no. 335\n",
      "Optimizing image for feature no. 336\n",
      "Optimizing image for feature no. 337\n",
      "Optimizing image for feature no. 338\n",
      "Optimizing image for feature no. 339\n",
      "Optimizing image for feature no. 340\n",
      "Optimizing image for feature no. 341\n",
      "Optimizing image for feature no. 342\n",
      "Optimizing image for feature no. 343\n",
      "Optimizing image for feature no. 344\n",
      "Optimizing image for feature no. 345\n",
      "Optimizing image for feature no. 346\n",
      "Optimizing image for feature no. 347\n",
      "Optimizing image for feature no. 348\n",
      "Optimizing image for feature no. 349\n",
      "Optimizing image for feature no. 350\n",
      "Optimizing image for feature no. 351\n",
      "Optimizing image for feature no. 352\n",
      "Optimizing image for feature no. 353\n",
      "Optimizing image for feature no. 354\n",
      "Optimizing image for feature no. 355\n",
      "Optimizing image for feature no. 356\n",
      "Optimizing image for feature no. 357\n",
      "Optimizing image for feature no. 358\n",
      "Optimizing image for feature no. 359\n",
      "Optimizing image for feature no. 360\n",
      "Optimizing image for feature no. 361\n",
      "Optimizing image for feature no. 362\n",
      "Optimizing image for feature no. 363\n",
      "Optimizing image for feature no. 364\n",
      "Optimizing image for feature no. 365\n",
      "Optimizing image for feature no. 366\n",
      "Optimizing image for feature no. 367\n",
      "Optimizing image for feature no. 368\n",
      "Optimizing image for feature no. 369\n",
      "Optimizing image for feature no. 370\n",
      "Optimizing image for feature no. 371\n",
      "Optimizing image for feature no. 372\n",
      "Optimizing image for feature no. 373\n",
      "Optimizing image for feature no. 374\n",
      "Optimizing image for feature no. 375\n",
      "Optimizing image for feature no. 376\n",
      "Optimizing image for feature no. 377\n",
      "Optimizing image for feature no. 378\n",
      "Optimizing image for feature no. 379\n",
      "Optimizing image for feature no. 380\n",
      "Optimizing image for feature no. 381\n",
      "Optimizing image for feature no. 382\n",
      "Optimizing image for feature no. 383\n",
      "Optimizing image for feature no. 384\n",
      "Optimizing image for feature no. 385\n",
      "Optimizing image for feature no. 386\n",
      "Optimizing image for feature no. 387\n",
      "Optimizing image for feature no. 388\n",
      "Optimizing image for feature no. 389\n",
      "Optimizing image for feature no. 390\n",
      "Optimizing image for feature no. 391\n",
      "Optimizing image for feature no. 392\n",
      "Optimizing image for feature no. 393\n",
      "Optimizing image for feature no. 394\n",
      "Optimizing image for feature no. 395\n",
      "Optimizing image for feature no. 396\n",
      "Optimizing image for feature no. 397\n",
      "Optimizing image for feature no. 398\n",
      "Optimizing image for feature no. 399\n",
      "Optimizing image for feature no. 400\n",
      "Optimizing image for feature no. 401\n",
      "Optimizing image for feature no. 402\n",
      "Optimizing image for feature no. 403\n",
      "Optimizing image for feature no. 404\n",
      "Optimizing image for feature no. 405\n",
      "Optimizing image for feature no. 406\n",
      "Optimizing image for feature no. 407\n",
      "Optimizing image for feature no. 408\n",
      "Optimizing image for feature no. 409\n",
      "Optimizing image for feature no. 410\n",
      "Optimizing image for feature no. 411\n",
      "Optimizing image for feature no. 412\n",
      "Optimizing image for feature no. 413\n",
      "Optimizing image for feature no. 414\n",
      "Optimizing image for feature no. 415\n",
      "Optimizing image for feature no. 416\n",
      "Optimizing image for feature no. 417\n",
      "Optimizing image for feature no. 418\n",
      "Optimizing image for feature no. 419\n",
      "Optimizing image for feature no. 420\n",
      "Optimizing image for feature no. 421\n",
      "Optimizing image for feature no. 422\n",
      "Optimizing image for feature no. 423\n",
      "Optimizing image for feature no. 424\n",
      "Optimizing image for feature no. 425\n",
      "Optimizing image for feature no. 426\n",
      "Optimizing image for feature no. 427\n",
      "Optimizing image for feature no. 428\n",
      "Optimizing image for feature no. 429\n",
      "Optimizing image for feature no. 430\n",
      "Optimizing image for feature no. 431\n",
      "Optimizing image for feature no. 432\n",
      "Optimizing image for feature no. 433\n",
      "Optimizing image for feature no. 434\n",
      "Optimizing image for feature no. 435\n",
      "Optimizing image for feature no. 436\n",
      "Optimizing image for feature no. 437\n",
      "Optimizing image for feature no. 438\n",
      "Optimizing image for feature no. 439\n",
      "Optimizing image for feature no. 440\n",
      "Optimizing image for feature no. 441\n",
      "Optimizing image for feature no. 442\n",
      "Optimizing image for feature no. 443\n",
      "Optimizing image for feature no. 444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing image for feature no. 445\n",
      "Optimizing image for feature no. 446\n",
      "Optimizing image for feature no. 447\n",
      "Optimizing image for feature no. 448\n",
      "Optimizing image for feature no. 449\n",
      "Optimizing image for feature no. 450\n",
      "Optimizing image for feature no. 451\n",
      "Optimizing image for feature no. 452\n",
      "Optimizing image for feature no. 453\n",
      "Optimizing image for feature no. 454\n",
      "Optimizing image for feature no. 455\n",
      "Optimizing image for feature no. 456\n",
      "Optimizing image for feature no. 457\n",
      "Optimizing image for feature no. 458\n",
      "Optimizing image for feature no. 459\n",
      "Optimizing image for feature no. 460\n",
      "Optimizing image for feature no. 461\n",
      "Optimizing image for feature no. 462\n",
      "Optimizing image for feature no. 463\n",
      "Optimizing image for feature no. 464\n",
      "Optimizing image for feature no. 465\n",
      "Optimizing image for feature no. 466\n",
      "Optimizing image for feature no. 467\n",
      "Optimizing image for feature no. 468\n",
      "Optimizing image for feature no. 469\n",
      "Optimizing image for feature no. 470\n",
      "Optimizing image for feature no. 471\n",
      "Optimizing image for feature no. 472\n",
      "Optimizing image for feature no. 473\n",
      "Optimizing image for feature no. 474\n",
      "Optimizing image for feature no. 475\n",
      "Optimizing image for feature no. 476\n",
      "Optimizing image for feature no. 477\n",
      "Optimizing image for feature no. 478\n",
      "Optimizing image for feature no. 479\n",
      "Optimizing image for feature no. 480\n",
      "Optimizing image for feature no. 481\n",
      "Optimizing image for feature no. 482\n",
      "Optimizing image for feature no. 483\n",
      "Optimizing image for feature no. 484\n",
      "Optimizing image for feature no. 485\n",
      "Optimizing image for feature no. 486\n",
      "Optimizing image for feature no. 487\n",
      "Optimizing image for feature no. 488\n",
      "Optimizing image for feature no. 489\n",
      "Optimizing image for feature no. 490\n",
      "Optimizing image for feature no. 491\n",
      "Optimizing image for feature no. 492\n",
      "Optimizing image for feature no. 493\n",
      "Optimizing image for feature no. 494\n",
      "Optimizing image for feature no. 495\n",
      "Optimizing image for feature no. 496\n",
      "Optimizing image for feature no. 497\n",
      "Optimizing image for feature no. 498\n",
      "Optimizing image for feature no. 499\n",
      "Optimizing image for feature no. 500\n",
      "Optimizing image for feature no. 501\n",
      "Optimizing image for feature no. 502\n",
      "Optimizing image for feature no. 503\n",
      "Optimizing image for feature no. 504\n",
      "Optimizing image for feature no. 505\n",
      "Optimizing image for feature no. 506\n",
      "Optimizing image for feature no. 507\n",
      "Optimizing image for feature no. 508\n",
      "Optimizing image for feature no. 509\n",
      "Optimizing image for feature no. 510\n",
      "Optimizing image for feature no. 511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "images = optimize_images(conv_id=5, num_iterations=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Magnitude_Model/voice-mask-unet/encoder/layer-1/conv2d/Conv2D',\n",
       " 'Magnitude_Model/voice-mask-unet/encoder/layer-2/conv2d/Conv2D',\n",
       " 'Magnitude_Model/voice-mask-unet/encoder/layer-3/conv2d/Conv2D',\n",
       " 'Magnitude_Model/voice-mask-unet/encoder/layer-4/conv2d/Conv2D',\n",
       " 'Magnitude_Model/voice-mask-unet/encoder/layer-5/conv2d/Conv2D',\n",
       " 'Magnitude_Model/voice-mask-unet/encoder/layer-6/conv2d/Conv2D',\n",
       " 'Magnitude_Model/gradients/Magnitude_Model/voice-mask-unet/decoder/layer-6/conv2d_transpose/conv2d_transpose_grad/Conv2D',\n",
       " 'Magnitude_Model/gradients/Magnitude_Model/voice-mask-unet/decoder/layer-5/conv2d_transpose/conv2d_transpose_grad/Conv2D',\n",
       " 'Magnitude_Model/gradients/Magnitude_Model/voice-mask-unet/decoder/layer-4/conv2d_transpose/conv2d_transpose_grad/Conv2D',\n",
       " 'Magnitude_Model/gradients/Magnitude_Model/voice-mask-unet/decoder/layer-3/conv2d_transpose/conv2d_transpose_grad/Conv2D',\n",
       " 'Magnitude_Model/gradients/Magnitude_Model/voice-mask-unet/decoder/layer-2/conv2d_transpose/conv2d_transpose_grad/Conv2D',\n",
       " 'Magnitude_Model/gradients/Magnitude_Model/voice-mask-unet/decoder/layer-1/conv2d_transpose/conv2d_transpose_grad/Conv2D']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Plot the images.\n",
    "    plot_images(images=images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Magnitude_Model/voice-mask-unet/encoder/layer-1/conv2d/BiasAdd:0' shape=(?, 128, 256, 16) dtype=float32>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.voice_mask_network.encoder.l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
