{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import Audio_functions as af\n",
    "from functools import partial\n",
    "import datetime\n",
    "\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = 'C:/Users/Toby/Speech_Data/CHiME3/data/audio/16kHz/backgrounds'\n",
    "#data_folder = 'C:/Users/Toby/Speech_Data/LibriSpeech/train-other-500'\n",
    "sample_rate = 16384\n",
    "n_parallel_readers = 4\n",
    "n_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_pipe = tf.data.Dataset.list_files(data_folder + '/*.wav').map(partial(af.read_audio,\n",
    "                                                                            sample_rate=sample_rate,\n",
    "                                                                            n_channels=n_channels), \n",
    "                                                                    num_parallel_calls=n_parallel_readers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "next_file = data_pipe.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 files processed\n",
      "20 files processed\n",
      "30 files processed\n",
      "40 files processed\n",
      "50 files processed\n",
      "60 files processed\n",
      "70 files processed\n",
      "80 files processed\n",
      "90 files processed\n",
      "100 files processed\n",
      "Files in folder: 102\n",
      "Total length of audio in folder = 181894.61s (2 days, 2:31:34.611328 hours)\n",
      "Maximum file length = 2865.91s\n",
      "Minimum file length = 1008.62s\n",
      "Mean file length = 1783.28s\n"
     ]
    }
   ],
   "source": [
    "length = 0\n",
    "file_count = 0\n",
    "max_file_length = 0\n",
    "min_file_length = 100000\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        file = sess.run(next_file)\n",
    "        len_file = len(file) / sample_rate\n",
    "        length += len_file\n",
    "        if len_file > max_file_length:\n",
    "            max_file_length = len_file\n",
    "        if len_file < min_file_length:\n",
    "            min_file_length = len_file\n",
    "        file_count += 1\n",
    "        if file_count % 10 == 0:\n",
    "            print('{fc} files processed'.format(fc=file_count))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        mean_file_length = length / file_count\n",
    "        print('Files in folder: {fc}'.format(fc=file_count))\n",
    "        print('Total length of audio in folder = {l}s ({lh} hours)'.format(l=round(length, 2), \n",
    "                                                                           lh=str(datetime.timedelta(seconds=length))))\n",
    "        print('Maximum file length = {maxfl}s'.format(maxfl=round(max_file_length, 2)))\n",
    "        print('Minimum file length = {minfl}s'.format(minfl=round(min_file_length, 2)))\n",
    "        print('Mean file length = {meanfl}s'.format(meanfl=round(mean_file_length, 2)))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_config = {'saving': True,  # Whether to take checkpoints\n",
    "                'loading': False,  # Whether to load an existing checkpoint\n",
    "                'dataset': 'LibriSpeech',  # Choice of 'LibriSpeech', 'CHiME', or 'both'\n",
    "                'local_run': False,  # Whether experiment is running on laptop or server\n",
    "                'checkpoint_to_load': \"26/26-20\",  # Checkpoint format: run/run-epoch\n",
    "                'INITIALISATION_TEST': False,  # Whether or not to calculate test metrics before training\n",
    "                'SAMPLE_RATE': 8192,  # Desired sample rate of audio. Input will be resampled to this\n",
    "                'N_FFT': 512,  # Number of samples in each fourier transform\n",
    "                'FFT_HOP': 128,  # Number of samples between the start of each fourier transform\n",
    "                'N_PARALLEL_READERS': 16,\n",
    "                'PATCH_WINDOW': 256,\n",
    "                'PATCH_HOP': 128,\n",
    "                'BATCH_SIZE': 50,\n",
    "                'N_SHUFFLE': 2000,\n",
    "                'EPOCHS': 1,  # Number of full passes through the dataset to train for\n",
    "                'EARLY_STOPPING': True,  # Should validation data checks be used for early stopping?\n",
    "                'VAL_BY_EPOCHS': True,  # Validation at end of each epoch or every 'val_iters'?\n",
    "                'VAL_ITERS': 2000,  # Number of training iterations between validation checks,\n",
    "                'NUM_WORSE_VAL_CHECKS': 3,  # Number of successively worse validation checks before early stopping,\n",
    "                'NORMALISE_MAG': True\n",
    "                }\n",
    "\n",
    "if model_config['local_run']:  # Data and Checkpoint directories on my laptop\n",
    "    model_config['data_root'] = 'C:/Users/Toby/MSc_Project/Test_Audio/GANdatasetsMini/'\n",
    "    model_config['model_base_dir'] = 'C:/Users/Toby/MSc_Project/MScFinalProjectCheckpoints'\n",
    "    model_config['log_dir'] = 'logs/local'\n",
    "\n",
    "else:  # Data and Checkpoint directories on the uni server\n",
    "    model_config['chime_data_root'] = '/data/CHiME3/data/audio/16kHz/isolated/'\n",
    "    model_config['librispeech_data_root'] = 'C:/Users/Toby/Speech_Data/LibriSpeech/'\n",
    "    model_config['model_base_dir'] = '/home/enterprise.internal.city.ac.uk/acvn728/checkpoints'\n",
    "    model_config['log_dir'] = 'logs/ssh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Dataset\n",
    "libri_data_pipe = Dataset.prepare_datasets(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: ((?, 256, 257, 2), (?, 256, 257, 2), (?, 32640, 1), (?, 32640, 1)), types: (tf.float32, tf.float32, tf.float32, tf.float32)>,\n",
       " <PrefetchDataset shapes: ((?, 256, 257, 2), (?, 256, 257, 2), (?, 32640, 1), (?, 32640, 1)), types: (tf.float32, tf.float32, tf.float32, tf.float32)>,\n",
       " <PrefetchDataset shapes: ((?, 256, 257, 2), (?, 256, 257, 2), (?, 32640, 1), (?, 32640, 1)), types: (tf.float32, tf.float32, tf.float32, tf.float32)>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libri_data_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
