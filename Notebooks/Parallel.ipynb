{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import mir_eval\n",
    "\n",
    "import Audio_functions as af\n",
    "import UNet\n",
    "import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model\n",
      "Loading checkpoint\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/Toby/MSc_Project/MScFinalProjectCheckpoints\\26/26-21\n"
     ]
    }
   ],
   "source": [
    "#  Set variables\n",
    "sample_rate=16384\n",
    "n_fft=1024\n",
    "fft_hop=256\n",
    "patch_window=256\n",
    "patch_hop=128\n",
    "n_parallel_readers=4\n",
    "normalise=True\n",
    "batch_size = 5\n",
    "shuffle=False\n",
    "n_shuffle = 10\n",
    "\n",
    "checkpoint = '26/26-21'\n",
    "model_base_dir = 'C:/Users/Toby/MSc_Project/MScFinalProjectCheckpoints'\n",
    "\n",
    "directory_a = 'C:/Users/Toby/MSc_Project/Test_Audio/CHiME/test/Mixed'\n",
    "directory_b = 'C:/Users/Toby/MSc_Project/Test_Audio/CHiME/test/Voice'\n",
    "\n",
    "#  Create the pipeline\n",
    "tf.reset_default_graph()\n",
    "data = Dataset.zip_files(directory_a, directory_b)\n",
    "data = Dataset.get_paired_dataset(data,\n",
    "                                  sample_rate,\n",
    "                                  n_fft,\n",
    "                                  fft_hop,\n",
    "                                  patch_window,\n",
    "                                  patch_hop,\n",
    "                                  n_parallel_readers,\n",
    "                                  batch_size,\n",
    "                                  n_shuffle,\n",
    "                                  normalise)\n",
    "\n",
    "#  Create the iterator\n",
    "mixed_spec, voice_spec, mixed_audio, voice_audio = data.make_one_shot_iterator().get_next()\n",
    "\n",
    "#  Create variable placeholders\n",
    "is_training = tf.placeholder(shape=(), dtype=bool)\n",
    "mixed_mag = tf.expand_dims(mixed_spec[:, :, 1:, 0], 3)\n",
    "mixed_phase = tf.expand_dims(mixed_spec[:, :, 1:, 1], 3)\n",
    "voice_mag = tf.expand_dims(voice_spec[:, :, 1:, 0], 3)\n",
    "\n",
    "# Build U-Net model\n",
    "print('Creating model')\n",
    "model = UNet.UNetModel(mixed_mag, voice_mag, mixed_phase, mixed_audio, voice_audio, 'unet', is_training, name='U_Net_Model')\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "print('Loading checkpoint')\n",
    "checkpoint_path = os.path.join(model_base_dir, checkpoint)\n",
    "restorer = tf.train.Saver()\n",
    "restorer.restore(sess, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal For Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-13 16:26:51.048300:\tBatch retrieved\n",
      "2018-09-13 16:26:51.049300:\tConverting spectrogram to audio\n",
      "2018-09-13 16:26:51.113289:\tCalculating audio quality metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\scipy\\fftpack\\basic.py:159: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  z[index] = x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-13 16:26:51.875023:\tConverting spectrogram to audio\n",
      "2018-09-13 16:26:51.907004:\tCalculating audio quality metrics\n",
      "2018-09-13 16:26:52.140990:\tConverting spectrogram to audio\n",
      "2018-09-13 16:26:52.174968:\tCalculating audio quality metrics\n",
      "2018-09-13 16:26:52.468803:\tConverting spectrogram to audio\n",
      "2018-09-13 16:26:52.523768:\tCalculating audio quality metrics\n",
      "2018-09-13 16:26:52.832593:\tConverting spectrogram to audio\n",
      "2018-09-13 16:26:52.872568:\tCalculating audio quality metrics\n",
      "2018-09-13 16:26:53.197384:\tTesting iteration: 1, Loss: 0.005031157284975052\n"
     ]
    }
   ],
   "source": [
    "test_costs = list()\n",
    "sdrs = list()\n",
    "sirs = list()\n",
    "sars = list()\n",
    "nsdrs = list()\n",
    "\n",
    "cost, voice_est_mag, voice, mixed_audio, mixed_phase = sess.run([model.cost, model.gen_voice,\n",
    "                                                                 model.voice_audio, model.mixed_audio,\n",
    "                                                                 model.mixed_phase], {model.is_training: False})\n",
    "#test_costs.append(cost)\n",
    "print('{ts}:\\tBatch retrieved'.format(ts=datetime.datetime.now()))\n",
    "for i in range(voice_est_mag.shape[0]):\n",
    "    # Transform output back to audio\n",
    "    print('{ts}:\\tConverting spectrogram to audio'.format(ts=datetime.datetime.now()))\n",
    "    voice_est = af.spectrogramToAudioFile(np.squeeze(voice_est_mag[i, :, :, :]).T, n_fft,\n",
    "                                          fft_hop, phase=np.squeeze(mixed_phase[i, :, :, :]).T)\n",
    "    # Reshape for mir_eval\n",
    "    voice_est = np.expand_dims(voice_est, 1).T\n",
    "    voice_patch = voice[i, :, :].T\n",
    "    mixed_patch = mixed_audio[i, :, :].T\n",
    "    # Calculate audio quality statistics\n",
    "    print('{ts}:\\tCalculating audio quality metrics'.format(ts=datetime.datetime.now()))\n",
    "    sdr, sir, sar, _ = mir_eval.separation.bss_eval_sources(voice_patch, voice_est, compute_permutation=False)\n",
    "    sdr_mr, _, _, _ = mir_eval.separation.bss_eval_sources(voice_patch, mixed_patch, compute_permutation=False)\n",
    "    nsdr = sdr[0] - sdr_mr[0]\n",
    "    sdrs.append(sdr[0])\n",
    "    sirs.append(sir[0])\n",
    "    sars.append(sar[0])\n",
    "    nsdrs.append(nsdr)\n",
    "#if iteration % 200 == 0:\n",
    "print(\"{ts}:\\tTesting iteration: 1, Loss: {c}\".format(ts=datetime.datetime.now(), c=cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-13 16:26:59.694589\n",
      "2018-09-13 16:27:31.340167:\tTesting iteration: 1, Loss: 0.005031157284975052\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "inputs = range(voice_est_mag.shape[0]) \n",
    "def get_test_metrics(i):\n",
    "        # Transform output back to audio\n",
    "    print('{ts}:\\tConverting spectrogram to audio'.format(ts=datetime.datetime.now()))\n",
    "    voice_est = af.spectrogramToAudioFile(np.squeeze(voice_est_mag[i, :, :, :]).T, n_fft,\n",
    "                                          fft_hop, phase=np.squeeze(mixed_phase[i, :, :, :]).T)\n",
    "    # Reshape for mir_eval\n",
    "    voice_est = np.expand_dims(voice_est, 1).T\n",
    "    voice_patch = voice[i, :, :].T\n",
    "    mixed_patch = mixed_audio[i, :, :].T\n",
    "    # Calculate audio quality statistics\n",
    "    print('{ts}:\\tCalculating audio quality metrics'.format(ts=datetime.datetime.now()))\n",
    "    sdr, sir, sar, _ = mir_eval.separation.bss_eval_sources(voice_patch, voice_est, compute_permutation=False)\n",
    "    sdr_mr, _, _, _ = mir_eval.separation.bss_eval_sources(voice_patch, mixed_patch, compute_permutation=False)\n",
    "    nsdr = sdr[0] - sdr_mr[0]\n",
    "    sdrs.append(sdr[0])\n",
    "    sirs.append(sir[0])\n",
    "    sars.append(sar[0])\n",
    "    nsdrs.append(nsdr)\n",
    " \n",
    "num_cores = multiprocessing.cpu_count()\n",
    "     \n",
    "results = Parallel(n_jobs=num_cores)(delayed(get_test_metrics)(i) for i in inputs)\n",
    "print(\"{ts}:\\tTesting iteration: 1, Loss: {c}\".format(ts=datetime.datetime.now(), c=cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
