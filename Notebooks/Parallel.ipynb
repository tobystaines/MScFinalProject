{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import mir_eval\n",
    "\n",
    "import Audio_functions as af\n",
    "import UNet\n",
    "import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model\n",
      "Loading checkpoint\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/Toby/MSc_Project/MScFinalProjectCheckpoints\\26/26-21\n"
     ]
    }
   ],
   "source": [
    "#  Set variables\n",
    "sample_rate=16384\n",
    "n_fft=1024\n",
    "fft_hop=256\n",
    "patch_window=256\n",
    "patch_hop=128\n",
    "n_parallel_readers=4\n",
    "normalise=True\n",
    "batch_size = 5\n",
    "shuffle=False\n",
    "n_shuffle = 10\n",
    "\n",
    "checkpoint = '26/26-21'\n",
    "model_base_dir = 'C:/Users/Toby/MSc_Project/MScFinalProjectCheckpoints'\n",
    "\n",
    "directory_a = 'C:/Users/Toby/MSc_Project/Test_Audio/CHiME/test/Mixed'\n",
    "directory_b = 'C:/Users/Toby/MSc_Project/Test_Audio/CHiME/test/Voice'\n",
    "\n",
    "#  Create the pipeline\n",
    "tf.reset_default_graph()\n",
    "data = Dataset.zip_files(directory_a, directory_b)\n",
    "data = Dataset.get_paired_dataset(data,\n",
    "                                  sample_rate,\n",
    "                                  n_fft,\n",
    "                                  fft_hop,\n",
    "                                  patch_window,\n",
    "                                  patch_hop,\n",
    "                                  n_parallel_readers,\n",
    "                                  batch_size,\n",
    "                                  n_shuffle,\n",
    "                                  normalise)\n",
    "\n",
    "#  Create the iterator\n",
    "mixed_spec, voice_spec, mixed_audio, voice_audio = data.make_one_shot_iterator().get_next()\n",
    "\n",
    "#  Create variable placeholders\n",
    "is_training = tf.placeholder(shape=(), dtype=bool)\n",
    "mixed_mag = tf.expand_dims(mixed_spec[:, :, 1:, 0], 3)\n",
    "mixed_phase = tf.expand_dims(mixed_spec[:, :, 1:, 1], 3)\n",
    "voice_mag = tf.expand_dims(voice_spec[:, :, 1:, 0], 3)\n",
    "\n",
    "# Build U-Net model\n",
    "print('Creating model')\n",
    "model = UNet.UNetModel(mixed_mag, voice_mag, mixed_phase, mixed_audio, voice_audio, 'unet', is_training, name='U_Net_Model')\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "print('Loading checkpoint')\n",
    "checkpoint_path = os.path.join(model_base_dir, checkpoint)\n",
    "restorer = tf.train.Saver()\n",
    "restorer.restore(sess, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal For Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-13 16:52:29.694866:\tBatch retrieved\n",
      "2018-09-13 16:52:29.695867:\tConverting spectrogram to audio\n",
      "2018-09-13 16:52:29.797808:\tCalculating audio quality metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\scipy\\fftpack\\basic.py:159: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  z[index] = x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-13 16:52:30.472422:\tConverting spectrogram to audio\n",
      "2018-09-13 16:52:30.505401:\tCalculating audio quality metrics\n",
      "2018-09-13 16:52:30.741268:\tConverting spectrogram to audio\n",
      "2018-09-13 16:52:30.774245:\tCalculating audio quality metrics\n",
      "2018-09-13 16:52:31.012428:\tConverting spectrogram to audio\n",
      "2018-09-13 16:52:31.049403:\tCalculating audio quality metrics\n",
      "2018-09-13 16:52:31.278275:\tConverting spectrogram to audio\n",
      "2018-09-13 16:52:31.311252:\tCalculating audio quality metrics\n",
      "2018-09-13 16:52:31.569106:\tTesting iteration: 1, Loss: 0.004972835071384907\n"
     ]
    }
   ],
   "source": [
    "test_costs = list()\n",
    "sdrs = list()\n",
    "sirs = list()\n",
    "sars = list()\n",
    "nsdrs = list()\n",
    "\n",
    "cost, voice_est_mag, voice, mixed_audio, mixed_phase = sess.run([model.cost, model.gen_voice,\n",
    "                                                                 model.voice_audio, model.mixed_audio,\n",
    "                                                                 model.mixed_phase], {model.is_training: False})\n",
    "#test_costs.append(cost)\n",
    "print('{ts}:\\tBatch retrieved'.format(ts=datetime.datetime.now()))\n",
    "for i in range(voice_est_mag.shape[0]):\n",
    "    # Transform output back to audio\n",
    "    print('{ts}:\\tConverting spectrogram to audio'.format(ts=datetime.datetime.now()))\n",
    "    voice_est = af.spectrogramToAudioFile(np.squeeze(voice_est_mag[i, :, :, :]).T, n_fft,\n",
    "                                          fft_hop, phase=np.squeeze(mixed_phase[i, :, :, :]).T)\n",
    "    # Reshape for mir_eval\n",
    "    voice_est = np.expand_dims(voice_est, 1).T\n",
    "    voice_patch = voice[i, :, :].T\n",
    "    mixed_patch = mixed_audio[i, :, :].T\n",
    "    # Calculate audio quality statistics\n",
    "    print('{ts}:\\tCalculating audio quality metrics'.format(ts=datetime.datetime.now()))\n",
    "    sdr, sir, sar, _ = mir_eval.separation.bss_eval_sources(voice_patch, voice_est, compute_permutation=False)\n",
    "    sdr_mr, _, _, _ = mir_eval.separation.bss_eval_sources(voice_patch, mixed_patch, compute_permutation=False)\n",
    "    nsdr = sdr[0] - sdr_mr[0]\n",
    "    sdrs.append(sdr[0])\n",
    "    sirs.append(sir[0])\n",
    "    sars.append(sar[0])\n",
    "    nsdrs.append(nsdr)\n",
    "#if iteration % 200 == 0:\n",
    "print(\"{ts}:\\tTesting iteration: 1, Loss: {c}\".format(ts=datetime.datetime.now(), c=cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-13 16:52:32.262554\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-1b1563eb1195>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mnum_cores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_cores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_test_metrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{ts}:\\tTesting iteration: 1, Loss: {c}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "test_costs = list()\n",
    "sdrs = list()\n",
    "sirs = list()\n",
    "sars = list()\n",
    "nsdrs = list()\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "inputs = range(voice_est_mag.shape[0]) \n",
    "def get_test_metrics(i):\n",
    "        # Transform output back to audio\n",
    "    print('{ts}:\\tConverting spectrogram to audio'.format(ts=datetime.datetime.now()))\n",
    "    voice_est = af.spectrogramToAudioFile(np.squeeze(voice_est_mag[i, :, :, :]).T, n_fft,\n",
    "                                          fft_hop, phase=np.squeeze(mixed_phase[i, :, :, :]).T)\n",
    "    # Reshape for mir_eval\n",
    "    voice_est = np.expand_dims(voice_est, 1).T\n",
    "    voice_patch = voice[i, :, :].T\n",
    "    mixed_patch = mixed_audio[i, :, :].T\n",
    "    # Calculate audio quality statistics\n",
    "    print('{ts}:\\tCalculating audio quality metrics'.format(ts=datetime.datetime.now()))\n",
    "    sdr, sir, sar, _ = mir_eval.separation.bss_eval_sources(voice_patch, voice_est, compute_permutation=False)\n",
    "    sdr_mr, _, _, _ = mir_eval.separation.bss_eval_sources(voice_patch, mixed_patch, compute_permutation=False)\n",
    "    nsdr = sdr[0] - sdr_mr[0]\n",
    "    sdrs.append(sdr[0])\n",
    "    sirs.append(sir[0])\n",
    "    sars.append(sar[0])\n",
    "    nsdrs.append(nsdr)\n",
    "    \n",
    "    return sdr[0], sir[0], sar[0], nsdr\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "     \n",
    "a, b, c, d = Parallel(n_jobs=num_cores)(delayed(get_test_metrics)(i) for i in inputs)\n",
    "print(\"{ts}:\\tTesting iteration: 1, Loss: {c}\".format(ts=datetime.datetime.now(), c=cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-13.900838252145267, inf, -13.900838252145267, -2.4618728368484675),\n",
       " (-10.147906543200982, inf, -10.147906543200982, 2.9871711022139493),\n",
       " (-7.499546615340268, inf, -7.499546615340268, 1.1246115114477586),\n",
       " (-13.767610654767992, inf, -13.767610654767992, -1.9199050980391004),\n",
       " (-7.620814563153079, inf, -7.620814563153079, 1.7411181495737331)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
