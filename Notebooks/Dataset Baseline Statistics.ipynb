{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Baseline Source Separation Statistics\n",
    "\n",
    "This notebook calculates the baseline source separation statistics for a given dataset. It is currently setup for the folder structure of the new CHiME dataset, which includes mixed, isolated voice and isolated background noise recordings.\n",
    "\n",
    "Metrics are calculated by comparison of the mixed audio to the isolated sources, giving a measure of the audio quality prior to separation and providing a reference against which to compare model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mir_eval\n",
    "import dataset\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((?, 256, 513, 4), (?, 256, 513, 4), (?, 256, 513, 4), (?, 65280, 1), (?, 65280, 1), (?, 65280, 1)), types: (tf.float32, tf.float32, tf.float32, tf.float32, tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Set variables\n",
    "sample_rate=16384\n",
    "n_fft=1024\n",
    "fft_hop=256\n",
    "patch_window=256\n",
    "patch_hop=128\n",
    "n_parallel_readers=4\n",
    "normalise=True\n",
    "batch_size = 50\n",
    "shuffle=False\n",
    "n_shuffle = 1\n",
    "\n",
    "#root = 'C:/Users/Toby/Speech_Data/BG_test/'\n",
    "root = '/home/enterprise.internal.city.ac.uk/acvn728/NewCHiME/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  Create the pipeline\n",
    "tf.reset_default_graph()\n",
    "data = np.empty((0, 3))\n",
    "for env in ['bus', 'caf', 'ped', 'str']:\n",
    "    directory_a = root + 'et05_' + env + '_simu'\n",
    "    directory_b = root + 'et05_bth'\n",
    "    directory_c = root + 'et05_' + env + '_bg'\n",
    "\n",
    "    file_list = dataset.zip_files(directory_a, directory_b, directory_c)\n",
    "    data = np.concatenate((data, file_list))\n",
    "    \n",
    "data = dataset.get_paired_dataset(data,\n",
    "                                  sample_rate,\n",
    "                                  n_fft,\n",
    "                                  fft_hop,\n",
    "                                  patch_window,\n",
    "                                  patch_hop,\n",
    "                                  n_parallel_readers,\n",
    "                                  batch_size,\n",
    "                                  n_shuffle,\n",
    "                                  normalise)\n",
    "\n",
    "#  Create the iterator\n",
    "pipe = data.make_initializable_iterator()\n",
    "_, _, _, mixed_audio, voice_audio, background_audio = pipe.get_next()\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Data and Collect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "tf_config.gpu_options.visible_device_list = str(0)\n",
    "sess = tf.Session(config=tf_config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(pipe.initializer)\n",
    "batch_count = 0\n",
    "metrics = []\n",
    "sdrs = np.empty((0, 2))\n",
    "sirs = np.empty((0, 2))\n",
    "sars = np.empty((0, 2))\n",
    "nsdrs = np.empty((0, 2))\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        mixed, voice, background = sess.run([mixed_audio, voice_audio, background_audio])\n",
    "\n",
    "        # Reshape for mir_eval\n",
    "        mixed = np.transpose(mixed, (0, 2, 1))\n",
    "        voice = np.transpose(voice, (0, 2, 1))\n",
    "        background = np.transpose(background, (0, 2, 1))\n",
    "\n",
    "        for i in range(voice.shape[0]):\n",
    "            ref_sources = np.concatenate((voice[i, :, :], background[i, :, :]), axis=0)\n",
    "            est_sources = np.concatenate((mixed[i, :, :], mixed[i, :, :]), axis=0)\n",
    "\n",
    "            # Calculate audio quality statistics\n",
    "            sdr, sir, sar, _ = mir_eval.separation.bss_eval_sources(ref_sources, est_sources, compute_permutation=False)\n",
    "            sdrs = np.concatenate((sdrs, np.expand_dims(sdr, 1).T), axis=0)\n",
    "            sirs = np.concatenate((sirs, np.expand_dims(sir, 1).T), axis=0)\n",
    "            sars = np.concatenate((sars, np.expand_dims(sar, 1).T), axis=0)\n",
    "        print('{ts}:\\t{bc} processed.'.format(ts=datetime.datetime.now(), bc=batch_count))\n",
    "        batch_count += 1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        mean_sdr = np.mean(sdrs, axis=0)\n",
    "        mean_sir = np.mean(sirs, axis=0)\n",
    "        mean_sar = np.mean(sars, axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-05 13:47:36.871146:\n",
      "Processing complete\n",
      "[{'mean_sir': 3.460299907111517, 'mean_sdr': 1.9689712679452347, 'test': 'voice', 'mean_sar': 14.605391982548587}, {'mean_sir': -2.7038786284632264, 'mean_sdr': -3.3982215847168984, 'test': 'background', 'mean_sar': 14.605391982548587}]\n"
     ]
    }
   ],
   "source": [
    "for (k, v) in (('voice', 0), ('background', 1)):\n",
    "            metrics.append({'test': k, 'mean_sdr': mean_sdr[v],\n",
    "                            'mean_sir': mean_sir[v], 'mean_sar': mean_sar[v]})\n",
    "\n",
    "print('{ts}:\\nProcessing complete\\n{m}'.format(ts=datetime.datetime.now(), m=metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir('test_metrics'):\n",
    "    os.mkdir('test_metrics')\n",
    "file_name = 'test_metrics/NewCHiMEDatasetBaselineMetrics.csv'\n",
    "with open(file_name, 'w') as csvfile:\n",
    "    fieldnames = ['test', 'mean_cost', 'mean_sdr', 'mean_sir', 'mean_sar', 'mean_nsdr']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, lineterminator='\\n')\n",
    "    writer.writeheader()\n",
    "    for test in metrics:\n",
    "        writer.writerow(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
