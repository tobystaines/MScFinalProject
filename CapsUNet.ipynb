{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import capslayer as cl\n",
    "import tensorflow as tf\n",
    "import Model_functions as mf\n",
    "import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Set other variables\n",
    "sample_rate=16384\n",
    "n_fft=1024\n",
    "fft_hop=256\n",
    "patch_window=256\n",
    "patch_hop=128\n",
    "n_parallel_readers=4\n",
    "normalise=True\n",
    "batch_size = 5\n",
    "shuffle=False\n",
    "n_shuffle = 10\n",
    "\n",
    "directory_a = 'C:/Users/Toby/MSc_Project/Test_Audio/GANdatasetsMini/test/Mixed'\n",
    "directory_b = 'C:/Users/Toby/MSc_Project/Test_Audio/GANdatasetsMini/test/Voice'\n",
    "\n",
    "#  Create the pipeline\n",
    "tf.reset_default_graph()\n",
    "data = Dataset.zip_files(directory_a, directory_b)\n",
    "data = Dataset.get_paired_dataset(data,\n",
    "                                  sample_rate,\n",
    "                                  n_fft,\n",
    "                                  fft_hop,\n",
    "                                  patch_window,\n",
    "                                  patch_hop,\n",
    "                                  n_parallel_readers,\n",
    "                                  batch_size,\n",
    "                                  n_shuffle,\n",
    "                                  normalise)\n",
    "\n",
    "#  Create the iterator\n",
    "mixed_spec, voice_spec, mixed_audio, voice_audio = data.make_one_shot_iterator().get_next()\n",
    "\n",
    "#  Create variable placeholders\n",
    "is_training = tf.placeholder(shape=(), dtype=bool)\n",
    "mixed_mag = tf.expand_dims(mixed_spec[:, :, 1:, 0], 3)\n",
    "mixed_phase = tf.expand_dims(mixed_spec[:, :, 1:, 1], 3)\n",
    "voice_mag = tf.expand_dims(voice_spec[:, :, 1:, 0], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CapsNet Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class basicCapsNet(object):\n",
    "    \n",
    "    def __init__(self, mixed_mag, voice_mag, is_training, reuse=True, name='basic_caps_net'):\n",
    "        \"\"\"\n",
    "        input_tensor: Tensor with shape [batch_size, height, width, channels]\n",
    "        is_training:  Boolean - should the model be trained on the current input or not\n",
    "        name:         Model instance name\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name):\n",
    "            self.mixed_mag = mixed_mag\n",
    "            self.voice_mag = voice_mag\n",
    "            self.is_training = is_training\n",
    "            \n",
    "            with tf.variable_scope('Convolution'):\n",
    "                net = mf.conv(mixed_mag, filters=128, kernel_size=5, stride=(1, 1))\n",
    "                self.conv1 = net\n",
    "                \n",
    "            with tf.variable_scope('Primary_Caps'):\n",
    "                net, activation = cl.layers.primaryCaps(inputs=net, \n",
    "                                                        filters=16, \n",
    "                                                        kernel_size=5, \n",
    "                                                        strides=(1,1),\n",
    "                                                        out_caps_dims=[8,1], \n",
    "                                                        method='norm')\n",
    "                self.primary_caps = (net,activation)\n",
    "            \n",
    "            with tf.variable_scope('Conv_Caps'):\n",
    "                net, activation = cl.layers.conv2d(inputs=net,\n",
    "                                                   activation=activation,\n",
    "                                                   filters=1,\n",
    "                                                   out_caps_dims=[16,1],\n",
    "                                                   kernel_size=1,\n",
    "                                                   strides=(1,1),\n",
    "                                                   padding=\"valid\",\n",
    "                                                   routing_method=\"DynamicRouting\",\n",
    "                                                   reuse=None)\n",
    "                self.conv_caps = (net,activation)\n",
    "            \n",
    "            #with tf.variable_scope('Reconstruction_Conv'):\n",
    "            #    net = \n",
    "                \n",
    "                \n",
    "            # Output of caps layers needs to be?\n",
    "            #           Mask of shape [input_tensor]\n",
    "            self.voice_mask = net\n",
    "            #self.gen_voice = self.voice_mask * mixed_mag\n",
    "            \n",
    "            #self.cost = ####\n",
    "            #self.optimizer = ####\n",
    "            #self.training_op = ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = basicCapsNet(mixed_mag, voice_mag, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'basic_caps_net/Conv_Caps/conv2d/routing/Squeeze:0' shape=(?, 252, 508, 1, 16, 1) dtype=float32>,\n",
       " <tf.Tensor 'basic_caps_net/Conv_Caps/conv2d/clip_by_value:0' shape=(?, 252, 508, 1) dtype=float32>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv_caps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up-Conv layer needs to:\n",
    "- take - \n",
    "    - input: [batch size, height, width, channels (capsule layer count), caps dims 1, caps dim 2]\n",
    "    - activtion: [batch size, height, width, channels (capsule layer count)]\n",
    "    - output dims: [channels (capsule layer count), caps dims 1, caps dim 2]\n",
    "    - strides\n",
    "    - padding\n",
    "- return - \n",
    "    - output: [batch size, height, width, channels (capsule layer count), caps dims 1, caps dim 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ExpandDims:0' shape=(?, 256, 512, 1) dtype=float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = tf.reshape(mixed_mag, shape=[-1, mixed_mag.shape[1], mixed_mag.shape[2], mixed_mag.shape[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.primary_caps[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = transforming(model.voice_mask,1, [16,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transforming/Sum:0' shape=(?, 252, 508, 16, 1, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'conv2d/routing/Squeeze:0' shape=(?, 252, 508, 1, 16, 1) dtype=float32>,\n",
       " <tf.Tensor 'conv2d/clip_by_value:0' shape=(?, 252, 508, 1) dtype=float32>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = cl.layers.conv2d(inputs=model.primary_caps[0],\n",
    "                         activation=model.primary_caps[1],\n",
    "                         filters=1,\n",
    "                         out_caps_dims=[16,1],\n",
    "                         kernel_size=1,\n",
    "                         strides=(1,1),\n",
    "                         padding=\"valid\",\n",
    "                         routing_method=\"DynamicRouting\",\n",
    "                         name=None,\n",
    "                         reuse=None)\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=1\n",
    "b=6\n",
    "c=2\n",
    "d=4\n",
    "\n",
    "[a,b]<[c,d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
